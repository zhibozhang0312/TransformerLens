Search.setIndex({"docnames": ["content/citation", "content/contributing", "content/gallery", "content/getting_started", "content/getting_started_mech_interp", "content/news/release-2.0", "content/special_cases", "content/tutorials", "generated/code/modules", "generated/code/transformer_lens", "generated/code/transformer_lens.ActivationCache", "generated/code/transformer_lens.BertNextSentencePrediction", "generated/code/transformer_lens.FactoredMatrix", "generated/code/transformer_lens.HookedEncoder", "generated/code/transformer_lens.HookedEncoderDecoder", "generated/code/transformer_lens.HookedTransformer", "generated/code/transformer_lens.HookedTransformerConfig", "generated/code/transformer_lens.SVDInterpreter", "generated/code/transformer_lens.components", "generated/code/transformer_lens.components.abstract_attention", "generated/code/transformer_lens.components.attention", "generated/code/transformer_lens.components.bert_block", "generated/code/transformer_lens.components.bert_embed", "generated/code/transformer_lens.components.bert_mlm_head", "generated/code/transformer_lens.components.bert_nsp_head", "generated/code/transformer_lens.components.bert_pooler", "generated/code/transformer_lens.components.embed", "generated/code/transformer_lens.components.grouped_query_attention", "generated/code/transformer_lens.components.layer_norm", "generated/code/transformer_lens.components.layer_norm_pre", "generated/code/transformer_lens.components.pos_embed", "generated/code/transformer_lens.components.rms_norm", "generated/code/transformer_lens.components.rms_norm_pre", "generated/code/transformer_lens.components.t5_attention", "generated/code/transformer_lens.components.t5_block", "generated/code/transformer_lens.components.token_typed_embed", "generated/code/transformer_lens.components.transformer_block", "generated/code/transformer_lens.components.unembed", "generated/code/transformer_lens.evals", "generated/code/transformer_lens.head_detector", "generated/code/transformer_lens.hook_points", "generated/code/transformer_lens.loading_from_pretrained", "generated/code/transformer_lens.past_key_value_caching", "generated/code/transformer_lens.patching", "generated/code/transformer_lens.pretrained", "generated/code/transformer_lens.pretrained.weight_conversions", "generated/code/transformer_lens.pretrained.weight_conversions.bert", "generated/code/transformer_lens.pretrained.weight_conversions.bloom", "generated/code/transformer_lens.pretrained.weight_conversions.coder", "generated/code/transformer_lens.pretrained.weight_conversions.gemma", "generated/code/transformer_lens.pretrained.weight_conversions.gpt2", "generated/code/transformer_lens.pretrained.weight_conversions.gptj", "generated/code/transformer_lens.pretrained.weight_conversions.llama", "generated/code/transformer_lens.pretrained.weight_conversions.mingpt", "generated/code/transformer_lens.pretrained.weight_conversions.mistral", "generated/code/transformer_lens.pretrained.weight_conversions.mixtral", "generated/code/transformer_lens.pretrained.weight_conversions.nanogpt", "generated/code/transformer_lens.pretrained.weight_conversions.neel_solu_old", "generated/code/transformer_lens.pretrained.weight_conversions.neo", "generated/code/transformer_lens.pretrained.weight_conversions.neox", "generated/code/transformer_lens.pretrained.weight_conversions.opt", "generated/code/transformer_lens.pretrained.weight_conversions.phi", "generated/code/transformer_lens.pretrained.weight_conversions.phi3", "generated/code/transformer_lens.pretrained.weight_conversions.qwen", "generated/code/transformer_lens.pretrained.weight_conversions.qwen2", "generated/code/transformer_lens.pretrained.weight_conversions.qwen3", "generated/code/transformer_lens.pretrained.weight_conversions.t5", "generated/code/transformer_lens.train", "generated/code/transformer_lens.utilities", "generated/code/transformer_lens.utilities.activation_functions", "generated/code/transformer_lens.utilities.addmm", "generated/code/transformer_lens.utilities.attention", "generated/code/transformer_lens.utilities.devices", "generated/code/transformer_lens.utils", "generated/demos/Exploratory_Analysis_Demo", "generated/demos/Main_Demo", "generated/model_properties_table", "index"], "filenames": ["content/citation.md", "content/contributing.md", "content/gallery.md", "content/getting_started.md", "content/getting_started_mech_interp.md", "content/news/release-2.0.md", "content/special_cases.md", "content/tutorials.md", "generated/code/modules.rst", "generated/code/transformer_lens.rst", "generated/code/transformer_lens.ActivationCache.rst", "generated/code/transformer_lens.BertNextSentencePrediction.rst", "generated/code/transformer_lens.FactoredMatrix.rst", "generated/code/transformer_lens.HookedEncoder.rst", "generated/code/transformer_lens.HookedEncoderDecoder.rst", "generated/code/transformer_lens.HookedTransformer.rst", "generated/code/transformer_lens.HookedTransformerConfig.rst", "generated/code/transformer_lens.SVDInterpreter.rst", "generated/code/transformer_lens.components.rst", "generated/code/transformer_lens.components.abstract_attention.rst", "generated/code/transformer_lens.components.attention.rst", "generated/code/transformer_lens.components.bert_block.rst", "generated/code/transformer_lens.components.bert_embed.rst", "generated/code/transformer_lens.components.bert_mlm_head.rst", "generated/code/transformer_lens.components.bert_nsp_head.rst", "generated/code/transformer_lens.components.bert_pooler.rst", "generated/code/transformer_lens.components.embed.rst", "generated/code/transformer_lens.components.grouped_query_attention.rst", "generated/code/transformer_lens.components.layer_norm.rst", "generated/code/transformer_lens.components.layer_norm_pre.rst", "generated/code/transformer_lens.components.pos_embed.rst", "generated/code/transformer_lens.components.rms_norm.rst", "generated/code/transformer_lens.components.rms_norm_pre.rst", "generated/code/transformer_lens.components.t5_attention.rst", "generated/code/transformer_lens.components.t5_block.rst", "generated/code/transformer_lens.components.token_typed_embed.rst", "generated/code/transformer_lens.components.transformer_block.rst", "generated/code/transformer_lens.components.unembed.rst", "generated/code/transformer_lens.evals.rst", "generated/code/transformer_lens.head_detector.rst", "generated/code/transformer_lens.hook_points.rst", "generated/code/transformer_lens.loading_from_pretrained.rst", "generated/code/transformer_lens.past_key_value_caching.rst", "generated/code/transformer_lens.patching.rst", "generated/code/transformer_lens.pretrained.rst", "generated/code/transformer_lens.pretrained.weight_conversions.rst", "generated/code/transformer_lens.pretrained.weight_conversions.bert.rst", "generated/code/transformer_lens.pretrained.weight_conversions.bloom.rst", "generated/code/transformer_lens.pretrained.weight_conversions.coder.rst", "generated/code/transformer_lens.pretrained.weight_conversions.gemma.rst", "generated/code/transformer_lens.pretrained.weight_conversions.gpt2.rst", "generated/code/transformer_lens.pretrained.weight_conversions.gptj.rst", "generated/code/transformer_lens.pretrained.weight_conversions.llama.rst", "generated/code/transformer_lens.pretrained.weight_conversions.mingpt.rst", "generated/code/transformer_lens.pretrained.weight_conversions.mistral.rst", "generated/code/transformer_lens.pretrained.weight_conversions.mixtral.rst", "generated/code/transformer_lens.pretrained.weight_conversions.nanogpt.rst", "generated/code/transformer_lens.pretrained.weight_conversions.neel_solu_old.rst", "generated/code/transformer_lens.pretrained.weight_conversions.neo.rst", "generated/code/transformer_lens.pretrained.weight_conversions.neox.rst", "generated/code/transformer_lens.pretrained.weight_conversions.opt.rst", "generated/code/transformer_lens.pretrained.weight_conversions.phi.rst", "generated/code/transformer_lens.pretrained.weight_conversions.phi3.rst", "generated/code/transformer_lens.pretrained.weight_conversions.qwen.rst", "generated/code/transformer_lens.pretrained.weight_conversions.qwen2.rst", "generated/code/transformer_lens.pretrained.weight_conversions.qwen3.rst", "generated/code/transformer_lens.pretrained.weight_conversions.t5.rst", "generated/code/transformer_lens.train.rst", "generated/code/transformer_lens.utilities.rst", "generated/code/transformer_lens.utilities.activation_functions.rst", "generated/code/transformer_lens.utilities.addmm.rst", "generated/code/transformer_lens.utilities.attention.rst", "generated/code/transformer_lens.utilities.devices.rst", "generated/code/transformer_lens.utils.rst", "generated/demos/Exploratory_Analysis_Demo.ipynb", "generated/demos/Main_Demo.ipynb", "generated/model_properties_table.md", "index.md"], "titles": ["Citation", "Contributing", "Gallery", "Getting Started", "Getting Started in Mechanistic Interpretability", "TransformerLens 2.0", "Special Cases", "Tutorials", "Transformer Lens API", "transformer_lens", "transformer_lens.ActivationCache", "transformer_lens.BertNextSentencePrediction", "transformer_lens.FactoredMatrix", "transformer_lens.HookedEncoder", "transformer_lens.HookedEncoderDecoder", "transformer_lens.HookedTransformer", "transformer_lens.HookedTransformerConfig", "transformer_lens.SVDInterpreter", "transformer_lens.components", "transformer_lens.components.abstract_attention", "transformer_lens.components.attention", "transformer_lens.components.bert_block", "transformer_lens.components.bert_embed", "transformer_lens.components.bert_mlm_head", "transformer_lens.components.bert_nsp_head", "transformer_lens.components.bert_pooler", "transformer_lens.components.embed", "transformer_lens.components.grouped_query_attention", "transformer_lens.components.layer_norm", "transformer_lens.components.layer_norm_pre", "transformer_lens.components.pos_embed", "transformer_lens.components.rms_norm", "transformer_lens.components.rms_norm_pre", "transformer_lens.components.t5_attention", "transformer_lens.components.t5_block", "transformer_lens.components.token_typed_embed", "transformer_lens.components.transformer_block", "transformer_lens.components.unembed", "transformer_lens.evals", "transformer_lens.head_detector", "transformer_lens.hook_points", "transformer_lens.loading_from_pretrained", "transformer_lens.past_key_value_caching", "transformer_lens.patching", "transformer_lens.pretrained", "transformer_lens.pretrained.weight_conversions", "transformer_lens.pretrained.weight_conversions.bert", "transformer_lens.pretrained.weight_conversions.bloom", "transformer_lens.pretrained.weight_conversions.coder", "transformer_lens.pretrained.weight_conversions.gemma", "transformer_lens.pretrained.weight_conversions.gpt2", "transformer_lens.pretrained.weight_conversions.gptj", "transformer_lens.pretrained.weight_conversions.llama", "transformer_lens.pretrained.weight_conversions.mingpt", "transformer_lens.pretrained.weight_conversions.mistral", "transformer_lens.pretrained.weight_conversions.mixtral", "transformer_lens.pretrained.weight_conversions.nanogpt", "transformer_lens.pretrained.weight_conversions.neel_solu_old", "transformer_lens.pretrained.weight_conversions.neo", "transformer_lens.pretrained.weight_conversions.neox", "transformer_lens.pretrained.weight_conversions.opt", "transformer_lens.pretrained.weight_conversions.phi", "transformer_lens.pretrained.weight_conversions.phi3", "transformer_lens.pretrained.weight_conversions.qwen", "transformer_lens.pretrained.weight_conversions.qwen2", "transformer_lens.pretrained.weight_conversions.qwen3", "transformer_lens.pretrained.weight_conversions.t5", "transformer_lens.train", "transformer_lens.utilities", "transformer_lens.utilities.activation_functions", "transformer_lens.utilities.addmm", "transformer_lens.utilities.attention", "transformer_lens.utilities.devices", "transformer_lens.utils", "Exploratory Analysis Demo", "Transformer Lens Main Demo Notebook", "Model Properties Table", "TransformerLens"], "terms": {"pleas": [0, 1, 3, 4, 5, 75], "cite": 0, "thi": [0, 1, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 67, 71, 72, 73, 75, 77], "librari": [0, 2, 3, 4, 5, 7, 10, 38, 73, 74], "misc": 0, "nanda2022transformerlen": 0, "titl": [0, 1, 74, 75], "transformerlen": [0, 2, 3, 4, 7, 10, 15, 19, 41, 65, 73, 74, 75], "author": [0, 74], "neel": [0, 2, 4, 7, 15, 17, 75], "nanda": [0, 2, 4, 15, 75], "joseph": [0, 5], "bloom": [0, 5, 15, 19, 41, 45, 76], "year": 0, "2022": [0, 73], "howpublish": 0, "url": [0, 3], "http": [0, 1, 3, 7, 10, 15, 16, 19, 27, 35, 38, 39, 43, 70, 73, 74, 75], "github": [0, 1, 3, 7, 15, 70], "com": [0, 3, 7, 10, 15, 19, 70, 74, 75], "transformerlensorg": [0, 3, 7], "For": [1, 5, 10, 11, 13, 14, 15, 19, 35, 39, 73, 74], "one": [1, 3, 4, 5, 10, 11, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 39, 40, 41, 42, 43, 73, 74, 75, 77], "click": [1, 75], "your": [1, 3, 5, 7, 15, 16, 39, 40, 74, 75], "develop": [1, 5, 7, 74, 75], "environ": [1, 3, 77], "project": [1, 5, 7, 10, 19, 27, 67, 74], "includ": [1, 4, 5, 7, 10, 13, 14, 15, 16, 38, 39, 40, 74], "It": [1, 3, 5, 7, 10, 11, 13, 14, 15, 16, 19, 38, 40, 43, 73, 74, 75, 77], "can": [1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 27, 38, 39, 40, 41, 42, 43, 73, 74, 75, 77], "us": [1, 2, 3, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 19, 20, 27, 29, 34, 36, 38, 39, 40, 41, 42, 43, 67, 71, 72, 73, 74, 75, 77], "local": [1, 15, 16, 19, 20, 27, 41, 73, 75], "v": [1, 10, 13, 14, 15, 16, 19, 27, 43, 74, 75], "code": [1, 4, 5, 10, 15, 16, 19, 38, 39, 40, 41, 73, 74, 75], "codespac": 1, "poetri": 1, "packag": 1, "manag": [1, 5, 10, 15, 40, 73], "instal": [1, 5, 74, 75], "follow": [1, 3, 5, 10, 11, 15, 24, 73, 75, 77], "also": [1, 5, 7, 10, 13, 14, 15, 16, 17, 34, 39, 40, 41, 72, 73, 74, 75], "virtual": 1, "config": [1, 15, 16, 19, 20, 27, 41, 43, 67], "virtualenv": 1, "true": [1, 10, 11, 13, 14, 15, 16, 33, 34, 38, 39, 40, 41, 43, 72, 73, 74, 75], "dev": 1, "doc": [1, 5, 8, 10, 15, 75], "jupyt": 1, "If": [1, 3, 5, 8, 10, 11, 13, 14, 15, 16, 28, 31, 35, 39, 40, 41, 43, 72, 73, 74, 75], "ad": [1, 7, 14, 15, 16, 19, 40, 74, 75], "featur": [1, 3, 5, 7, 13, 14, 17, 19, 43, 73, 74, 77], "add": [1, 5, 11, 15, 16, 19, 40, 42, 70, 73, 74, 75, 77], "unit": [1, 5], "you": [1, 3, 4, 5, 7, 10, 13, 14, 15, 16, 17, 33, 38, 39, 40, 41, 72, 73, 74, 75, 77], "need": [1, 3, 5, 10, 14, 15, 16, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 73, 74, 75, 77], "model": [1, 2, 3, 6, 7, 10, 11, 13, 14, 15, 16, 17, 19, 20, 22, 27, 38, 39, 40, 41, 43, 48, 67, 72, 73, 74], "ones": [1, 13, 14, 15, 34, 39, 74], "ar": [1, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 21, 27, 38, 39, 40, 41, 42, 43, 72, 73, 75, 77], "cach": [1, 10, 14, 15, 16, 34, 36, 39, 40, 42, 43, 73, 74, 77], "action": [1, 2, 74], "so": [1, 5, 7, 10, 12, 13, 14, 15, 16, 17, 38, 40, 41, 42, 43, 73, 74, 75], "quickli": [1, 5, 7, 77], "cd": [1, 74, 75], "These": [1, 74, 75], "gpt2": [1, 15, 16, 17, 19, 20, 27, 38, 41, 45, 74, 75, 76], "attn": [1, 10, 13, 14, 15, 16, 19, 33, 41, 43, 73, 74, 75, 76], "onli": [1, 2, 5, 10, 12, 13, 14, 15, 16, 19, 20, 27, 29, 34, 36, 39, 40, 41, 73, 74, 75, 76], "1l": [1, 41, 74, 75, 76], "2l": [1, 15, 41, 75, 76], "3l": [1, 41, 75, 76], "4l": [1, 41, 75, 76], "tini": [1, 10, 15, 41, 73, 74, 75, 76], "stori": [1, 10, 15, 41, 43, 73, 74, 76], "1m": [1, 10, 15, 41, 73, 76], "note": [1, 3, 5, 10, 12, 14, 15, 16, 19, 27, 38, 40, 41, 70, 73, 74, 75], "i": [1, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 23, 24, 25, 27, 29, 34, 35, 36, 38, 39, 40, 41, 42, 43, 67, 71, 72, 73, 74, 77], "quit": [1, 5], "slow": [1, 75], "we": [1, 2, 5, 8, 10, 14, 15, 16, 39, 42, 43, 72, 73, 74, 75, 77], "have": [1, 3, 5, 10, 13, 14, 15, 19, 20, 27, 39, 43, 73, 74, 75, 77], "cpu": [1, 10, 13, 14, 15, 16, 19, 41, 74, 75], "smaller": [1, 5, 75], "like": [1, 3, 4, 5, 7, 11, 13, 14, 15, 16, 22, 33, 38, 39, 43, 73, 74, 75, 77], "prefer": 1, "possibl": [1, 5, 13, 14, 15, 39, 43, 73, 74, 75, 77], "via": [1, 2, 3, 4, 5, 10, 13, 14, 15, 43, 74], "make": [1, 3, 5, 7, 12, 13, 14, 15, 39, 40, 74, 75, 77], "accept": [1, 3, 5, 13, 14, 15, 40, 74], "notebook": [1, 3, 7, 74, 77], "all": [1, 4, 5, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 43, 69, 72, 73, 74, 77], "suit": 1, "mention": [1, 5, 75], "pycln": 1, "isort": 1, "black": [1, 75], "pull": [1, 5], "request": [1, 5], "check": [1, 3, 5, 7, 15, 17, 19, 38, 39, 40, 73, 74, 75], "file": [1, 5, 73], "line": [1, 5, 74, 75], "length": [1, 10, 11, 13, 14, 15, 16, 19, 25, 28, 29, 30, 31, 32, 73, 74, 75], "set": [1, 2, 5, 10, 13, 14, 15, 16, 19, 38, 39, 40, 43, 67, 73, 74, 75], "100": [1, 38, 74, 75], "pyproject": 1, "toml": 1, "instead": [1, 6, 10, 14, 15, 16, 19, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 74, 75], "default": [1, 6, 10, 11, 13, 14, 15, 16, 17, 19, 20, 27, 30, 34, 36, 38, 39, 40, 41, 43, 73, 74, 75], "88": [1, 75], "sure": [1, 3, 5, 15, 74, 75], "thorough": 1, "ani": [1, 3, 10, 13, 14, 15, 16, 19, 20, 27, 40, 41, 65, 73, 74, 75, 77], "should": [1, 5, 7, 10, 11, 13, 14, 15, 19, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 39, 40, 67, 72, 73, 74, 75], "do": [1, 3, 4, 5, 7, 10, 13, 14, 15, 19, 38, 40, 43, 73, 74, 75, 77], "directli": [1, 5, 11, 13, 14, 16, 73, 74, 75], "automat": [1, 5, 7, 11, 15, 16, 73, 74, 75], "gener": [1, 5, 7, 14, 15, 19, 34, 36, 38, 42, 43, 73, 74], "api": [1, 5, 40, 74], "when": [1, 3, 5, 7, 10, 12, 13, 14, 15, 16, 27, 34, 36, 38, 40, 41, 42, 43, 71, 73, 74, 75], "merg": [1, 5, 15], "main": [1, 3, 5, 6, 7, 10, 40, 74], "thei": [1, 4, 5, 15, 16, 19, 38, 43, 73, 74, 75, 77], "pytest": 1, "doctest": 1, "want": [1, 5, 7, 10, 15, 17, 38, 39, 40, 42, 73, 74, 75], "view": [1, 2], "chang": [1, 2, 3, 5, 15, 16, 40, 43, 73, 74, 75], "hot": [1, 74, 75], "reload": [1, 74, 75], "give": [1, 5, 10, 15, 16, 38, 41, 43, 73, 74, 75, 77], "real": [1, 7, 73, 74, 75, 77], "time": [1, 5, 7, 8, 10, 14, 15, 39, 40, 73, 74, 75], "edit": [1, 7, 15, 43, 74, 75, 77], "googl": [1, 7, 41, 74, 75], "python": [1, 2, 16, 33, 38, 41, 73, 75, 76], "write": [1, 2, 3, 5, 15, 73, 74, 75, 77], "some": [1, 3, 5, 10, 14, 15, 17, 19, 38, 40, 43, 73, 74], "from": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 27, 35, 38, 39, 41, 43, 73, 74, 75, 77], "restructuredtext": 1, "rest": [1, 5, 10, 15, 16, 38, 41, 73, 75], "In": [1, 2, 5, 6, 10, 13, 14, 15, 38, 40, 74, 75], "case": [1, 2, 5, 10, 14, 15, 16, 38, 39, 40, 41, 43, 73, 74, 75, 76], "A": [1, 2, 4, 5, 10, 11, 12, 13, 14, 15, 19, 24, 27, 34, 35, 36, 38, 40, 42, 43, 73, 74, 75], "descript": 1, "what": [1, 3, 5, 7, 10, 15, 39, 40, 43, 75, 77], "doe": [1, 5, 10, 11, 13, 14, 15, 16, 39, 40, 43, 73, 74, 75], "much": [1, 5, 10, 14, 15, 38, 39, 43, 72, 73, 74, 75], "detail": [1, 5, 10, 15, 16, 19, 27, 36, 40, 41, 43, 73, 74, 75], "necessari": [1, 5, 75], "fulli": [1, 43, 74], "understand": [1, 10, 15, 39, 75], "warn": [1, 10, 15, 39, 40, 73], "user": [1, 2, 5, 15, 16, 41, 73, 75], "e": [1, 5, 10, 11, 13, 14, 15, 16, 19, 25, 39, 40, 41, 73, 74, 75, 76], "g": [1, 5, 10, 11, 13, 14, 15, 25, 39, 40, 41, 73, 75], "common": [1, 5, 7, 10, 15, 16, 19, 73, 74, 75], "pitfal": 1, "exampl": [1, 2, 10, 11, 13, 14, 15, 17, 19, 35, 38, 40, 73, 74], "here": [1, 2, 3, 5, 15, 16, 19, 20, 27, 38, 39, 73, 74, 75], "print": [1, 10, 38, 67, 73, 74, 75], "1": [1, 3, 4, 5, 10, 11, 13, 14, 15, 16, 19, 20, 21, 27, 33, 34, 35, 39, 40, 41, 42, 73, 74, 75, 76], "2": [1, 3, 4, 10, 11, 13, 14, 15, 16, 19, 24, 38, 39, 41, 73, 74, 75, 76, 77], "3": [1, 6, 10, 12, 13, 14, 15, 16, 19, 38, 41, 43, 72, 73, 74, 75, 76, 77], "arg": [1, 14, 27, 40], "param_without_type_signatur": 1, "each": [1, 5, 10, 11, 12, 13, 14, 15, 16, 19, 39, 40, 41, 42, 43, 71, 72, 73, 74, 75], "indent": 1, "onc": [1, 3, 5, 15, 73, 74, 75], "more": [1, 5, 7, 10, 12, 14, 15, 16, 19, 35, 39, 43, 73, 74, 75, 77], "param_2": 1, "anoth": [1, 5, 74, 75, 77], "paramet": [1, 5, 7, 10, 11, 13, 14, 15, 16, 17, 19, 20, 27, 28, 29, 30, 34, 36, 38, 39, 40, 41, 43, 72, 73, 74], "return": [1, 5, 10, 11, 12, 13, 14, 15, 19, 27, 30, 34, 36, 38, 39, 40, 41, 43, 67, 72, 73, 74, 75], "without": [1, 3, 5, 10, 11, 13, 15, 31, 32, 73, 74, 75], "type": [1, 6, 7, 10, 11, 13, 14, 15, 16, 17, 22, 27, 30, 34, 35, 36, 39, 40, 41, 43, 67, 72, 73, 74, 75], "signatur": [1, 13, 14, 15, 75], "rais": [1, 11, 13, 15, 39, 41, 72, 73, 75], "inform": [1, 15, 16, 35, 40, 41, 74, 75], "about": [1, 5, 7, 10, 15, 38, 40, 43, 73, 74, 75, 77], "error": [1, 10, 11, 15, 39, 41, 72, 75], "mai": [1, 5, 10, 13, 14, 15, 16, 19, 73, 74, 75], "part": [1, 5, 10, 15, 16, 29, 43, 74, 75, 77], "codebas": [1, 75], "cross": [1, 10, 15, 33, 34, 73, 74, 75], "referenc": [1, 5], "omit": [1, 39, 75], "full": [1, 4, 5, 10, 13, 15, 16, 19, 73, 75], "path": [1, 4, 73], "same": [1, 3, 5, 10, 12, 14, 15, 16, 19, 39, 40, 42, 43, 71, 72, 73, 74, 75], "mod": 1, "transformer_len": [1, 3, 5, 8, 74, 75], "modul": [1, 5, 8, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 40, 42, 43, 73, 75], "const": 1, "loading_from_pretrain": [1, 8, 9, 15, 75], "official_model_nam": [1, 15, 41], "hookedtransform": [1, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 38, 39, 41, 43, 67, 72, 73, 74, 75], "meth": [1, 10], "from_pretrain": [1, 3, 6, 10, 13, 14, 15, 17, 38, 41, 73, 74, 75], "attr": 1, "cfg": [1, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 42, 47, 48, 54, 55, 61, 62, 63, 64, 65, 66, 72, 73, 74, 75], "latex": 1, "re": [1, 3, 4, 7, 10, 15, 16, 39, 74, 75], "place": [1, 5, 7, 13, 14, 15, 73, 74, 75, 77], "string": [1, 11, 13, 14, 15, 16, 38, 39, 40, 41, 72, 73, 74, 75], "backward": [1, 40, 74, 75], "slash": 1, "must": [1, 10, 15, 16, 19, 39, 40, 70, 73, 74, 75], "repeat": [1, 15, 38, 42, 73, 74, 75], "inlin": 1, "displai": [1, 74, 75], "mode": [1, 10, 15, 16, 19, 29, 73, 74, 75], "b": [1, 11, 12, 13, 15, 24, 35, 38, 41, 43, 71, 73, 75, 76], "2ab": 1, "nowrap": 1, "begin": [1, 3, 5, 14, 15, 38, 39, 73, 74, 75], "eqnarrai": 1, "y": [1, 10, 15, 39, 74, 75], "ax": [1, 15, 43, 75], "bx": 1, "c": [1, 41, 73, 75, 76], "f": [1, 74, 75], "x": [1, 5, 10, 15, 19, 28, 29, 31, 32, 39, 40, 41, 70, 73, 74, 75], "2xy": 1, "end": [1, 5, 7, 14, 15, 40, 43, 73, 74, 75], "ital": 1, "text": [1, 7, 10, 11, 13, 14, 15, 16, 19, 34, 36, 38, 40, 41, 42, 73, 74], "bold": 1, "list": [1, 3, 4, 10, 11, 13, 14, 15, 16, 38, 39, 40, 42, 43, 72, 73, 74, 75], "item": [1, 5, 10, 73, 74, 75], "number": [1, 5, 10, 14, 15, 16, 17, 19, 38, 41, 43, 67, 72, 73, 74, 75], "quot": 1, "level": [1, 40, 74, 75, 77], "extern": [1, 74], "link": [1, 15, 38], "domain": 1, "invalid": 1, "research": [2, 3, 4, 5, 7, 74, 75, 77], "done": [2, 4, 5, 6, 10, 15, 16, 19, 40, 74, 75], "involv": [2, 5, 74, 75], "progress": [2, 5, 14, 15, 75], "measur": [2, 38, 39, 43, 73, 74], "grokk": [2, 7], "mechanist": [2, 3, 7, 43, 74, 75], "interpret": [2, 3, 7, 10, 15, 17, 39, 43, 73, 74], "iclr": 2, "spotlight": 2, "2023": 2, "lawrenc": 2, "chan": 2, "tom": [2, 74], "lieberum": 2, "jess": 2, "smith": 2, "jacob": 2, "steinhardt": 2, "find": [2, 5, 7, 10, 12, 15, 43, 74, 75], "neuron": [2, 7, 10, 15, 74, 75], "haystack": 2, "studi": [2, 4, 43, 74, 75], "spars": [2, 5], "probe": 2, "gurne": 2, "matthew": 2, "pauli": 2, "katherin": 2, "harvei": 2, "dmitrii": 2, "troitskii": 2, "dimitri": 2, "bertsima": 2, "toward": [2, 19, 43, 74], "autom": 2, "circuit": [2, 13, 15, 19, 38, 39, 43, 73, 74, 75], "discoveri": 2, "arthur": [2, 75], "conmi": [2, 75], "augustin": 2, "n": [2, 15, 19, 67, 70, 73, 74, 75], "mavor": 2, "parker": 2, "aengu": 2, "lynch": 2, "stefan": 2, "heimersheim": 2, "adri\u00e0": 2, "garriga": 2, "alonso": 2, "actual": [2, 5, 15, 39, 40, 75], "othello": [2, 7, 41, 76], "gpt": [2, 3, 4, 7, 10, 11, 13, 14, 15, 16, 19, 20, 27, 38, 41, 73, 74, 75, 76, 77], "ha": [2, 3, 4, 5, 10, 11, 12, 13, 14, 15, 19, 27, 38, 41, 42, 43, 71, 72, 73, 74, 75], "linear": [2, 7, 13, 14, 15, 19, 41, 71, 74, 75], "emerg": [2, 7], "world": [2, 5, 7, 75, 77], "represent": [2, 7, 25], "docstr": 2, "4": [2, 3, 5, 16, 19, 38, 41, 73, 74, 75, 76], "layer": [2, 6, 10, 11, 13, 14, 15, 16, 17, 19, 20, 22, 27, 28, 29, 39, 40, 41, 42, 43, 71, 72, 73, 75], "attent": [2, 7, 10, 13, 14, 15, 16, 18, 19, 21, 27, 30, 33, 34, 36, 39, 43, 68, 73, 75], "transform": [2, 3, 4, 7, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 41, 42, 43, 70, 73, 74], "jett": 2, "janiak": 2, "toi": [2, 15], "univers": 2, "icml": 2, "bilal": 2, "chughtai": 2, "n2g": 2, "scalabl": 2, "approach": [2, 5, 10, 74, 75], "quantifi": [2, 39], "larg": [2, 5, 7, 16, 19, 41, 73, 75, 76, 77], "languag": [2, 13, 15, 38, 67, 73, 74, 75], "workshop": 2, "rtml": 2, "alex": [2, 75], "foot": [2, 15, 75], "esben": 2, "kran": 2, "ioanni": 2, "konsta": 2, "fazl": 2, "barez": 2, "elicit": 2, "latent": 2, "predict": [2, 7, 10, 11, 13, 15, 23, 24, 25, 38, 39, 73, 74, 75], "tune": [2, 13, 14, 41, 73, 75, 76], "len": [2, 10, 41], "nora": 2, "belros": 2, "zach": 2, "furman": 2, "logan": 2, "danni": 2, "halawi": 2, "igor": 2, "ostrovski": 2, "lev": 2, "mckinnei": 2, "stella": 2, "biderman": 2, "contribut": [2, 5, 10, 15, 74], "being": [2, 5, 10, 13, 14, 15, 16, 39, 40, 43, 73, 74, 75], "induct": [2, 4, 38, 39, 41], "head": [2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 19, 23, 24, 27, 38, 39, 41, 43, 71, 73], "phase": 2, "replic": [2, 4, 15, 17, 38, 74, 75], "partial": [2, 74, 75], "context": [2, 10, 11, 13, 14, 15, 40, 43, 73, 74, 75], "learn": [2, 3, 7, 16, 67, 73, 74, 75, 77], "connor": 2, "kissan": 2, "decis": [2, 3], "script": [2, 7], "train": [2, 7, 8, 9, 10, 13, 14, 15, 16, 38, 41, 73, 74, 77], "which": [2, 3, 5, 6, 7, 10, 11, 13, 14, 15, 16, 38, 39, 40, 41, 42, 43, 73, 74, 75, 77], "intermedi": [2, 10, 15, 40, 75], "activ": [2, 3, 4, 5, 7, 10, 11, 13, 14, 15, 16, 17, 40, 43, 69, 73, 77], "perform": [2, 6, 7, 11, 13, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 38, 40, 73, 74, 75], "attribut": [2, 4, 7, 10, 19, 43, 73, 75], "ablat": [2, 74, 75], "up": [2, 3, 4, 5, 10, 15, 16, 40, 43, 67, 73, 74, 75], "initi": [2, 5, 8, 15, 16, 27, 40, 72, 73, 74, 75], "work": [2, 3, 4, 5, 7, 10, 13, 14, 15, 19, 40, 41, 73, 74, 75, 77], "found": [2, 3, 5, 6, 15, 16, 74, 75], "demo": [3, 5, 17, 41, 76, 77], "how": [3, 5, 7, 10, 14, 15, 39, 43, 67, 72, 74, 75, 77], "basic": [3, 7, 15, 38, 73, 74], "To": [3, 4, 5, 10, 14, 15, 16, 19, 40, 74, 75], "see": [3, 5, 7, 10, 13, 14, 15, 16, 19, 27, 35, 36, 39, 40, 41, 43, 73, 74, 75, 77], "exploratori": [3, 7, 39, 73, 75, 77], "analysi": [3, 7, 10, 15, 39, 73, 75, 77], "practic": [3, 4, 7, 74, 75], "look": [3, 4, 5, 7, 8, 10, 15, 19, 39, 43, 72, 73, 74, 75, 77], "out": [3, 5, 7, 10, 15, 17, 43, 72, 73, 74, 75], "my": [3, 5, 7, 15, 16, 73, 74, 75, 77], "analys": [3, 7, 10, 15, 75], "indirect": [3, 4, 7, 38], "object": [3, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 38, 40, 41, 42, 67, 73], "identif": [3, 4, 7, 38], "record": [3, 7, 75], "myself": [3, 5, 7, 75], "veri": [3, 4, 5, 7, 10, 16, 17, 38, 74, 75, 77], "young": [3, 4, 75], "small": [3, 4, 5, 6, 7, 10, 15, 16, 38, 41, 73, 74, 75, 76, 77], "field": [3, 4, 5, 15, 73, 75, 77], "lot": [3, 4, 5, 7, 10, 12, 42, 43, 73, 74, 75, 77], "open": [3, 4, 5, 15, 38, 77], "problem": [3, 4, 5, 75, 77], "would": [3, 4, 5, 11, 13, 19, 35, 74, 75, 77], "help": [3, 4, 5, 16, 43, 74, 75, 77], "try": [3, 4, 10, 15, 39, 74, 75], "concret": [3, 4, 74, 75], "figur": [3, 43, 74, 75], "where": [3, 5, 6, 10, 11, 12, 13, 14, 15, 16, 19, 36, 39, 40, 41, 43, 67, 73, 74, 75], "skill": [3, 75], "kei": [3, 4, 5, 10, 13, 14, 15, 16, 19, 20, 27, 33, 34, 36, 38, 39, 42, 43, 73, 74, 75], "resourc": [3, 4, 5], "new": [3, 7, 10, 14, 15, 40, 41, 42, 73, 74, 75], "tutori": [3, 4, 5, 74, 75], "scratch": [3, 4, 74], "an": [3, 4, 7, 10, 11, 12, 13, 14, 15, 16, 19, 38, 39, 40, 41, 42, 43, 67, 71, 73, 74, 77], "accompani": [3, 4, 7, 75], "templat": [3, 38], "yourself": [3, 15, 74, 75], "One": [3, 5, 15, 74, 75, 77], "signific": [3, 40, 74, 75], "design": [3, 5, 10, 11, 74, 75, 77], "made": [3, 5, 38, 74, 75], "wa": [3, 5, 6, 10, 11, 13, 14, 15, 16, 38, 43, 74, 75], "singl": [3, 5, 10, 11, 13, 14, 15, 19, 25, 34, 35, 36, 42, 43, 73, 74, 75], "implement": [3, 5, 11, 13, 14, 15, 19, 43, 70, 73, 74, 75], "could": [3, 5, 74, 75], "support": [3, 5, 7, 10, 11, 13, 14, 15, 16, 33, 39, 40, 69, 70, 72, 73, 74, 75], "rang": [3, 4, 5, 15, 17, 39, 43, 73, 74, 75], "subtli": [3, 19], "differ": [3, 5, 6, 10, 11, 13, 14, 15, 16, 19, 38, 39, 40, 43, 72, 73, 74, 75], "style": [3, 5, 10, 11, 13, 14, 15, 16, 20, 39, 74, 75, 77], "upsid": 3, "just": [3, 4, 5, 10, 14, 15, 16, 38, 43, 73, 74, 75], "arbitrari": [3, 15, 74, 75], "name": [3, 5, 10, 15, 16, 38, 39, 40, 41, 43, 67, 73], "But": [3, 10, 15, 43, 73, 74, 75], "downsid": 3, "py": [3, 5, 13, 14, 70], "compon": [3, 8, 9, 10, 11, 13, 14, 15, 16, 71, 73, 74, 75], "difficult": [3, 10], "recommend": [3, 8, 10, 15, 16, 17, 40, 74, 75], "clean": [3, 43, 73, 74, 75], "minim": [3, 5, 75], "intern": [3, 5, 10, 15, 43, 74, 75, 77], "architectur": [3, 11, 13, 14, 74], "significantli": [3, 11, 13, 14, 15, 38, 43, 74, 75], "clearer": 3, "better": [3, 15, 16, 38, 39, 41, 74, 75], "document": [3, 15, 73, 75], "pip": [3, 5, 74, 75], "git": 3, "import": [3, 5, 10, 15, 17, 38, 42, 43, 73, 77], "known": [3, 77], "easytransform": [3, 75, 77], "break": [3, 5, 10, 74, 75], "been": [3, 5, 10, 15, 73, 75], "sinc": [3, 5, 10, 15, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 74, 75], "renam": [3, 5], "old": [3, 5, 41, 75], "version": [3, 7, 15, 38, 40, 70, 74, 75], "legaci": [3, 39], "run": [3, 5, 6, 10, 14, 15, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 41, 42, 43, 67, 72, 74, 77], "v1": [3, 74], "avail": [3, 5, 7, 10, 15, 16, 39, 41, 72], "requir": [3, 5, 13, 14, 15, 43, 73, 75], "luckili": 3, "provid": [3, 10, 11, 13, 14, 15, 28, 31, 35, 40, 72, 73], "wai": [3, 5, 6, 10, 15, 16, 40, 73, 74, 75], "those": [3, 5, 6, 15, 40, 73, 74], "configur": [3, 5, 16, 67, 72], "environment": 3, "variabl": [3, 11, 13, 14, 25], "simpli": [3, 5, 74], "token": [3, 7, 10, 11, 13, 14, 15, 16, 17, 19, 20, 22, 23, 25, 26, 27, 30, 34, 35, 36, 38, 39, 41, 43, 73, 74], "hf_token": 3, "agreement": 3, "issu": [3, 5, 15, 74, 75], "attempt": [3, 5, 15], "ue": 3, "befor": [3, 10, 13, 14, 15, 16, 19, 20, 21, 40, 73, 74, 75], "relat": [3, 15, 19, 40, 74, 75], "consol": 3, "output": [3, 5, 7, 10, 11, 13, 14, 15, 16, 19, 39, 40, 43, 74, 75], "point": [3, 5, 10, 13, 14, 15, 16, 17, 36, 40, 73, 74, 77], "As": [3, 15, 16, 73, 74, 75], "23": [3, 74, 75], "24": [3, 15, 73, 74, 75, 76], "current": [3, 5, 10, 13, 14, 15, 16, 19, 20, 27, 39, 72, 74, 75], "co": [3, 73], "mistralai": [3, 41, 76], "mixtral": [3, 5, 6, 41, 45, 76], "8x7b": [3, 41], "v0": [3, 41, 76], "mistral": [3, 16, 19, 38, 41, 45, 76], "7b": [3, 5, 7, 41, 75, 76], "instruct": [3, 41, 75, 76], "mean": [4, 5, 10, 15, 16, 17, 19, 20, 27, 31, 32, 39, 40, 73, 74, 75], "": [4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 38, 39, 40, 41, 43, 72, 73, 75, 77], "both": [4, 5, 10, 15, 16, 19, 39, 40, 42, 70, 74, 75], "low": [4, 12, 15, 16, 19, 73, 75], "hang": [4, 75], "fruit": [4, 75], "bar": [4, 14, 15], "entri": [4, 19, 42, 43, 72, 75], "The": [4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 23, 24, 25, 27, 30, 34, 35, 36, 38, 39, 40, 41, 42, 43, 67, 72, 73, 74, 75, 77], "standard": [4, 6, 15, 16, 74, 75], "answer": [4, 10, 43, 73, 74, 75], "why": [4, 5, 10, 19, 73, 74, 75], "yet": [4, 5, 13, 14, 15, 74, 75, 77], "aren": [4, 41, 75], "t": [4, 5, 10, 11, 12, 13, 14, 15, 16, 17, 19, 38, 41, 73, 74, 75, 77], "enough": [4, 5, 10, 74, 75], "peopl": [4, 5, 75], "guid": [4, 75], "arena": 4, "callum": [4, 75], "mcdougal": [4, 75], "comprehens": [4, 75], "introduct": 4, "mech": [4, 74], "interp": [4, 74], "written": [4, 5, 7, 74], "snippet": 4, "copi": [4, 11, 13, 14, 15, 74], "come": [4, 5, 15, 16, 43, 74, 75], "exercis": [4, 74], "solut": [4, 5, 74, 75], "notabl": [4, 15, 40, 74, 75], "video": [4, 7, 74], "me": [4, 5, 41, 75, 77], "good": [4, 5, 7, 10, 38, 73, 74, 75, 77], "cover": [4, 15, 75], "foundat": [4, 75], "concept": [4, 74, 75], "wild": [4, 10, 74, 75], "techniqu": [4, 7, 15, 43, 74, 75], "direct": [4, 5, 10, 15, 17, 40, 43, 75], "logit": [4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 23, 24, 38, 43, 73, 75], "patch": [4, 5, 7, 8, 9], "paper": [4, 7, 10, 15, 16, 19, 35, 38, 43, 75], "read": [4, 5, 7, 10, 15, 75], "200": [4, 75], "explain": [4, 7, 74, 75], "jargon": 4, "unfamiliar": [4, 74], "term": [4, 10, 15, 74], "go": [4, 5, 7, 43, 75, 77], "across": [4, 5, 10, 13, 14, 15, 17, 41, 43, 72, 74, 75], "youtub": 4, "channel": 4, "content": [4, 38, 74, 75], "walkthrough": [4, 74, 75], "am": 5, "happi": 5, "announc": 5, "now": [5, 7, 15, 16, 72, 74, 75], "releas": 5, "recent": 5, "primari": 5, "motiv": [5, 74], "behind": [5, 19, 74], "jump": [5, 75], "transit": [5, 74], "strictli": [5, 10, 75], "describ": [5, 16, 73, 74], "At": [5, 74], "last": [5, 10, 15, 73, 75], "minut": 5, "did": [5, 10, 72, 73, 74], "remov": [5, 10, 12, 15, 19, 40, 72, 73, 74, 75, 77], "hookedsa": 5, "had": [5, 74], "saelen": 5, "bundl": [5, 75], "major": 5, "hand": [5, 74, 75], "modif": 5, "affect": [5, 15, 16, 43, 74], "bryce": 5, "meyer": 5, "softwar": 5, "engin": [5, 43, 74, 75, 77], "littl": [5, 16, 75, 77], "under": [5, 10, 15, 27], "15": [5, 74, 75], "profession": [5, 7], "experi": [5, 7, 16, 74, 75, 77], "wide": 5, "expertis": 5, "embed": [5, 7, 10, 13, 14, 15, 16, 19, 22, 23, 24, 25, 30, 36, 74, 75], "comput": [5, 10, 12, 15, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 33, 35, 37, 39, 40, 42, 43, 73, 74, 75, 77], "coupl": 5, "gotten": [5, 15], "ml": [5, 74, 75, 77], "especi": [5, 15, 74, 75], "ai": [5, 16, 19, 41, 73, 75], "safeti": 5, "nine": 5, "march": 5, "chat": [5, 41, 75, 76], "bit": [5, 16, 74, 75], "he": 5, "ask": 5, "might": [5, 10, 13, 14, 74], "interest": [5, 7, 13, 14, 15, 74, 75], "take": [5, 7, 10, 14, 15, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 43, 72, 73, 74, 75, 77], "role": 5, "maintain": 5, "basi": [5, 13, 15], "april": 5, "far": [5, 15, 73, 74, 75], "pretti": [5, 10, 15, 73, 74, 75], "mani": [5, 15, 27, 42, 43, 67, 74, 75], "kind": [5, 10, 74, 75], "address": 5, "everi": [5, 10, 13, 14, 15, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 43, 67, 73, 74, 75], "await": 5, "repli": 5, "total": [5, 74, 75], "around": [5, 6, 10, 11, 13, 14, 15, 40, 43, 72, 74, 75], "30": [5, 74, 75, 76], "20": [5, 73, 74, 75, 76], "pr": 5, "were": [5, 10, 15, 16, 38, 73, 74, 75, 77], "limit": [5, 13, 14, 15, 74], "llama": [5, 7, 16, 41, 45, 76], "quantiz": [5, 16], "hookedsaetransform": 5, "brand": 5, "class": [5, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 67, 73], "splice": 5, "autoencod": 5, "two": [5, 6, 11, 12, 13, 35, 39, 41, 43, 73, 74, 75], "goal": [5, 74, 75, 77], "posit": [5, 7, 10, 11, 13, 14, 15, 16, 19, 22, 30, 33, 36, 38, 39, 40, 41, 43, 73, 74, 75], "while": [5, 13, 14, 15, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 74, 75], "remain": [5, 10, 15, 40, 75], "power": [5, 75], "who": [5, 75], "push": 5, "second": [5, 15, 38, 72, 74, 75], "base": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 67, 72, 73, 74, 75, 76], "easier": [5, 15, 38, 74, 75, 77], "futur": 5, "llm": 5, "continu": [5, 43, 74, 75], "acceler": [5, 74, 75], "feel": [5, 74, 75, 77], "massiv": [5, 74, 75], "amount": [5, 10, 16, 72, 74], "momentum": [5, 67], "moment": [5, 19, 20, 27, 72], "hope": [5, 75], "carri": 5, "over": [5, 10, 15, 43, 73, 74, 75], "background": [5, 74], "know": [5, 7, 10, 13, 14, 74, 75], "talk": 5, "ensur": [5, 15, 74], "meet": 5, "person": [5, 74], "spoken": 5, "dozen": 5, "commun": 5, "happen": [5, 74, 75], "appoint": 5, "curiou": 5, "hear": 5, "anyon": [5, 38], "tool": [5, 7, 75, 77], "absolut": [5, 6, 13, 14, 15, 16, 19, 30, 39, 73, 74, 75], "beginn": 5, "complet": [5, 10, 19, 73, 74, 75], "expert": [5, 16], "Not": [5, 19, 20, 27, 29], "idea": [5, 15, 19, 43, 74, 75, 77], "evolv": 5, "biggest": [5, 10], "previous": [5, 74], "offici": [5, 41, 75], "instanc": [5, 11, 13, 14, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 39, 40, 74], "compat": [5, 15, 41, 73, 77], "through": [5, 11, 13, 15, 40, 72, 74, 75], "forward": [5, 10, 11, 13, 14, 15, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 42, 75], "start": [5, 10, 14, 15, 16, 19, 43, 73, 74, 75, 77], "todai": [5, 75, 77], "assur": 5, "abl": [5, 74, 75], "upgrad": 5, "worri": 5, "There": [5, 6, 10, 13, 14, 39, 41, 73, 74, 75, 77], "right": [5, 11, 13, 14, 15, 19, 20, 43, 73, 74, 75], "move_model": [5, 10], "activationcach": [5, 8, 9, 11, 13, 14, 15, 39, 43, 73, 74, 75], "function": [5, 10, 11, 13, 14, 15, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 35, 37, 39, 40, 41, 43, 67, 69, 70, 72, 73, 75, 77], "cache_al": [5, 40], "hook_point": [5, 8, 9, 15, 75], "keep": [5, 10, 14, 15, 40, 74, 75, 77], "thing": [5, 12, 15, 16, 19, 43, 74, 75, 77], "simpl": [5, 74, 75], "howev": [5, 10, 15, 27, 38, 74, 75], "them": [5, 10, 14, 15, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 43, 73, 74, 75], "adapt": [5, 75], "awai": [5, 14, 15, 74], "along": [5, 15, 19, 73, 74, 75], "anyth": [5, 38, 73, 74], "mark": [5, 13, 74, 75], "whenev": [5, 40], "someth": [5, 15, 38, 74], "becom": [5, 74, 75], "promin": 5, "sort": [5, 40, 72, 75], "slip": 5, "scenario": 5, "situat": 5, "handl": [5, 13, 15, 40], "persist": [5, 40], "allow": [5, 10, 15, 39, 43, 73, 74, 75], "reli": 5, "interrupt": 5, "still": [5, 40, 74], "encourag": [5, 19, 73], "everyon": 5, "period": [5, 74, 75], "ey": 5, "don": [5, 10, 11, 13, 14, 15, 16, 17, 38, 73, 74, 75, 77], "imagin": [5, 74], "often": [5, 10, 15, 16, 41, 73, 74, 75], "save": [5, 10, 15, 16, 39, 67, 73, 74, 75], "troubl": [5, 10], "move": [5, 10, 11, 13, 14, 15, 43, 74, 75], "three": [5, 15, 43, 73, 74], "timefram": 5, "plan": 5, "state": [5, 10, 15, 34, 40, 74, 75, 77], "tracker": 5, "categor": 5, "easi": [5, 10, 15, 73, 74, 75, 77], "date": [5, 15], "below": [5, 13, 14, 15, 74], "draft": 5, "our": [5, 36, 74, 75, 77], "priorit": 5, "feedback": [5, 73, 74, 75, 77], "surfac": 5, "other": [5, 10, 11, 15, 19, 20, 27, 39, 40, 41, 43, 74], "improv": [5, 73, 74, 75], "achiev": [5, 10, 75], "diagnos": 5, "variou": [5, 16, 40, 74, 75, 77], "area": 5, "memori": [5, 10, 12, 13, 14, 15, 16, 72, 74, 75], "leak": 5, "occur": [5, 74], "seem": [5, 15, 16, 38, 41, 74, 75], "refer": [5, 10, 15, 20, 40, 74, 75], "properli": [5, 38, 72, 74], "thu": 5, "caus": 5, "garbag": 5, "collect": [5, 40, 75], "correctli": [5, 15], "identifi": [5, 7, 15, 43, 72, 74, 75], "proper": [5, 11], "overal": [5, 16, 74], "deal": [5, 15, 19, 73, 74], "larger": [5, 10, 38, 74, 75], "task": [5, 7, 11, 15, 16, 25, 38, 43, 67, 74], "explor": [5, 73, 75], "abil": [5, 10, 43, 74], "batch": [5, 10, 11, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 40, 42, 43, 67, 70, 71, 73, 74, 75], "process": [5, 11, 13, 14, 15, 16, 41, 74, 75], "alreadi": [5, 10, 15, 73, 74, 75], "share": 5, "well": [5, 7, 15, 17, 40, 43, 73, 74, 75], "togeth": [5, 15, 73, 74, 75], "separ": [5, 11, 13, 14, 15, 16, 40, 71, 73, 74, 75], "volunt": 5, "said": 5, "submiss": 5, "discuss": [5, 74], "think": [5, 15, 38, 73, 74, 75], "few": [5, 10, 13, 14, 72, 74, 75], "week": 5, "confus": [5, 74, 75], "among": 5, "calcul": [5, 10, 11, 12, 13, 15, 16, 19, 27, 39, 71, 72, 73, 74, 75], "match": [5, 10, 15, 39, 70, 74], "huggingfac": [5, 13, 14, 15, 16, 38, 41, 70, 73, 75, 77], "solv": [5, 40, 74, 75, 77], "systemat": 5, "submit": 5, "show": [5, 7, 14, 15, 17, 39, 74, 75, 77], "order": [5, 10, 15, 19, 41, 43, 72, 73, 74], "allevi": 5, "build": [5, 40, 75, 77], "spit": 5, "tabl": [5, 74, 75], "u": [5, 12, 15, 43, 73, 74, 75], "snapshot": 5, "store": [5, 10, 15, 16, 27, 40, 42, 43, 67, 74, 75], "repo": [5, 74], "regener": 5, "cumul": [5, 14, 15, 73], "valu": [5, 7, 10, 12, 13, 14, 15, 16, 19, 27, 33, 34, 36, 39, 41, 42, 43, 73, 74, 75, 77], "creat": [5, 7, 10, 15, 19, 40, 74, 75], "robust": [5, 10, 74], "big": [5, 39, 41, 73, 74, 75], "famili": [5, 16, 75], "hard": [5, 15, 74, 75], "even": [5, 7, 12, 15, 16, 19, 38, 41, 74, 75, 77], "smallest": [5, 75], "thought": [5, 10, 74, 75], "thrown": 5, "topic": [5, 7], "best": [5, 7, 15, 72, 74, 75], "guess": [5, 74], "reason": [5, 19, 20, 27, 74, 75], "untrain": 5, "eg": [5, 10, 15, 38, 43, 73, 74, 75], "randomli": [5, 15, 16, 75], "weight": [5, 7, 13, 14, 15, 16, 19, 27, 29, 65, 67, 70, 73, 74, 75, 77], "verifi": [5, 7, 74, 75], "load": [5, 10, 13, 14, 15, 16, 38, 41, 73, 74, 77], "result": [5, 10, 13, 14, 15, 16, 22, 33, 36, 39, 41, 43, 73, 74, 75, 77], "accur": 5, "sens": [5, 12, 40, 74, 75], "consist": [5, 15, 74, 75], "sampl": [5, 14, 15, 38, 73], "size": [5, 10, 14, 15, 16, 19, 25, 38, 67, 73, 74, 75], "against": [5, 74], "bite": 5, "success": [5, 74], "turn": [5, 10, 15, 73, 74, 75], "effici": [5, 12, 19, 73, 75], "proof": [5, 74], "put": [5, 74, 75], "strong": 5, "opinion": 5, "most": [5, 10, 15, 40, 72, 73, 74, 75, 77], "roundtabl": 5, "wrapper": [5, 10, 11, 13, 14, 15, 43, 72, 75], "plugin": 5, "addit": [5, 7, 13, 14, 15, 74, 75], "outsid": 5, "publish": 5, "themselv": [5, 15], "final": [5, 6, 10, 13, 14, 15, 16, 19, 73, 74, 75], "overhaul": 5, "composit": [5, 15, 74, 75], "util": [5, 8, 9, 10, 12, 15, 39, 40, 67, 74, 75], "isol": [5, 74], "rapidli": 5, "itself": [5, 39, 73, 74], "none": [5, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 27, 28, 30, 31, 33, 34, 36, 38, 39, 40, 41, 43, 67, 72, 73, 74, 75], "pain": [5, 75], "rel": [5, 16, 33, 73, 74], "grow": 5, "exponenti": 5, "whole": [5, 74, 75], "explod": 5, "section": [5, 16, 74, 75], "relev": [5, 15, 16, 19, 43, 73, 74, 75], "skip": [5, 15, 74, 75], "setup": [5, 15, 40, 43], "act": [5, 40, 43, 73, 74, 75], "vast": 5, "due": [5, 6, 15, 75], "potenti": 5, "mismatch": [5, 39], "between": [5, 10, 11, 15, 16, 19, 39, 43, 72, 73, 74, 75, 77], "meant": 5, "repres": [5, 11, 12, 13, 16, 35, 39, 43, 73, 74, 75], "updat": [5, 7, 15, 42, 43, 72, 74, 75], "readi": 5, "sent": 5, "justifi": 5, "bug": [5, 7, 10, 16, 75], "fix": [5, 25, 40, 74, 75], "exist": [5, 15, 39, 41, 72, 74, 75], "split": [5, 15, 19, 41, 73, 74, 75], "group": [5, 15, 16, 19, 27], "call": [5, 10, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 35, 37, 40, 41, 73, 74, 75], "again": [5, 74], "piec": [5, 74], "tradition": 5, "everyth": [5, 40, 43, 73, 75], "That": [5, 74], "mock": 5, "spi": 5, "control": [5, 16, 43, 74, 75], "input": [5, 10, 11, 13, 14, 15, 16, 25, 27, 30, 35, 40, 41, 42, 43, 70, 71, 73, 74, 75], "side": [5, 11, 12, 13, 14, 15], "effect": [5, 10, 15, 16, 43, 74, 75], "certain": [5, 16, 43], "logic": 5, "entir": [5, 10, 14, 15, 43, 74], "rule": 5, "incredibli": [5, 75], "cannot": [5, 15, 73, 74, 75], "origin": [5, 11, 16, 17, 19, 74, 75], "pass": [5, 10, 11, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 39, 40, 41, 42, 72, 73, 75], "bunch": [5, 10, 11, 13, 14, 15, 40, 74, 75], "Being": [5, 74], "live": [5, 11, 13, 14, 15, 74, 75], "ci": 5, "report": 5, "great": [5, 7, 75, 77], "get": [5, 7, 10, 11, 13, 14, 15, 16, 17, 19, 38, 39, 40, 43, 72, 74, 75, 77], "review": 5, "meaning": [5, 16, 43], "than": [5, 6, 10, 15, 16, 19, 21, 38, 39, 40, 43, 73, 74, 75], "ever": [5, 73], "substanti": 5, "let": [5, 16, 73, 74, 75, 77], "shift": [5, 43, 75], "favor": 5, "individu": [5, 7, 10, 15, 19, 74], "3000": 5, "18": [5, 73, 74, 75, 76], "distinct": 5, "either": [5, 11, 14, 15, 39, 40, 41, 43, 72, 74, 75], "interdepend": 5, "least": [5, 43, 75], "depend": [5, 10, 11, 13, 15, 75], "its": [5, 10, 15, 19, 40, 74, 75, 77], "own": [5, 7, 74, 75], "realli": [5, 38, 39, 73, 74, 75], "anywher": [5, 43], "els": [5, 15, 16, 19, 41, 73, 74, 75], "mlp": [5, 10, 13, 14, 15, 16, 21, 36, 43, 73, 74, 75], "exactli": [5, 14, 15, 41, 70, 74, 75], "thank": [5, 75], "excit": 5, "standpoint": 5, "perspect": [5, 75], "comparison": [5, 39], "worth": [5, 7, 10, 74, 75], "enabl": [5, 10, 15, 74, 75, 77], "huge": 5, "impact": [5, 10], "bring": 5, "realiti": [5, 74], "semver": 5, "older": [5, 73, 75], "log": [5, 15, 67, 73, 74, 75], "data": [5, 6, 7, 15, 38, 73, 74, 75], "expos": [5, 15, 77], "properti": [5, 12, 13, 14, 15, 19, 27, 73, 74, 75], "minor": [5, 74], "bump": [5, 75], "whatsoev": 5, "With": [5, 19, 75], "fact": [5, 15, 74, 75, 77], "discov": 5, "earlier": [5, 74, 75], "extent": 5, "probabl": [5, 7, 14, 15, 38, 39, 43, 73, 74, 75], "regardless": [5, 73], "stand": 5, "reliabl": 5, "17": [5, 74, 75], "possibli": 5, "easiest": [5, 74], "fresh": 5, "consum": [5, 10, 12], "top": [6, 14, 15, 73, 74, 75], "k": [6, 10, 12, 13, 14, 15, 17, 19, 27, 43, 73, 74, 75], "gate": [6, 15], "hidden": [6, 16, 34, 75], "amplifi": 6, "greatli": [6, 75, 77], "select": [6, 10, 73, 74, 75], "lead": [6, 7, 12, 13, 14, 40, 73, 75], "higher": [6, 14, 15, 74], "normal": [6, 10, 15, 16, 29, 73, 74, 75, 77], "varianc": [6, 74], "test": [6, 7, 15, 38, 39, 73, 74, 75], "half": [6, 12, 13, 14, 15, 19, 38, 75], "precis": [6, 39, 43, 74, 75], "deviat": [6, 16, 75], "compar": [6, 38, 73, 75, 77], "2e": 6, "mitig": 6, "disabl": [6, 15, 39, 40, 74], "preprocess": [6, 13, 14, 74], "option": [6, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 27, 28, 30, 31, 33, 34, 36, 38, 39, 40, 41, 42, 43, 67, 72, 73], "from_pretrained_no_process": [6, 15], "increas": [6, 43, 74, 75], "colab": [7, 74, 75, 77], "blob": [7, 70], "ipynb": 7, "causal": [7, 16, 43, 74, 75], "intervent": [7, 43, 74, 75], "matter": [7, 15, 43, 74, 75], "produc": [7, 14, 15, 43, 74], "incomplet": 7, "gradient": [7, 10, 40, 67, 75], "approxim": [7, 73, 74, 75], "bad": [7, 15], "residu": [7, 10, 13, 14, 15, 16, 19, 34, 36, 37, 43, 75], "stream": [7, 10, 13, 14, 15, 16, 34, 36, 43, 73, 75], "after": [7, 10, 15, 16, 21, 29, 40, 67, 73, 74, 75, 77], "demonstr": [7, 17, 74, 75], "focus": [7, 74, 75], "less": [7, 15, 19, 74, 75], "rigor": [7, 74, 75], "grasp": 7, "steal": 7, "liber": [7, 40], "phenomenon": 7, "memoris": 7, "minimis": 7, "loss": [7, 10, 15, 38, 40, 43, 67, 73, 74, 75], "longer": 7, "generalis": [7, 74, 75], "sharp": [7, 75], "decreas": [7, 19, 73, 74], "modular": [7, 73], "grok": 7, "light": 7, "explan": [7, 43, 74], "ll": [7, 15, 39, 74, 75], "pair": [7, 11, 12, 15, 19, 39, 73, 74, 75], "seri": [7, 10, 75], "detector": [7, 39], "detect": [7, 39, 74, 75], "sever": [7, 10, 15, 73, 74, 75], "custom": [7, 15, 16, 22, 38, 40, 73, 74, 75], "algorithm": [7, 12, 16, 75, 77], "interact": [7, 69, 74, 75], "neuroscop": [7, 75], "hacki": [7, 73], "web": [7, 75], "visualis": [7, 74], "front": 7, "visual": [7, 13, 14, 75], "dynam": [7, 16, 75], "convert": [7, 10, 11, 13, 14, 15, 25, 41, 65, 73, 74, 75], "meta": [7, 15, 41, 73, 74, 75, 76], "until": [7, 10, 14, 15, 40, 74, 75], "multi": [7, 10, 72, 73, 75], "gpu": [7, 10, 12, 13, 14, 15, 72, 74, 75], "access": [7, 10, 16, 40, 73, 74], "No": [7, 75], "previou": [7, 10, 14, 15, 34, 36, 39, 74, 75], "port": 7, "excel": [7, 10, 74, 75, 77], "sequenc": [7, 11, 13, 14, 15, 16, 19, 25, 35, 38, 39, 40, 43, 73, 74, 75], "investig": [7, 10, 15, 39, 74, 75], "svd": [7, 12, 15, 17, 75], "conjectur": 7, "post": [7, 10, 16, 17, 74, 75], "singular": [7, 12, 15, 17, 75], "decomposit": [7, 10, 12, 15, 74, 75], "matric": [7, 12, 13, 14, 15, 17, 19, 20, 27, 70, 74, 75, 77], "surprisingli": 7, "reproduc": [7, 16, 39], "further": [7, 10, 15, 73, 74, 75], "tracr": 7, "cool": 7, "deepmind": 7, "compil": 7, "program": [7, 75, 77], "rasp": 7, "jax": 7, "form": [7, 10, 12, 15, 43, 74, 75], "pytorch": [7, 15, 16, 38, 40, 75], "brows": 8, "first": [8, 10, 15, 16, 38, 41, 43, 72, 73, 74, 75], "submodul": 8, "bertnextsentencepredict": [8, 9], "factoredmatrix": [8, 9, 13, 14, 19, 73, 75], "hookedencod": [8, 9, 11, 72], "hookedencoderdecod": [8, 9, 72], "hookedtransformerconfig": [8, 9, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 42, 47, 48, 54, 55, 61, 62, 63, 64, 65, 66, 72], "svdinterpret": [8, 9], "eval": [8, 9, 75], "head_detector": [8, 9], "past_key_value_cach": [8, 9], "subpackag": 8, "pretrain": [8, 9, 10, 13, 14, 15, 16, 38, 41, 73, 74, 75], "core": [10, 15, 74, 75, 77], "varieti": [10, 75], "helper": [10, 15, 19, 38, 40, 43, 73, 75], "skim": 10, "method": [10, 11, 13, 14, 15, 16, 40, 41, 42, 73, 74, 75], "back": [10, 16, 19, 20, 27, 75], "cache_dict": 10, "dict": [10, 11, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 73], "str": [10, 11, 13, 14, 15, 16, 19, 20, 27, 33, 38, 39, 40, 41, 42, 43, 67, 72, 73, 74, 75], "tensor": [10, 11, 12, 13, 14, 15, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 70, 71, 73, 74, 75, 77], "has_batch_dim": 10, "bool": [10, 11, 13, 14, 15, 16, 33, 34, 38, 39, 40, 41, 42, 43, 67, 73], "run_with_cach": [10, 11, 13, 14, 15, 40, 74, 75], "particular": [10, 17, 39, 74, 75], "behaviour": [10, 15, 74, 75], "step": [10, 15, 16, 41, 67, 73, 74, 75], "respons": [10, 16, 74], "prompt": [10, 15, 19, 38, 43, 73, 74, 75], "chicken": 10, "road": [10, 73], "specif": [10, 11, 13, 14, 15, 19, 39, 41, 43, 72, 74, 75], "sublay": 10, "commonli": 10, "fall": 10, "categori": [10, 74], "dla": 10, "_logit": 10, "residual_stream": 10, "label": [10, 15, 16, 19, 20, 27, 41, 74, 75], "decompose_resid": [10, 74], "return_label": [10, 74], "0": [10, 11, 13, 14, 15, 16, 17, 19, 30, 35, 39, 41, 67, 72, 73, 74, 75, 76], "emb": [10, 15, 18, 22, 30, 35, 73, 75], "pos_emb": [10, 16, 18, 75], "0_attn_out": 10, "proceed": 10, "space": [10, 13, 15, 73, 74, 75], "logit_attr": 10, "shape": [10, 11, 13, 14, 15, 19, 20, 27, 34, 35, 36, 43, 73, 74, 75], "torch": [10, 11, 13, 14, 15, 16, 19, 27, 30, 34, 36, 40, 41, 43, 70, 72, 73, 74, 75], "10": [10, 14, 15, 17, 73, 74, 75, 76], "7": [10, 38, 74, 75, 76], "most_important_component_idx": 10, "argmax": [10, 74], "3_attn_out": 10, "dig": [10, 74, 75, 77], "granular": 10, "get_full_resid_decomposit": 10, "stack": [10, 13, 14, 15, 43, 73, 74, 75], "equal": [10, 16, 75], "struggl": 10, "construct": [10, 13, 14, 15], "joke": 10, "trivial": 10, "accumulated_resid": [10, 74], "footgun": [10, 40], "sourc": [10, 15, 16, 19, 38, 43, 77], "track": [10, 74], "index": [10, 12, 13, 14, 15, 16, 17, 19, 20, 27, 41, 43, 72, 73, 74, 75], "dimens": [10, 12, 15, 16, 19, 27, 28, 31, 40, 43, 70, 71, 73, 74, 75], "vector": [10, 12, 15, 17, 19, 25, 43, 74, 75], "q": [10, 13, 14, 15, 19, 27, 43], "z": [10, 15, 27, 39, 43, 74, 75], "po": [10, 11, 13, 14, 15, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 43, 71, 73, 74, 75], "head_index": [10, 15, 17, 19, 20, 27, 28, 29, 33, 34, 43, 71, 74, 75], "d_head": [10, 13, 14, 15, 16, 19, 20, 27, 41, 42, 71, 73, 74, 75, 76], "pattern": [10, 13, 14, 15, 19, 20, 27, 39, 43, 75], "softmax": [10, 15, 16, 19, 20, 27, 29, 73, 75], "attn_scor": [10, 16, 19, 20], "pre": [10, 15, 16, 19, 20, 27, 29, 32, 39, 73], "query_po": [10, 19, 20, 27, 74], "key_po": [10, 19, 20, 27, 74], "d_model": [10, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 36, 37, 41, 71, 73, 74, 75, 76], "mid": [10, 74], "solu_ln": [10, 16], "layernorm": [10, 13, 14, 15, 16, 21, 28, 29, 31, 73, 74], "d_mlp": [10, 13, 14, 15, 16, 29, 41, 73, 75, 76], "resid_pr": [10, 16, 21, 34, 36, 43, 74, 75], "resid_mid": [10, 43], "resid_post": [10, 16, 74], "attn_out": [10, 15, 16, 43, 74], "mlp_out": [10, 15, 16, 43, 74], "ln": [10, 15, 16, 74, 75], "lnpre": [10, 16], "scale": [10, 15, 16, 19, 20, 27, 73, 74, 75], "sometim": [10, 38, 74], "miss": [10, 74], "becaus": [10, 11, 12, 13, 14, 15, 16, 19, 38, 73, 74, 75, 77], "appli": [10, 12, 15, 16, 19, 21, 36, 40, 43, 73, 74, 75], "remove_batch_dim": [10, 40, 73, 75], "batch_siz": [10, 11, 13, 14, 15, 35, 38, 40, 42, 67, 74, 75], "annot": [10, 75], "layers_cov": 10, "queri": [10, 13, 14, 15, 16, 19, 20, 27, 33, 39, 43, 75], "batch_and_pos_dim": 10, "ve": [10, 15, 19, 38, 40, 74, 77], "slice": [10, 40, 73, 74], "dictionari": [10, 11, 13, 14, 15, 16, 39, 40, 41, 73, 75], "whether": [10, 11, 13, 14, 15, 16, 19, 24, 35, 38, 40, 41, 43, 67, 73, 74, 75], "__getitem__": [10, 12, 38, 42], "retriev": [10, 73], "shorthand": [10, 73], "convent": [10, 20, 73, 74, 75], "tupl": [10, 11, 12, 13, 14, 15, 19, 27, 39, 40, 43, 72, 73, 75], "advanc": 10, "layer_index": [10, 17, 74], "layer_typ": [10, 73, 74], "get_act_nam": [10, 73, 74, 75], "correspond": [10, 15, 27, 39, 43, 73, 74, 75], "given": [10, 12, 13, 14, 15, 17, 39, 40, 41, 43, 72, 73, 74, 75], "__iter__": 10, "iter": [10, 43, 73, 74, 75], "special": [10, 15, 75], "loop": [10, 73, 74, 75, 77], "cache_interesting_nam": 10, "startswith": [10, 75], "block": [10, 15, 16, 19, 20, 21, 27, 34, 36, 43, 73, 74, 75], "append": [10, 42, 74, 75], "hook_emb": [10, 73, 75], "hook_pos_emb": [10, 75], "hook_resid_pr": [10, 75], "__len__": [10, 38], "int": [10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 26, 27, 28, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 67, 72, 73, 74, 75], "incl_mid": [10, 74], "fals": [10, 11, 13, 14, 15, 16, 33, 38, 39, 40, 41, 42, 43, 67, 73, 74, 75], "apply_ln": [10, 74], "pos_slic": [10, 40, 74], "union": [10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 72, 73, 74], "ndarrai": [10, 15, 40, 73], "mlp_input": [10, 15], "float": [10, 11, 12, 13, 14, 15, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 41, 42, 43, 67, 70, 71, 73, 74, 75], "accumul": [10, 15, 74], "sub": [10, 75], "www": 10, "lesswrong": 10, "ackrb8wdpdan6v6ru": 10, "believ": [10, 38, 74], "vocabulari": [10, 16, 74, 75], "rememb": 10, "norm": [10, 12, 15, 16, 22, 28, 29, 31, 32, 41, 67, 74, 75], "decod": [10, 14, 16, 34], "therefor": [10, 15, 73], "multipli": [10, 15, 19, 20, 39, 70, 74, 75], "unembed": [10, 13, 14, 15, 74, 75], "matrix": [10, 12, 13, 14, 15, 16, 17, 19, 27, 39, 73, 74], "w_u": [10, 13, 14, 15, 74, 75], "broken": [10, 40, 73, 74, 75], "down": [10, 15, 19, 20, 27, 74, 75], "einop": [10, 74, 75], "einsum": [10, 74, 75], "panda": [10, 43], "pd": [10, 43], "devic": [10, 11, 13, 14, 15, 16, 17, 19, 33, 38, 40, 41, 42, 67, 68, 74, 75], "answer_token": [10, 74], "to_single_token": [10, 15, 74, 75], "2975": 10, "accum_resid": 10, "last_token_accum": 10, "9": [10, 73, 74, 75, 76], "64": [10, 41, 73, 75, 76], "50257": [10, 41, 75, 76], "layers_unembed": 10, "d_vocab": [10, 13, 14, 15, 16, 17, 41, 43, 73, 75, 76], "rank": [10, 12, 15, 19, 73, 74, 75], "correct": [10, 43, 72, 73, 74, 75], "sorted_indic": 10, "argsort": 10, "dim": [10, 15, 73, 74, 75], "descend": [10, 75], "rank_answ": 10, "nonzero": 10, "as_tupl": 10, "0_pre": 10, "4442": 10, "1_pre": [10, 74], "382": 10, "2_pre": 10, "982": 10, "3_pre": 10, "1160": 10, "4_pre": 10, "408": 10, "5_pre": 10, "145": 10, "6_pre": 10, "78": 10, "7_pre": 10, "387": 10, "final_post": 10, "6": [10, 15, 41, 73, 74, 75, 76], "dtype": [10, 13, 14, 15, 16, 19, 41, 72, 74, 75], "int64": [10, 73], "exclud": [10, 39], "n_layer": [10, 13, 14, 15, 16, 41, 43, 72, 74, 75, 76], "immedi": [10, 20, 73, 74, 75], "indic": [10, 11, 13, 14, 35, 40, 43, 72, 73, 74, 75], "taken": [10, 11, 13, 14, 15, 75], "l": [10, 13, 14, 15, 74, 75], "noth": [10, 11, 13, 14, 15, 40, 73, 74, 75], "essenti": [10, 15, 74, 75, 77], "rather": [10, 15, 16, 21, 43, 73, 74, 75], "graph": [10, 74, 75], "apply_ln_to_stack": [10, 15, 73, 74], "residual_stack": [10, 74], "num_compon": 10, "batch_slic": 10, "batch_and_pos_dims_out": 10, "treat": [10, 15, 16, 74, 75], "factor": [10, 12, 15, 16, 72, 74], "simul": [10, 15, 74, 75], "global": [10, 15, 19, 20, 27, 33, 40, 41, 73, 74, 75], "element": [10, 15, 19, 39, 43, 73, 75], "rmsnorm": [10, 16, 19, 31], "unchang": [10, 13, 14, 15, 73, 74, 75], "whose": [10, 13, 14, 15, 38, 73, 74], "trail": [10, 12, 73], "assum": [10, 11, 12, 13, 14, 15, 16, 28, 31, 35, 40, 43, 67, 73, 74], "hook_scal": [10, 73, 74, 75], "unemb": [10, 15, 16, 18, 74, 75], "map": [10, 13, 14, 15, 16, 19, 39, 40, 74, 75], "ie": [10, 13, 14, 15, 16, 19, 41, 43, 73, 74, 75], "ln2": [10, 36, 73, 75], "ln1": [10, 16, 36, 73, 75], "ln_final": [10, 15, 74, 75], "apply_slice_to_batch_dim": 10, "compute_head_result": 10, "sum": [10, 12, 15, 16, 22, 39, 73, 74, 75], "plu": 10, "b_o": [10, 13, 14, 15, 75], "intend": [10, 16, 73], "use_attn_result": [10, 15, 16], "forget": 10, "liter": [10, 11, 13, 14, 15, 17, 39, 40, 43], "incl_emb": 10, "decompos": 10, "incl": 10, "expand_neuron": 10, "bias": [10, 13, 14, 15, 16, 67, 74], "expand": [10, 15, 27], "get_neuron_result": 10, "neuron_slic": 10, "num_neuron": 10, "subset": [10, 16, 38, 74, 75], "specifi": [10, 13, 14, 15, 16, 27, 38, 39, 40, 72, 73, 75], "expens": [10, 12, 75], "cheap": 10, "incorrect_token": [10, 74], "typic": [10, 15, 35, 39, 74, 75], "revers": [10, 12, 43, 73, 74, 75, 77], "dot": [10, 15, 19, 20, 73], "product": [10, 12, 13, 14, 19, 20, 75], "incorrect": [10, 15, 43, 74, 75], "arxiv": [10, 15, 16, 19, 27, 35, 38], "org": [10, 15, 16, 19, 27, 35, 38, 75, 77], "ab": [10, 12, 15, 27, 39, 74, 75], "2211": [10, 38], "00593": [10, 38], "john": [10, 74, 75], "mari": [10, 74, 75], "went": [10, 74, 75], "shop": [10, 74, 75], "gave": [10, 38, 74, 75], "bag": [10, 74], "choos": [10, 74, 75], "final_ln": 10, "residual_stack_item": 10, "dure": [10, 16, 27, 40, 42, 75, 77], "stack_activ": 10, "activation_nam": [10, 43, 74], "sublayer_typ": 10, "flexibl": 10, "infer": [10, 11, 13, 14, 15, 29, 43, 74, 75], "incl_remaind": 10, "stack_head_result": [10, 74], "axi": [10, 19, 43, 73, 74, 75], "n_head": [10, 13, 14, 15, 16, 19, 27, 41, 42, 43, 73, 74, 75, 76], "notat": [10, 74, 77], "l0h0": 10, "stack_neuron_result": 10, "l0n0": 10, "super": [10, 15, 75], "short": [10, 73, 74, 75, 77], "mostli": [10, 11, 13, 14, 74, 75], "finish": [10, 14, 15, 73, 74, 75], "oper": [10, 72, 74, 75], "slower": 10, "unless": [10, 15, 16, 38, 75], "deprec": [10, 72], "toggle_autodiff": 10, "toggl": [10, 15], "autodiff": [10, 75], "set_grad_en": [10, 74, 75], "danger": 10, "off": [10, 15, 38, 73, 74, 75], "realis": [10, 33, 74], "downstream": [10, 25], "delet": [10, 73, 74], "stick": [10, 74], "mess": [10, 15, 73, 75], "inference_mod": 10, "decor": 10, "similar": [10, 13, 14, 15, 21, 27, 39, 74, 75], "requires_grad": 10, "next": [11, 15, 25, 73, 74, 75], "sentenc": [11, 13, 14, 15, 23, 24, 25, 35, 39, 74, 75], "contain": [11, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 73, 74, 75], "bert": [11, 13, 21, 22, 23, 24, 25, 35, 41, 45, 75, 76], "nsp": [11, 24], "extend": [11, 74], "natur": [11, 38, 74, 75], "inherit": [11, 13, 14, 75], "pooler": [11, 25], "human": [11, 13, 75, 77], "readabl": [11, 13, 73], "sequenti": 11, "appropri": [11, 15, 75], "id": [11, 13, 14, 15, 16, 35], "distinguish": [11, 73, 74], "expect": [11, 33, 38, 39, 74, 75], "return_typ": [11, 13, 14, 15, 40, 74, 75], "token_type_id": [11, 13, 22, 35], "one_zero_attention_mask": [11, 13, 14], "nextsentencepredict": 11, "integ": [11, 13, 15, 73, 74, 75], "binari": [11, 13, 14, 35], "belong": [11, 13, 35], "cl": [11, 13, 25, 35, 75], "sep": [11, 13, 35], "sequence_length": [11, 13, 14, 35, 39, 73], "mask": [11, 13, 14, 15, 19, 23, 30, 34, 36, 73, 74], "attend": [11, 13, 14, 16, 19, 20, 27, 73, 74, 75], "ignor": [11, 13, 14, 15, 16, 19, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 73, 75], "primarili": [11, 13, 14], "pad": [11, 13, 14, 15, 19, 30, 34, 36, 73, 74, 75], "shorter": [11, 13, 14, 15, 75], "explicitli": [11, 13, 15, 16, 19, 38, 41, 43, 75], "valueerror": [11, 73], "format": [11, 13, 14, 15, 40, 65, 74, 75], "assertionerror": [11, 13], "model_arg": [11, 13, 14, 15, 40], "return_cache_object": [11, 13, 14, 15], "kwarg": [11, 13, 14, 15, 41, 73, 74, 75], "hookedrootmodul": [11, 13, 14, 15, 40, 75], "otherwis": [11, 13, 14, 15, 38, 39, 73], "to_token": [11, 13, 14, 15, 73, 74, 75], "move_to_devic": [11, 13, 14, 15], "truncat": [11, 13, 14, 15, 38, 73, 75], "prepend_bo": [11, 13, 14, 15, 16, 38, 41, 73, 74], "param": [11, 13, 20, 67, 73, 75], "too": [11, 13, 14, 15, 43, 74], "long": [11, 13, 14, 15, 75], "max": [11, 13, 14, 15, 74], "window": [11, 13, 14, 15, 16, 73], "eigenvalu": 12, "ldim": [12, 75], "mdim": [12, 75], "rdim": [12, 75], "leading_dim": [12, 73], "ba": 12, "vh": [12, 15], "idx": [12, 38, 42], "collapse_l": 12, "collaps": [12, 74, 75], "left": [12, 15, 19, 73, 74, 75, 77], "orthogon": [12, 15], "self": [12, 13, 14, 15, 19, 73, 75], "collapse_r": 12, "analog": [12, 74, 75], "apart": [12, 73, 74, 75], "zero": [12, 15, 19, 39, 73, 74, 75], "bav": 12, "kv": 12, "abav": 12, "kav": 12, "av": 12, "eigenvector": [12, 75], "get_corn": [12, 73, 74], "make_even": 12, "sqrt": [12, 15, 16, 73], "diag": 12, "equival": [12, 15, 19, 74, 75], "factoris": [12, 15, 19, 75], "row": [12, 15, 43], "col": 12, "ndim": 12, "frobeniu": [12, 75], "squar": [12, 31, 32, 73, 75], "m": [12, 19, 70, 73, 74, 75], "st": 12, "transpos": [12, 73], "obviou": [12, 15, 74], "unsqueez": [12, 73], "hook": [13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 35, 36, 37, 40, 74], "encod": [13, 14, 19, 23, 24, 25, 34, 73, 75], "hookpoint": [13, 14, 15, 40, 74, 75], "dropout": [13, 14], "inconsist": [13, 14, 17], "fine": [13, 14, 75], "fold": [13, 14, 15, 19, 29, 41, 74], "ov": [13, 14, 15, 17, 19, 74, 75], "o": [13, 14, 70, 75], "qk": [13, 14, 15, 19, 74], "w_e": [13, 14, 15, 75], "conveni": [13, 14, 15, 16, 40, 73, 75], "w_e_po": [13, 15], "n_ctx": [13, 15, 16, 19, 41, 75, 76], "concaten": [13, 15, 73, 74, 75], "w_po": [13, 14, 15, 75], "overcomplet": [13, 15], "w_k": [13, 14, 15, 16, 19, 27, 75], "w_o": [13, 14, 15, 19, 20, 74, 75], "w_q": [13, 14, 15, 19, 27, 75], "w_v": [13, 14, 15, 19, 27, 75], "w_in": [13, 14, 15, 17, 75], "w_out": [13, 14, 15, 17, 75], "all_head_label": [13, 14, 15], "h": [13, 14, 15, 74, 75], "b_k": [13, 14, 15, 19, 27, 75], "b_q": [13, 14, 15, 75], "b_u": [13, 14, 15, 74, 75], "bia": [13, 14, 15, 16, 19, 31, 32, 33, 70, 74, 75], "b_v": [13, 14, 15, 19, 27, 75], "b_in": [13, 14, 15, 75], "b_out": [13, 14, 15, 75], "buffer": [13, 14, 15], "modifi": [13, 14, 15], "cuda": [13, 14, 15, 16, 38, 41, 72], "associ": [13, 14, 15, 40], "optim": [13, 14, 15, 67, 74], "encoder_output": 13, "segment": 13, "membership": 13, "resid": [13, 23, 24, 25], "word": [13, 16, 73, 74, 75], "classmethod": [13, 14, 15, 16, 42, 73], "model_nam": [13, 14, 15, 16, 41, 75], "checkpoint_index": [13, 14, 15, 16, 41, 75], "checkpoint_valu": [13, 14, 15, 16, 41, 75], "hf_model": [13, 14, 15], "float32": [13, 14, 15, 16, 19, 41, 74], "from_pretrained_kwarg": [13, 14, 15], "bertformaskedlm": [13, 14], "unlik": [13, 14, 15, 43, 75], "mp": [13, 14, 15], "device_or_dtyp": [13, 15, 72], "print_detail": [13, 15, 72, 73], "cast": [13, 14, 15], "non_block": [13, 14, 15], "memory_format": [13, 14, 15], "channels_last": [13, 14, 15], "Its": [13, 14, 15], "complex": [13, 14, 15, 16, 74, 75], "integr": [13, 14, 15, 41], "tri": [13, 14, 15, 74, 75, 77], "asynchron": [13, 14, 15], "respect": [13, 14, 15, 40, 73, 75], "host": [13, 14, 15, 41], "pin": [13, 14, 15], "desir": [13, 14, 15], "4d": [13, 14, 15], "keyword": [13, 14, 15, 40, 75], "argument": [13, 14, 15, 16, 40, 41, 72, 73, 75], "xdoctest": [13, 14, 15], "ignore_w": [13, 14, 15], "non": [13, 14, 15, 16, 19, 38, 73, 74, 75], "determinist": [13, 14, 15, 73, 74], "nn": [13, 14, 15, 40, 75], "1913": [13, 14, 15], "3420": [13, 14, 15], "5113": [13, 14, 15], "2325": [13, 14, 15], "doubl": [13, 14, 15], "in_featur": [13, 14, 15], "out_featur": [13, 14, 15], "float64": [13, 14, 15], "env": [13, 14, 15], "torch_doctest_cuda1": [13, 14, 15], "gpu1": [13, 14, 15], "1914": [13, 14, 15], "5112": [13, 14, 15], "2324": [13, 14, 15], "float16": [13, 14, 15], "cdoubl": [13, 14, 15], "3741": [13, 14, 15], "j": [13, 14, 15, 16, 19, 41, 74, 75, 76], "2382": [13, 14, 15], "5593": [13, 14, 15], "4443": [13, 14, 15], "complex128": [13, 14, 15], "6122": [13, 14, 15], "1150": [13, 14, 15], "encoderdecod": [14, 16], "t5": [14, 16, 33, 34, 41, 45, 76], "pretrainedtokenizerbas": [14, 15, 73], "decoder_input": 14, "decoder_po": 14, "bo": [14, 15, 16, 39, 41, 73, 74, 75], "vocab_s": [14, 73], "max_new_token": [14, 15, 75], "stop_at_eo": [14, 15], "eos_token_id": [14, 15, 73], "do_sampl": [14, 15], "top_k": [14, 15, 73, 74, 75], "top_p": [14, 15, 73], "temperatur": [14, 15, 73, 75], "freq_penalti": [14, 15, 73], "verbos": [14, 15], "new_token": [14, 42], "eos_token": [14, 15], "reach": [14, 15, 75], "adjust": [14, 16, 74, 75], "avoid": [14, 15, 16, 42, 73, 74, 75], "fiddl": [14, 15], "rag": [14, 15], "eot": [14, 15], "throw": [14, 15], "enter": [14, 74, 75, 77], "messi": [14, 15, 75], "maximum": [14, 15, 16, 19, 67, 75], "stop": [14, 15, 75], "stable_lm": [14, 15], "distribut": [14, 15, 72, 73, 74, 75], "greedi": [14, 15, 73], "search": [14, 15, 39, 74, 75], "mass": [14, 15], "random": [14, 15, 16, 38, 67, 74, 75], "temp": [14, 15, 73], "inf": [14, 15], "uniform": [14, 15, 73], "frequenc": [14, 15, 16, 73, 74], "penalti": [14, 15, 73], "penalis": [14, 15], "whatev": [14, 15, 74], "tqdm": [14, 15, 75], "fairli": [15, 74, 75], "extract": [15, 75], "harder": [15, 43, 74], "aim": [15, 74, 77], "simplifi": [15, 74, 75], "attach": [15, 75], "within": [15, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 39, 40, 43, 73, 74, 75], "inspect": [15, 74], "alter": 15, "facilit": 15, "deeper": 15, "default_padding_sid": 15, "50": [15, 67, 75], "initialis": [15, 16], "although": [15, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40], "instanti": [15, 16, 75], "__init__": [15, 19, 20, 27, 28, 29, 31, 32, 40, 73, 75], "test_prompt": [15, 73, 74, 75], "w_gate": 15, "tokenizer_nam": [15, 16], "n_devic": [15, 16, 41, 72], "greater": [15, 39], "multipl": [15, 39, 72, 73, 75], "accumulated_bia": 15, "include_mlp_bias": 15, "all_composition_scor": [15, 73], "score": [15, 16, 19, 20, 27, 39, 43, 74], "l1": 15, "h1": 15, "l2": 15, "h2": [15, 74], "upper": [15, 19], "triangular": [15, 39, 73, 75], "third": [15, 75], "pub": [15, 73], "2021": 15, "framework": [15, 19, 74, 75], "html": [15, 73, 74], "20abov": 15, "20diagram": 15, "20show": 15, "20q": 15, "2d": [15, 70, 73], "2c": 15, "20k": [15, 73], "20and": 15, "20v": 15, "2dcomposit": 15, "metric": [15, 39, 43, 74, 75], "center_unemb": [15, 74], "state_dict": 15, "center": [15, 16, 29, 31, 32, 74, 75], "subtract": [15, 39, 74], "translat": [15, 74, 75], "invari": 15, "prob": [15, 73, 74, 75], "slightli": [15, 73, 74], "misl": 15, "center_writing_weight": [15, 74, 75], "fold_layer_norm": [15, 41], "check_hooks_to_add": [15, 40], "hook_point_nam": [15, 40], "dir": [15, 40], "fwd": [15, 40], "is_perman": [15, 40], "prepend": [15, 16, 38, 40, 41, 73, 75], "overrid": [15, 16, 40, 41, 73], "fold_bias": 15, "center_weight": 15, "rm": [15, 16, 31, 32], "neighbour": 15, "further_com": [15, 16], "md": [15, 16], "fold_value_bias": 15, "alwai": [15, 16, 43, 74, 75], "constant": [15, 16, 19, 74, 75], "doesn": [15, 38, 73, 74, 75], "formal": 15, "b_o_new": 15, "b_o_origin": 15, "sum_head": 15, "b_v_head": 15, "w_o_head": 15, "loss_per_token": 15, "use_default_valu": 15, "padding_sid": [15, 73, 74], "start_at_lay": 15, "shortformer_pos_emb": [15, 19, 36], "attention_mask": [15, 19, 30, 34, 36, 42, 73], "stop_at_lay": [15, 75], "past_kv_cach": [15, 30], "hookedtransformerkeyvaluecach": [15, 34, 36, 42], "flag": [15, 16, 38, 40, 43, 73, 74, 75], "entropi": [15, 73, 74, 75], "per": [15, 43, 74, 75], "averag": [15, 38, 74, 75], "scalar": [15, 19, 40, 75], "default_prepend_bo": [15, 16, 38, 41, 73, 75], "impli": 15, "usag": [15, 74], "accordingli": [15, 16, 19, 41, 74, 75], "lose": [15, 16, 41], "empir": [15, 16, 41, 43, 75], "inclus": 15, "neg": [15, 73, 74, 75], "shortform": [15, 16, 19, 36, 41], "positional_embedding_typ": [15, 16, 19], "exclus": [15, 73], "etc": [15, 16, 43, 74, 75, 77], "frozen": [15, 42], "pai": [15, 19, 74], "okai": 15, "twice": [15, 38, 74, 75], "accident": [15, 40], "fold_ln": [15, 41, 74, 75], "refactor_factored_attn_matric": [15, 74], "first_n_lay": [15, 41], "autoregress": [15, 67], "neo": [15, 19, 20, 27, 41, 45, 75, 76], "gptj": [15, 41, 45], "opt": [15, 41, 45, 75, 76], "solu": [15, 16, 41, 73, 75, 76], "checkpoint": [15, 16, 41, 67], "neelnanda": [15, 41], "stanford": [15, 16, 19, 20, 27, 41, 75, 76], "crfm": [15, 41, 75], "load_and_process_state_dict": 15, "alia": [15, 40, 41, 72, 73, 75], "subsequ": [15, 41, 74, 75], "regular": [15, 19, 27], "batchnorm": [15, 74, 75], "mathemat": [15, 19, 74, 75], "w_": 15, "b_": 15, "w": [15, 71], "layernormpr": [15, 29, 32], "eff": 15, "ext": 15, "wise": [15, 39], "computation": [15, 75], "wish": 15, "defin": [15, 19, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 73, 74, 75], "x_1": [15, 75], "x_0": [15, 75], "x_2": [15, 75], "frac": [15, 75], "x_3": 15, "cdot": 15, "x_4": 15, "preced": [15, 73, 74, 75], "never": [15, 75], "w_write": 15, "keepdim": 15, "fed": [15, 39], "1000": [15, 38, 73, 75], "recreat": 15, "onto": [15, 41, 74], "By": [15, 38, 40, 41, 43, 73, 74, 75], "mix": [15, 73, 74, 75], "linearli": 15, "technic": [15, 74, 75], "deriv": [15, 75], "broadcast_b_v": 15, "broadcast": 15, "And": [15, 43, 74, 75], "destination_posit": [15, 75], "source_posit": [15, 75], "source_": 15, "destin": [15, 16, 43, 75], "behavior": [15, 16, 41, 74], "resolut": [15, 41], "cfg_dict": [15, 41], "cache_dir": [15, 73], "torch_dtyp": 15, "bfloat16": 15, "boolean": [15, 40, 43, 73, 74, 75], "hidden_s": 15, "use_past_kv_cach": 15, "pos_plus_new_token": 15, "precomput": [15, 33], "speed": [15, 74], "applic": [15, 16, 73, 74], "get_pos_offset": 15, "get_residu": 15, "pos_offset": 15, "return_shortformer_pos_emb": 15, "get_token_posit": [15, 74, 75], "single_token": [15, 75], "present": 15, "gotcha": [15, 17, 74], "Be": 15, "care": [15, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 74, 75], "weird": [15, 16, 74, 75], "carefulli": [15, 74], "dummi": [15, 40, 75], "init_weight": [15, 16], "empti": [15, 40], "bulk": 15, "seed": [15, 16, 67, 75], "determin": [15, 19, 43, 72, 73, 74, 75], "NOT": [15, 40, 73, 75], "scheme": 15, "tell": [15, 38, 74, 75], "round": [15, 38, 74, 75], "18182": 15, "fan_in": [15, 73], "tha": 15, "kaim": [15, 73], "despit": [15, 75], "xavier": [15, 73], "fan_out": 15, "transformerencod": 15, "exact": 15, "72253": 15, "mup": [15, 16], "haven": 15, "2203": 15, "03466": 15, "input_to_emb": 15, "redwood": [15, 74, 75], "load_sample_training_dataset": 15, "dataset": [15, 38, 67, 73, 75], "10k": [15, 38, 73], "get_dataset": [15, 73], "info": [15, 16, 43, 73, 75], "download": [15, 73, 75], "locat": [15, 43, 74, 75], "pt": 15, "openwebtext": [15, 38, 73], "karma": [15, 38], "reddit": [15, 38], "pile": [15, 38, 41, 73, 75, 76], "imperfectli": 15, "suppli": 15, "valid": [15, 38, 74], "loss_fn": [15, 75], "per_token": [15, 73, 75], "lm_cross_entropy_loss": [15, 73], "move_model_modules_to_devic": 15, "process_weights_": 15, "cleaner": 15, "experiment": 15, "argu": [15, 75], "somewhat": [15, 74, 75], "w_qk": [15, 19, 75], "w_ov": [15, 19, 75], "hopefulli": [15, 77], "column": [15, 43, 73], "rotat": [15, 16, 19, 75], "nth": 15, "formula": 15, "r": 15, "refactor": 15, "diagon": [15, 74, 75], "asymmetri": 15, "fiddli": 15, "preserv": [15, 74, 75], "bilinear": [15, 75], "dimension": [15, 16], "coordin": 15, "sample_datapoint": 15, "implicitli": [15, 43, 75], "hasn": 15, "manual": [15, 73, 75], "replac": [15, 16, 43, 74, 75, 77], "choic": [15, 74], "set_token": [15, 16], "pretrainedtoken": 15, "set_ungroup_grouped_query_attent": 15, "ungroup_grouped_query_attent": [15, 16], "ungroup": [15, 16], "gqa": 15, "set_use_attn_in": 15, "use_attn_in": [15, 16], "set_use_attn_result": 15, "easili": [15, 73, 74, 75], "burn": 15, "set_use_hook_mlp_in": 15, "use_hook_mlp_in": [15, 16], "set_use_split_qkv_input": 15, "use_split_qkv_input": [15, 16], "to_single_str_token": 15, "int_token": 15, "uncertain": 15, "to_str_token": [15, 17, 74, 75], "weirdli": [15, 74, 75], "gotcha2": 15, "letter": [15, 75], "capit": [15, 74, 75], "shoot": [15, 75], "gotcha3": 15, "exce": 15, "str_token": [15, 74], "to_str": [15, 74, 75], "numpi": [15, 16, 73, 74], "arrai": [15, 17, 73], "tokens_to_residual_direct": [15, 74], "mislead": [15, 74], "residual_direct": 15, "namedtupl": 15, "dataclass": [16, 40], "act_fn": [16, 76], "ep": 16, "1e": [16, 41], "05": [16, 41], "use_attn_scal": 16, "attn_scal": 16, "use_qk_norm": 16, "use_local_attn": 16, "original_architectur": 16, "from_checkpoint": 16, "checkpoint_label_typ": [16, 75], "window_s": [16, 19, 20, 27], "attn_typ": [16, 19, 20, 27, 33], "init_mod": 16, "normalization_typ": 16, "attention_dir": 16, "attn_onli": [16, 76], "initializer_rang": 16, "scale_attn_by_inverse_layer_idx": 16, "final_rm": 16, "d_vocab_out": [16, 37], "parallel_attn_mlp": 16, "rotary_dim": [16, 19], "n_param": [16, 76], "use_hook_token": 16, "gated_mlp": 16, "tokenizer_prepends_bo": 16, "n_key_value_head": [16, 27, 76], "post_embedding_ln": 16, "rotary_bas": 16, "10000": [16, 19, 75], "trust_remote_cod": 16, "rotary_adjacent_pair": 16, "load_in_4bit": 16, "num_expert": 16, "experts_per_token": 16, "relative_attention_max_dist": 16, "relative_attention_num_bucket": 16, "decoder_start_token_id": 16, "tie_word_embed": 16, "use_normalization_before_and_aft": 16, "attn_scores_soft_cap": 16, "output_logits_soft_cap": 16, "use_ntk_by_parts_rop": 16, "ntk_by_parts_low_freq_factor": 16, "ntk_by_parts_high_freq_factor": 16, "ntk_by_parts_factor": 16, "8": [16, 19, 38, 39, 74, 75, 76], "ntk_original_ctx_len": 16, "8192": [16, 76], "AND": 16, "feedforward": 16, "network": [16, 74, 75], "vocab": 16, "lowercas": 16, "relu": [16, 73, 76], "gelu": [16, 41, 73, 75, 76], "silu": [16, 76], "gelu_new": [16, 73], "gelu_fast": [16, 73], "epsilon": 16, "5": [16, 19, 38, 39, 41, 43, 73, 74, 75, 76], "THEN": 16, "intens": 16, "divid": [16, 39, 73, 74], "distanc": [16, 19, 74], "xavier_uniform": 16, "xavier_norm": 16, "kaiming_uniform": 16, "kaiming_norm": 16, "rmspre": 16, "pipelin": 16, "parallel": [16, 73, 74], "aka": 16, "unidirect": 16, "bidirect": [16, 75], "gain": [16, 73], "layer_id": [16, 19, 20, 27, 33], "numer": [16, 17, 19, 20, 27, 75], "stabil": [16, 19, 20, 27, 75], "fp16": 16, "rotari": [16, 19], "blog": [16, 19], "eleuth": [16, 19, 73, 75], "res_stream": 16, "sinusoid": 16, "dumb": 16, "mainli": 16, "curs": 16, "init": 16, "law": 16, "pdf": [16, 19, 35, 38], "2001": 16, "08361": 16, "Will": [16, 43], "interven": [16, 40, 43, 74], "add_bos_token": [16, 73], "bitsandbyt": 16, "moe": 16, "bucket": 16, "tie": 16, "gemma": [16, 41, 45, 76], "softcap": 16, "soft_cap": 16, "tanh": 16, "squash": 16, "interv": [16, 39], "ntk": 16, "interpol": 16, "2309": 16, "00071": 16, "threshold": 16, "high": [16, 73, 74, 75], "rate": [16, 67, 75], "strategi": [16, 75], "from_dict": 16, "config_dict": 16, "is_layer_norm_activ": 16, "set_seed_everywher": 16, "to_dict": 16, "unwrap": [16, 73], "duplic": [16, 39, 74, 75], "get_singular_vector": 17, "vector_typ": 17, "num_vector": 17, "plot": [17, 75], "pysvelt": [17, 75], "instabl": 17, "d": [17, 38, 39, 41, 74, 76], "medium": [17, 41, 76], "svd_interpret": 17, "22": [17, 38, 73, 74, 75], "all_token": 17, "np": [17, 73, 74], "def": [17, 74, 75], "plot_matrix": 17, "filter": [17, 40, 41, 73, 75], "topk": [17, 74], "topktabl": 17, "obj_typ": 17, "abstract_attent": 18, "bert_block": 18, "bert_emb": 18, "bert_mlm_head": 18, "bert_nsp_head": 18, "bert_pool": 18, "grouped_query_attent": 18, "layer_norm": [18, 74], "layer_norm_pr": 18, "rms_norm": 18, "rms_norm_pr": 18, "t5_attent": 18, "t5_block": 18, "token_typed_emb": 18, "transformer_block": 18, "abstractattent": [19, 20, 27, 33], "abc": [19, 40, 75], "pure": 19, "glossari": 19, "sorri": 19, "underli": [19, 43, 74, 75], "destination_residu": 19, "destination_po": 19, "source_po": [19, 75], "abstract": [19, 74, 75], "groupedqueryattent": [19, 27], "enforc": 19, "child": 19, "better_abc": 19, "abstract_attribut": 19, "stackoverflow": 19, "question": [19, 74, 75], "23831510": 19, "256": [19, 20, 27, 75, 76], "alibi": 19, "apply_causal_mask": 19, "pos_plus_past_kv_pos_offset": 19, "past_kv_pos_offset": [19, 30, 73], "offset_po": [19, 30, 36, 73], "apply_rotari": 19, "calculate_attention_scor": [19, 27], "calculate_qkv_matric": [19, 27], "query_input": [19, 27], "key_input": [19, 27], "kv_po": [19, 33, 34], "value_input": [19, 27], "calculate_sin_cos_rotari": 19, "sine": 19, "cosin": 19, "wave": 19, "inexplic": 19, "adjac": [19, 74], "neox": [19, 41, 45, 75, 76], "clue": [19, 74], "resolv": 19, "calculate_z_scor": [19, 27], "static": [19, 38], "create_alibi_bia": 19, "head_idx": 19, "2108": 19, "12409": 19, "broad": [19, 74], "proport": [19, 73], "distant": 19, "0000": [19, 74], "0625": 19, "1250": 19, "1875": 19, "0039": 19, "0078": 19, "0117": 19, "create_alibi_multipli": 19, "geometr": 19, "ratio": [19, 73, 74, 75], "16": [19, 73, 74, 75, 76], "5000": 19, "2500": [19, 74], "0312": 19, "0156": 19, "7071": 19, "3536": 19, "1768": 19, "0884": 19, "0442": 19, "0221": 19, "0110": 19, "0055": 19, "create_alibi_slop": 19, "slope": 19, "triangl": 19, "lower": [19, 38, 39, 73, 74, 75], "bottom": [19, 75], "corner": 19, "kv_head_index": [19, 27], "past_kv_cache_entri": [19, 34, 36], "hookedtransformerkeyvaluecacheentri": [19, 34, 36, 42], "additive_attention_mask": [19, 21, 34], "position_bia": [19, 33, 34], "irrelev": [19, 74, 75], "past": [19, 42, 74], "k_norm": 19, "q_norm": 19, "rotary_co": 19, "rotary_sin": 19, "rotate_every_two": 19, "x0": 19, "x1": 19, "mistal": [20, 27], "bertblock": 21, "transformerblock": [21, 36], "except": [21, 74, 75], "overridden": [21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 73], "subclass": [21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40], "recip": [21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40], "afterward": [21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40], "former": [21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40], "regist": [21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40], "latter": [21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40, 75], "silent": [21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 37, 40], "bertemb": 22, "input_id": 22, "mlm": 23, "bertmlmhead": 23, "purpos": [23, 24, 25, 38, 74, 75], "bertnsphead": 24, "bertpool": 25, "suitabl": 25, "2305": 27, "13245": 27, "hood": 27, "_w_k": 27, "_w_v": 27, "getter": 27, "similarli": 27, "kept": 27, "repeat_interleav": 27, "unexpand": 27, "expan": 27, "n_query_head": 27, "gpa": 27, "normalis": [29, 74], "posemb": 30, "new_po": 30, "root": [31, 32, 75], "rmsnormpr": 32, "t5attent": [33, 34], "has_relative_attention_bia": 33, "feed": [33, 38, 73, 75], "positional_bia": 33, "compute_relative_attention_bia": 33, "query_len": 33, "key_len": 33, "query_length": 33, "key_length": 33, "bin": 33, "t5block": 34, "block_index": [34, 36], "is_decod": 34, "t5layernorm": 34, "inst": 34, "usual": 34, "encoder_additive_attention_mask": 34, "encoder_po": 34, "encoder_hidden_st": 34, "_description_": 34, "_type_": [34, 40], "tokentypeemb": 35, "1810": 35, "04805": 35, "apply_mlp": 36, "normalized_resid": 36, "central": [36, 74], "positional_embeddings_typ": 36, "canbeusedasmlp": 36, "evalu": [38, 40, 74, 75], "rough": [38, 75], "cheapli": 38, "roughli": [38, 74, 75], "baselin": 38, "ioidataset": 38, "noun": 38, "num_sampl": 38, "symmetr": 38, "ioi_ev": 38, "476": 38, "met": 38, "alic": 38, "bob": 38, "charli": 38, "ball": [38, 74], "book": 38, "397": 38, "get_default_nam": 38, "get_default_noun": 38, "get_default_templ": 38, "get_sampl": 38, "evaluate_on_dataset": 38, "data_load": 38, "induction_loss": [38, 75], "subseq_len": 38, "384": [38, 75], "io": [38, 39, 74, 75], "accuraci": [38, 39, 73], "make_code_data_load": 38, "codeparrot": [38, 73], "dump": 38, "presum": [38, 74], "make_owt_data_load": 38, "corpu": [38, 73], "make_pile_data_load": 38, "eleutherai": [38, 41], "english": [38, 75, 77], "academ": 38, "internet": [38, 75], "make_wiki_data_load": 38, "wikitext": 38, "wikipedia": [38, 73, 75], "articl": [38, 73, 74, 75], "bother": 38, "quarantin": 38, "nowadai": 38, "leakag": 38, "though": [38, 73, 74, 75], "sanity_check": 38, "paragraph": [38, 75], "zoom": [38, 43, 74], "quick": [38, 39, 75], "saniti": [38, 74], "ok": [38, 74, 75], "gone": [38, 74, 75], "wrong": [38, 40, 74], "compute_head_attention_similarity_scor": 39, "attention_pattern": [39, 75], "detection_pattern": 39, "exclude_bo": 39, "exclude_current_token": 39, "error_measur": 39, "mul": 39, "exclude_bcurrent_token": 39, "detect_head": 39, "seq": [39, 73], "previous_token_head": 39, "duplicate_token_head": 39, "induction_head": 39, "headnam": 39, "straightforward": [39, 74], "fraction": 39, "alloc": 39, "prohibit": [39, 75], "cours": [39, 74], "raw": [39, 74], "perfect": [39, 74], "examin": 39, "switch": 39, "advantag": 39, "closer": 39, "head_nam": 39, "ntensor": 39, "ioi": [39, 74, 75], "spacifi": 39, "analyz": 39, "paid": [39, 74, 75], "get_duplicate_token_head_detection_pattern": 39, "dynalist": 39, "n2zwtnoyhru1s4vnfsaq519j": 39, "2ukvedzonghl5uhugvhroxeo": 39, "get_induction_head_detection_pattern": 39, "_tfvup5csv5orithmqwj0gsi": 39, "get_previous_token_head_detection_pattern": 39, "0o5vohe9xezn8ertywkh7ioc": 39, "get_supported_head": 39, "hookfunct": 40, "_hookfunctionprotocol": 40, "inspir": [40, 75, 77], "garcon": [40, 75, 77], "ident": [40, 73, 74, 75], "wrap": [40, 75], "add_hook": [40, 74], "bwd": 40, "fn": 40, "hook_nam": 40, "add_perma_hook": [40, 75], "clear_context": 40, "remove_hook": 40, "including_perman": 40, "interfac": [40, 75, 77], "nice": [40, 74], "run_with_hook": [40, 74, 75], "temporari": [40, 73, 75], "debug": [40, 41, 67], "intent": 40, "reset_hook": [40, 75], "goe": [40, 74, 75], "reset_hooks_end": [40, 74], "add_caching_hook": 40, "names_filt": [40, 74, 75], "callabl": [40, 43], "incl_bwd": 40, "namesfilt": 40, "lambda": [40, 74, 75], "cache_som": 40, "check_and_add_hook": 40, "get_caching_hook": 40, "fwd_hook": [40, 74, 75], "bwd_hook": 40, "hook_dict": 40, "exit": [40, 73], "clear": [40, 75], "reset": 40, "my_hook": 40, "hooked_loss": 40, "mod_dict": 40, "remove_all_hook_fn": 40, "model_kwarg": 40, "degrad": 40, "lenshandl": 40, "removablehandl": 40, "context_level": 40, "hold": 40, "perman": 40, "768": [41, 74, 75, 76], "layer_norm_ep": 41, "init_rang": 41, "02": 41, "1024": [41, 73, 75, 76], "3072": [41, 75, 76], "12": [41, 74, 75, 76], "model_alias": 41, "01": 41, "yi": [41, 76], "34b": [41, 76], "6b": [41, 75, 76], "arthurconmi": 41, "redwood_attn_2l": [41, 76], "baidicoot": 41, "3b": [41, 75, 76], "125m": [41, 75, 76], "20b": [41, 75, 76], "pythia": [41, 76], "4b": [41, 76], "dedup": [41, 76], "12b": [41, 76], "13b": [41, 75, 76], "14m": [41, 76], "160m": [41, 76], "seed1": [41, 76], "seed2": [41, 76], "seed3": [41, 76], "1b": [41, 76], "800m": 41, "8b": [41, 75, 76], "31m": [41, 76], "410m": [41, 76], "350m": 41, "9b": [41, 76], "70m": [41, 76], "19m": [41, 76], "2l512w": 41, "lr": [41, 67], "attn_only_1l512w_c4_cod": 41, "c4": [41, 73, 75], "attn_only_2l512w_c4_cod": 41, "attn_only_3l512w_c4_cod": 41, "attn_only_4l512w_c4_cod": 41, "gelu_1l512w_c4_cod": 41, "gelu_2l512w_c4_cod": 41, "gelu_3l512w_c4_cod": 41, "gelu_4l512w_c4_cod": 41, "solu_10l1280w_c4_cod": 41, "10l": [41, 75, 76], "solu_10l_v22_old": 41, "solu_12l1536w_c4_cod": 41, "12l": [41, 75, 76], "solu_12l_v23_old": 41, "solu_1l512w_c4_cod": 41, "solu_1l512w_wiki_finetun": 41, "wiki": [41, 73, 74, 75, 76], "finetun": 41, "solu_1l_v9_old": 41, "solu_2l512w_c4_cod": 41, "solu_2l_v10_old": 41, "solu_3l512w_c4_cod": 41, "solu_4l512w_c4_cod": 41, "solu_4l512w_wiki_finetun": 41, "solu_4l_v11_old": 41, "solu_6l768w_c4_cod": 41, "6l": [41, 75, 76], "solu_6l_v13_old": 41, "solu_8l1024w_c4_cod": 41, "8l": [41, 75, 76], "solu_8l_v21_old": 41, "qwen": [41, 45, 64, 65, 76], "qwq": 41, "32b": [41, 76], "preview": [41, 76], "14b": [41, 76], "1_8b": 41, "qwen1": [41, 76], "5b": [41, 75, 76], "qwen2": [41, 45, 76], "72b": [41, 76], "qwen3": [41, 45, 76], "forev": 41, "mgpt": [41, 76], "bigcod": 41, "santacod": [41, 76], "bigscienc": 41, "1b1": [41, 76], "1b7": [41, 76], "560m": [41, 76], "7b1": [41, 76], "codellama": [41, 76], "hf": 41, "codellamallama": [41, 76], "distilgpt2": [41, 75], "distillgpt2": [41, 76], "distil": [41, 75], "facebook": 41, "xxl": 41, "30b": [41, 75, 76], "xxxl": 41, "xl": [41, 75, 76], "66b": [41, 75, 76], "xxxxl": 41, "uncas": [41, 76], "27b": [41, 76], "2b": [41, 76], "65b": [41, 76], "70b": [41, 76], "microsoft": 41, "phi": [41, 45, 62, 76], "mini": 41, "4k": 41, "1_5": [41, 76], "nemo": [41, 76], "2407": [41, 76], "roneneldan": 41, "tinystori": 41, "1layer": 41, "21m": [41, 76], "28m": [41, 76], "2layer": 41, "33m": [41, 76], "3m": [41, 76], "8m": [41, 76], "instuct": 41, "stabilityai": 41, "stablelm": [41, 75, 76], "alpha": [41, 76], "x21": 41, "arwen": 41, "battlestar": 41, "x49": 41, "beren": 41, "caprica": 41, "x81": 41, "celebrimbor": 41, "darkmatt": 41, "x343": 41, "durin": 41, "eowyn": 41, "x777": 41, "expans": 41, "alias": 41, "non_hf_hosted_model_nam": 41, "24b": [41, 76], "2501": [41, 76], "get_checkpoint_label": [41, 75], "label_typ": 41, "get_num_params_of_pretrain": 41, "suffici": [41, 74], "get_pretrained_model_config": 41, "hf_cfg": 41, "automodel": 41, "autoconfig": 41, "infrastructur": [41, 74, 75, 77], "ourselv": [42, 73, 75, 77], "previous_attention_mask": 42, "pos_so_far": 42, "prefix": 42, "append_attention_mask": 42, "freez": 42, "init_cach": 42, "unfreez": 42, "past_kei": 42, "jaxtyp": [42, 74, 75], "past_valu": 42, "new_kei": 42, "new_valu": 42, "init_cache_entri": 42, "structur": [43, 75], "generic_activation_patch": 43, "specialis": [43, 74], "introduc": [43, 74], "rome": [43, 74, 75], "baulab": 43, "corrupt": [43, 74, 75], "localis": [43, 74, 75], "__from__": 43, "__to": 43, "__the": 43, "confid": [43, 74, 75], "intuit": [43, 74, 75], "diffus": [43, 74], "spread": [43, 74], "connect": [43, 74], "ultim": [43, 74], "tend": [43, 75], "extrem": [43, 74, 75, 77], "eiffel": 43, "tower": 43, "pari": 43, "factual": [43, 74], "recal": [43, 74], "colosseum": 43, "corrupted_token": [43, 74, 75], "clean_cach": [43, 74, 75], "patching_metr": 43, "patch_sett": 43, "index_axis_nam": 43, "src_po": [43, 74], "dest_po": [43, 74, 75], "index_df": 43, "datafram": 43, "return_index_df": 43, "counterfactu": [43, 74, 75], "Then": 43, "index_to_act_nam": 43, "recov": [43, 74, 75], "diff": [43, 74], "corrupted_activ": 43, "chunk": 43, "fill": 43, "flatten": [43, 74, 75], "patched_output": 43, "get_act_patch_attn_head_all_pos_everi": 43, "patch_typ": 43, "get_act_patch_attn_head_by_pos_everi": 43, "get_act_patch_attn_head_k_all_po": 43, "corruptedactiv": 43, "patchedactiv": 43, "layer_head_vector_patch_sett": 43, "axisnam": 43, "get_act_patch_attn_head_k_by_po": 43, "layer_pos_head_vector_patch_sett": 43, "get_act_patch_attn_head_out_all_po": 43, "get_act_patch_attn_head_out_by_po": 43, "get_act_patch_attn_head_pattern_all_po": 43, "layer_head_pattern_patch_sett": 43, "get_act_patch_attn_head_pattern_by_po": 43, "layer_head_pos_pattern_patch_sett": 43, "get_act_patch_attn_head_pattern_dest_src_po": 43, "layer_head_dest_src_pos_pattern_patch_sett": 43, "get_act_patch_attn_head_q_all_po": 43, "get_act_patch_attn_head_q_by_po": 43, "get_act_patch_attn_head_v_all_po": 43, "get_act_patch_attn_head_v_by_po": 43, "get_act_patch_attn_out": 43, "layer_pos_patch_sett": 43, "get_act_patch_block_everi": 43, "get_act_patch_mlp_out": 43, "get_act_patch_resid_mid": 43, "get_act_patch_resid_pr": 43, "clean_activ": 43, "weight_convers": 44, "coder": 45, "mingpt": 45, "nanogpt": 45, "neel_solu_old": 45, "phi3": 45, "convert_bloom_weight": 47, "convert_coder_weight": 48, "convert_mistral_weight": 54, "convert_mixtral_weight": 55, "convert_phi_weight": 61, "convert_phi3_weight": 62, "convert_qwen_weight": 63, "convert_qwen2_weight": 64, "convert_qwen3_weight": 65, "convert_t5_weight": 66, "hookedtransformertrainconfig": 67, "num_epoch": 67, "001": 67, "max_grad_norm": 67, "weight_decai": 67, "optimizer_nam": 67, "adam": 67, "warmup_step": 67, "save_everi": 67, "save_dir": 67, "wandb": 67, "wandb_project_nam": 67, "print_everi": 67, "max_step": 67, "hyperparamet": [67, 73], "epoch": 67, "decai": 67, "warmup": 67, "wandb_project": 67, "termin": 67, "activation_funct": 68, "addmm": 68, "batch_addmm": 70, "d_out": [70, 73], "d_in": [70, 73], "fuse": 70, "conv1d": 70, "9ba9369a2557e53a01378199a9839ec6e82d8bc7": 70, "src": 70, "pytorch_util": 70, "l102": 70, "l106": 70, "vanilla_addmm": 70, "mat1": 70, "mat2": 70, "typecheck": 70, "complex_attn_linear": 71, "almost": [71, 74], "simple_attn_linear": 71, "extra": [71, 73], "assist": 72, "availabledevicememori": 72, "calculate_available_device_cuda_memori": 72, "determine_available_memory_for_available_devic": 72, "max_devic": 72, "precalcul": 72, "get_best_available_cuda_devic": 72, "whichev": 72, "environmenterror": 72, "get_best_available_devic": 72, "get_device_for_block_index": 72, "target": 72, "account": [72, 74], "move_to_and_update_config": 72, "sort_devices_based_on_available_memori": 72, "vari": [73, 74], "throughout": [73, 75], "locallyoverridendefault": 73, "restor": 73, "overriden": 73, "input_slic": 73, "syntax": [73, 74, 75], "reduc": [73, 74, 75], "leav": [73, 75], "elif": 73, "1d": 73, "sliceinput": 73, "abov": [73, 74, 75], "max_ctx": 73, "int32": 73, "slice_input": 73, "calc_fan_in_and_fan_out": 73, "fan": 73, "composition_scor": 73, "broadcast_dim": 73, "leading_dims_left_and_right": 73, "download_file_from_hf": 73, "repo_nam": 73, "file_nam": 73, "subfold": 73, "home": 73, "runner": 73, "hub": 73, "force_is_torch": 73, "json": [73, 74], "pth": 73, "extens": [73, 74], "gelu_pytorch_tanh": [73, 76], "hack": [73, 75], "stuff": [73, 75], "digit": [73, 75], "appear": [73, 75], "hook_k": [73, 75], "hook_pr": [73, 75], "27": [73, 74, 75], "hook_norm": [73, 75], "k6": 73, "scale4ln1": 73, "pre5": 73, "get_attention_mask": 73, "leftmost": 73, "rightmost": 73, "consid": 73, "get_cumsum_along_dim": 73, "dataset_nam": 73, "000": [73, 75], "enorm": [73, 75], "100gb": 73, "2tb": 73, "effort": [73, 74], "dataload": 73, "fanci": 73, "data_dir": 73, "approx": [73, 74, 75], "ton": [73, 77], "divers": [73, 74, 75], "coloss": 73, "crawl": 73, "bigger": 73, "c4_code": 73, "friendli": 73, "22m": [73, 75], "5m": 73, "20220301": 73, "en": [73, 75], "get_devic": [73, 74, 75], "get_input_with_manually_prepended_bo": 73, "get_nested_attr": 73, "obj": 73, "attr_str": 73, "nest": 73, "hierarchi": 73, "get_offset_position_id": 73, "offset": [73, 74, 75], "get_tokenizer_with_bo": 73, "Such": [73, 74], "llamatoken": 73, "get_tokens_with_bos_remov": 73, "init_kaiming_normal_": 73, "nonlinear": 73, "std": 73, "init_kaiming_uniform_": 73, "init_xavier_normal_": 73, "init_xavier_uniform_": 73, "is_lower_triangular": 73, "is_squar": 73, "keep_single_column": 73, "col_nam": 73, "lm_accuraci": 73, "seq_len": [73, 74, 75], "altern": 73, "override_or_use_default_valu": 73, "default_flag": 73, "print_gpu_mem": 73, "step_nam": 73, "repeat_along_head_dimens": 73, "clone_tensor": 73, "sample_logit": 73, "final_logit": [73, 74], "argmaxi": 73, "90": 73, "renormalis": 73, "mutual": 73, "neither": [73, 74], "input_token": 73, "todo": 73, "edg": 73, "randn": [73, 75], "uniqu": 73, "return_count": 73, "set_nested_attr": 73, "prepend_space_to_answ": 73, "eleph": 73, "endoftext": [73, 74, 75], "14": [73, 74, 75, 76], "51": [73, 75], "0th": [73, 74], "59": [73, 75, 76], "ground": [73, 74], "1th": [73, 74], "41": [73, 75], "tree": 73, "2th": [73, 74], "3th": [73, 74], "45": [73, 75], "car": 73, "4th": [73, 74], "13": [73, 74, 75], "92": [73, 74], "55": [73, 74, 75], "river": 73, "5th": [73, 74], "79": 73, "25": [73, 74, 75, 76], "street": 73, "6th": [73, 74], "77": 73, "21": [73, 74, 75], "7th": [73, 74], "75": 73, "hill": 73, "8th": [73, 74], "swing": 73, "9th": [73, 74], "46": [73, 75, 76], "61": [73, 75, 76], "park": [73, 74], "to_numpi": [73, 74, 75], "tokenize_and_concaten": 73, "max_length": 73, "column_nam": 73, "num_proc": 73, "eo": [73, 75], "reshap": [73, 74], "____": 73, "drop": [73, 75], "faster": [73, 74, 75], "parallelis": [73, 75], "chop": 73, "privileg": 73, "earli": [73, 75], "cnn": [73, 75], "bos_token_id": 73, "swap": [73, 74], "runtim": [74, 75], "hardwar": [74, 75], "pane": [74, 75], "sidebar": [74, 75], "navig": [74, 75], "vscode": [74, 75], "outlin": 74, "tab": 74, "dropdown": [74, 75], "arrow": [74, 75], "page": [74, 75], "ctrl": [74, 75], "in_colab": [74, 75], "circuitsvi": [74, 75], "node": [74, 75], "curl": [74, 75], "fssl": [74, 75], "deb": [74, 75], "nodesourc": [74, 75], "setup_16": [74, 75], "sudo": [74, 75], "bash": [74, 75], "apt": [74, 75], "nodej": [74, 75], "noqa": [74, 75], "ipython": [74, 75], "get_ipython": [74, 75], "ip": [74, 75], "extension_manag": [74, 75], "autoreload": [74, 75], "functool": [74, 75], "plotli": [74, 75], "express": [74, 75], "px": [74, 75], "pio": [74, 75], "attention_head": 74, "fancy_einsum": [74, 75], "ifram": 74, "differenti": [74, 75], "simplic": 74, "imshow": [74, 75], "color_continuous_midpoint": [74, 75], "color_continuous_scal": [74, 75], "rdbu": [74, 75], "scatter": [74, 75], "xaxi": [74, 75], "yaxi": [74, 75], "caxi": [74, 75], "color": [74, 75], "principl": [74, 75, 77], "fun": [74, 75, 77], "gap": [74, 75, 77], "plai": [74, 75, 77], "flow": [74, 75, 77], "toolkit": [74, 75], "stylist": 74, "slowli": 74, "convei": 74, "tag": 74, "asid": 74, "flavour": 74, "weed": 74, "star": 74, "capabl": [74, 75], "interview": 74, "kevin": [74, 75], "wang": 74, "twitter": 74, "thread": 74, "overview": 74, "bottl": [74, 75], "milk": [74, 75], "26": [74, 75, 76], "Their": 74, "skimp": 74, "rigour": 74, "suggest": 74, "evid": 74, "80m": [74, 75], "simplif": 74, "nbval_ignore_output": [74, 75], "stabl": 74, "example_prompt": 74, "example_answ": 74, "39": [74, 75], "lt": [74, 75], "gt": [74, 75], "09": [74, 75], "70": 74, "07": [74, 75], "38": [74, 75], "67": 74, "35": [74, 75], "54": [74, 75], "11": [74, 75, 76], "84": [74, 75], "73": 74, "hi": [74, 75], "06": 74, "her": 74, "74": 74, "52": [74, 75, 76], "49": [74, 75], "jesu": 74, "97": 74, "42": [74, 75, 76], "him": 74, "subword": 74, "frequent": 74, "substr": [74, 75], "headach": 74, "annoi": [74, 75], "devot": 74, "sensibl": 74, "later": [74, 75], "wherev": 74, "flesh": 74, "prompt_format": 74, "jame": 74, "dan": 74, "sid": 74, "appl": 74, "martin": 74, "ami": 74, "drink": 74, "correct_token": 74, "insert": 74, "filler": 74, "newlin": 74, "intellig": 74, "complic": 74, "aggreg": 74, "original_logit": 74, "upon": 74, "subject": [74, 75], "logits_to_ave_logit_diff": 74, "per_prompt": 74, "answer_logit": 74, "gather": 74, "answer_logit_diff": 74, "detach": [74, 75], "decim": [74, 75], "original_average_logit_diff": 74, "3370": 74, "2020": 74, "7090": 74, "7970": 74, "7200": 74, "2810": 74, "6010": 74, "7670": 74, "552": 74, "33": [74, 75], "dive": 74, "spend": [74, 75], "engag": 74, "decent": [74, 75], "hypothes": 74, "cheat": [74, 75], "hypothesi": 74, "scienc": 74, "belief": 74, "trap": 74, "flounder": 74, "dogmat": 74, "overconfid": 74, "unwil": 74, "contradict": 74, "flinch": 74, "disconfirm": 74, "focu": 74, "primit": 74, "nearbi": 74, "came": 74, "trigram": 74, "symmetri": 74, "cancel": 74, "inhibit": 74, "spoiler": 74, "simplist": 74, "importantli": [74, 75], "perfectli": [74, 75], "final_residual_stream": 74, "eleg": 74, "particularli": 74, "aspect": 74, "nicer": 74, "inde": 74, "log_prob": 74, "log_softmax": 74, "logsumexp": 74, "decid": 74, "pronoun": 74, "refin": 74, "friendlier": 74, "answer_residual_direct": 74, "logit_diff_direct": 74, "w_u_fold": 74, "unigram": [74, 75], "statist": [74, 75], "opposit": 74, "hook_normalis": 74, "sub_layer_typ": 74, "final_token_residual_stream": 74, "scaled_final_token_residual_stream": 74, "average_logit_diff": 74, "residual_stack_to_logit_diff": 74, "scaled_residual_stack": 74, "fascinatingli": 74, "utterli": 74, "unabl": 74, "hover": [74, 75], "n_pre": 74, "n_mid": 74, "n_post": 74, "middl": [74, 75], "accumulated_residu": 74, "logit_lens_logit_diff": 74, "arang": 74, "hover_nam": [74, 75], "vnd": 74, "terminologi": 74, "overload": 74, "kth": 74, "per_layer_residu": 74, "per_layer_logit_diff": 74, "independ": [74, 75, 77], "l9h6": 74, "l9h9": 74, "l10h7": 74, "l11h10": 74, "harm": 74, "strongli": 74, "observ": [74, 75], "144": 74, "claim": 74, "surpris": 74, "7x": 74, "per_head_residu": 74, "per_head_logit_diff": 74, "rearrang": 74, "weren": 74, "alan": [74, 75], "coonei": [74, 75], "illustr": [74, 75], "mistak": 74, "mayb": [74, 75], "sai": [74, 75], "summari": 74, "sole": 74, "visualize_attention_pattern": 74, "local_cach": 74, "local_token": 74, "max_width": 74, "700": 74, "isinst": 74, "batch_index": 74, "combin": [74, 75], "attention_head_nam": 74, "show_cod": 74, "title_html": 74, "br": 74, "div": 74, "width": [74, 75], "top_positive_logit_attr_head": 74, "positive_html": 74, "top_negative_logit_attr_head": 74, "negative_html": 74, "conceptu": 74, "clearli": 74, "compos": [74, 75], "ideal": [74, 75], "david": [74, 75], "bau": [74, 75], "meng": [74, 75], "trace": [74, 75], "anim": 74, "lai": 74, "pro": 74, "con": 74, "Or": 74, "bake": 74, "claus": 74, "tack": 74, "gaussian": 74, "nois": 74, "beforehand": 74, "19": [74, 75], "corrupted_prompt": [74, 75], "corrupted_logit": [74, 75], "corrupted_cach": 74, "corrupted_average_logit_diff": 74, "temporarili": [74, 75], "patch_residual_compon": 74, "corrupted_residual_compon": 74, "normalize_patched_logit_diff": 74, "patched_logit_diff": [74, 75], "wors": [74, 75], "patched_residual_stream_diff": 74, "hook_fn": 74, "patched_logit": [74, 75], "abus": 74, "prompt_position_label": 74, "tok": 74, "_": [74, 75], "enumer": [74, 75], "reus": 74, "patched_attn_diff": 74, "patched_mlp_diff": 74, "patched_attn_logit": 74, "patched_attn_logit_diff": 74, "patched_mlp_logit": 74, "patched_mlp_logit_diff": 74, "late": [74, 75], "contrast": 74, "statement": 74, "mlp0": 74, "destroi": 74, "frame": 74, "unprincipl": 74, "invers": [74, 75], "plausibli": 74, "dedic": 74, "overcom": 74, "love": 74, "someon": 74, "patch_head_vector": 74, "corrupted_head_vector": 74, "patched_head_z_diff": 74, "l8h6": 74, "l8h10": 74, "l7h9": 74, "l5h5": 74, "l6h9": 74, "l3h0": 74, "semi": 74, "disentangl": 74, "familiar": 74, "28": [74, 75, 76], "patched_head_v_diff": 74, "heatmap": 74, "29": [74, 75], "lesson": 74, "head_label": 74, "range_x": 74, "range_i": 74, "31": [74, 75], "patch_head_pattern": 74, "corrupted_head_pattern": 74, "patched_head_attn_diff": 74, "32": [74, 75, 76], "reconsolid": 74, "l7h3": 74, "specul": 74, "mysteri": [74, 75], "top_heads_by_output_patch": 74, "first_mid_lay": 74, "first_late_lay": 74, "early_head": 74, "mid_head": 74, "logical_and": 74, "late_head": 74, "diagram": [74, 77], "l1h2": 74, "latest": [74, 75], "definit": 74, "priori": 74, "stroke": 74, "didn": 74, "bracket": 74, "serv": [74, 75], "particip": 74, "behav": 74, "l5h0": 74, "wrote": [74, 75, 77], "overkil": 74, "simpler": 74, "repurpos": 74, "machineri": 74, "life": [74, 75], "built": 74, "34": [74, 75], "example_text": [74, 75], "seek": 74, "machin": [74, 75], "example_repeated_text": 74, "example_repeated_token": 74, "example_repeated_logit": 74, "example_repeated_cach": 74, "induction_head_label": 74, "81": 74, "65": 74, "800": 74, "accord": 74, "wildli": 74, "characteris": 74, "superfici": 74, "boost": [74, 75], "anti": 74, "suppress": [74, 75], "pick": [74, 75], "signal": 74, "hook_": 74, "hook_attn": 74, "token_po": 74, "metadata": 74, "36": [74, 75, 76], "prev_token_scor": 74, "prev_token_hook": 74, "dim1": [74, 75], "dim2": [74, 75], "duplicate_token_scor": 74, "duplicate_token_hook": 74, "induction_scor": [74, 75], "induction_hook": 74, "manual_se": [74, 75], "original_token": 74, "randint": [74, 75], "20000": [74, 75], "repeated_token": [74, 75], "pattern_filt": 74, "act_nam": [74, 75], "endswith": [74, 75], "hook_pattern": [74, 75], "0390": 74, "0310": 74, "1890": 74, "1720": 74, "0680": 74, "1570": 74, "0210": 74, "4820": 74, "0030": 74, "1320": 74, "0050": 74, "0020": 74, "0090": 74, "0040": 74, "0010": 74, "instantli": 74, "37": [74, 75], "seen": [74, 75], "mosaic": 74, "40": [74, 75, 76], "fascin": 74, "knock": 74, "naiv": [74, 75], "convers": 74, "flaw": 74, "knockout": 74, "send": 74, "redund": 74, "job": 74, "underestim": 74, "57": [74, 75], "99": [74, 75], "hook_z": [74, 75], "top_name_mov": 74, "top_name_mover_lay": 74, "top_name_mover_head": 74, "ablate_top_head_hook": 74, "ablated_logit": 74, "ablated_cach": 74, "2f": [74, 75], "l10h10": 74, "margin": 74, "obvious": 74, "per_head_ablated_residu": 74, "per_head_ablated_logit_diff": 74, "04": [74, 75], "uniformli": [74, 75], "042": 74, "5200": 74, "4700": 74, "8200": 74, "5100": 74, "2600": 74, "1800": 74, "4300": 74, "5700": 74, "3500": 74, "2900": 74, "6800": 74, "4900": 74, "8700": 74, "4200": 74, "reader": [74, 75], "gentler": 75, "tip": 75, "development_mod": 75, "in_github": 75, "getenv": 75, "github_act": 75, "render": 75, "argh": 75, "notebook_connect": 75, "cv": 75, "hello": 75, "auto": 75, "autograd": 75, "grad_mod": 75, "0x7fcdf6a88910": 75, "speak": [75, 77], "palm": [75, 77], "nor": [75, 77], "offend": [75, 77], "anthrop": [75, 77], "team": [75, 77], "got": [75, 77], "frustrat": [75, 77], "deepspe": [75, 77], "industri": [75, 77], "heavili": [75, 77], "credit": [75, 77], "nelson": [75, 77], "elhag": [75, 77], "chri": [75, 77], "olah": [75, 77], "model_description_text": 75, "hyper": 75, "1758": 75, "box": 75, "On": 75, "insid": 75, "kinda": 75, "gpt2_cache_no_batch_dim": 75, "gpt2_cach": 75, "gpt2_text": 75, "summar": 75, "supervis": 75, "taskspecif": 75, "gpt2_token": 75, "gpt2_logit": 75, "lock": 75, "grid": 75, "gpt2_str_token": 75, "cell": 75, "attn_hook_nam": 75, "attn_lay": 75, "gpt2_attn_cach": 75, "gpt2_attn": 75, "assert": 75, "neural": 75, "system": 75, "surgic": 75, "surround": 75, "current_activation_valu": 75, "new_activation_valu": 75, "substitut": 75, "relationship": 75, "underr": 75, "janki": 75, "shamelessli": 75, "probepoint": 75, "qualiti": 75, "head_ablation_hook": 75, "layer_to_abl": 75, "head_index_to_abl": 75, "original_loss": 75, "ablated_loss": 75, "3f": 75, "999": 75, "453": 75, "stai": 75, "clean_prompt": 75, "clean_token": 75, "logits_to_logit_diff": 75, "correct_answ": 75, "incorrect_answ": 75, "correct_index": 75, "incorrect_index": 75, "clean_logit": 75, "clean_logit_diff": 75, "corrupted_logit_diff": 75, "276": 75, "738": 75, "residual_stream_patching_hook": 75, "clean_resid_pr": 75, "num_posit": 75, "ioi_patching_result": 75, "temp_hook_fn": 75, "ish": 75, "token_label": 75, "workflow": 75, "michael": 75, "jordan": 75, "surnam": 75, "occurr": 75, "terribl": 75, "halfwai": 75, "input_tensor": 75, "random_token": 75, "repeated_logit": 75, "correct_log_prob": 75, "loss_by_posit": 75, "manipul": 75, "hook_funct": 75, "induction_score_stor": 75, "induction_score_hook": 75, "induction_strip": 75, "pattern_hook_names_filt": 75, "highli": 75, "stripe": 75, "induction_head_lay": 75, "induction_head_index": 75, "single_random_sequ": 75, "repeated_random_sequ": 75, "visualize_pattern_hook": 75, "3d": 75, "four": 75, "300m": 75, "soon": 75, "distilgpt": 75, "distilgpt2_induction_score_stor": 75, "classic": 75, "openai": 75, "85m": [75, 76], "700m": 75, "22b": 75, "300b": 75, "180b": 75, "600": 75, "265": 75, "108m": 75, "bookscorpu": 75, "free": 75, "512": [75, 76], "tractabl": 75, "motif": 75, "80": [75, 76], "shuffl": 75, "scan": 75, "40m": 75, "100m": 75, "200m": 75, "340m": [75, 76], "15b": [75, 76], "13m": [75, 76], "digress": 75, "usefulli": 75, "variengien": 75, "websit": 75, "cleantransformerdemo": 75, "new_activ": 75, "old_activ": 75, "remind": 75, "50267": 75, "named_paramet": 75, "fallback": 75, "spam": 75, "dest_posit": 75, "brown": 75, "fox": 75, "lazi": 75, "dog": 75, "num": 75, "print_name_shape_hook_funct": 75, "not_in_late_block_filt": 75, "hook_q": 75, "hook_v": 75, "hook_attn_scor": 75, "hook_attn_out": 75, "hook_resid_mid": 75, "hook_post": 75, "hook_mlp_out": 75, "hook_resid_post": 75, "preconcept": 75, "overhead": 75, "elementwis": 75, "consequ": 75, "rare": 75, "dramat": 75, "degre": 75, "punctuat": 75, "ass": 75, "randomredditor": 75, "unembed_bia": 75, "bias_valu": 75, "bias_indic": 75, "repr": 75, "03": 75, "98": 75, "68": 75, "48": [75, 76], "47": 75, "72": [75, 76], "44": [75, 76], "82": 75, "\u30b5\u30fc\u30c6\u30a3": 75, "83": 75, "x18": 75, "x14": 75, "\u9f8d": 75, "x1b": 75, "x05": 75, "x00": 75, "x06": 75, "x07": 75, "x0c": 75, "x02": 75, "oreandonlin": 75, "x11": 75, "x10": 75, "favour": 75, "6x": 75, "john_bia": 75, "mary_bia": 75, "4f": 75, "exp": 75, "8995": 75, "6034": 75, "6550x": 75, "finit": 75, "invert": 75, "de": 75, "uncommon": 75, "iz": 75, "charact": 75, "example_text_str_token": 75, "example_text_token": 75, "50256": 75, "464": 75, "717": 75, "1517": 75, "345": 75, "761": 75, "284": 75, "3785": 75, "503": 75, "318": 75, "1635": 75, "4919": 75, "1243": 75, "389": 75, "11241": 75, "1143": 75, "4600": 75, "19849": 75, "1462": 75, "62": 75, "2536": 75, "482": 75, "641": 75, "63": 75, "30778": 75, "257": 75, "4731": 75, "656": 75, "262": 75, "16326": 75, "292": 75, "1351": 75, "286": 75, "850": 75, "37336": 75, "25666": 75, "290": 75, "523": 75, "8781": 75, "7301": 75, "644": 75, "2420": 75, "3073": 75, "588": 75, "1675": 75, "10176": 75, "428": 75, "1309": 75, "338": 75, "779": 75, "340": 75, "319": 75, "7322": 75, "signifi": 75, "example_multi_text": 75, "cat": 75, "sat": 75, "mat": 75, "example_multi_text_token": 75, "3797": 75, "3332": 75, "2603": 75, "1107": 75, "1327": 75, "th": 75, "cat_text": 75, "cat_logit": 75, "cat_prob": 75, "capital_the_token_index": 75, "ascii": 75, "squeez": 75, "annoy": 75, "arithmet": 75, "impress": 75, "2342": 75, "2017": 75, "21445": 75, "1000000": 75, "999999": 75, "214": 75, "000000": 75, "9999": 75, "tim": 75, "ne": 75, "el": 75, "messier": 75, "takeawai": 75, "unexpect": 75, "notic": 75, "trip": 75, "confusingli": 75, "forth": 75, "ioi_logits_with_bo": 75, "clair": 75, "mary_logit_with_bo": 75, "claire_logit_with_bo": 75, "ioi_logits_without_bo": 75, "mary_logit_without_bo": 75, "claire_logit_without_bo": 75, "754": 75, "782": 75, "air": 75, "understood": 75, "requisit": 75, "attention_scor": 75, "ab_factor": 75, "9105": 75, "linalg": 75, "eig": 75, "2877e": 75, "00": 75, "8626e": 75, "3121e": 75, "9038e": 75, "08": 75, "1527e": 75, "2877": 75, "3121": 75, "3126e": 75, "3963e": 75, "2029e": 75, "7690e": 75, "2164e": 75, "3126": 75, "3963": 75, "43": 75, "300": 75, "abc_factor": 75, "unfactor": 75, "160": 75, "0830": 75, "ab_unfactor": 75, "isclos": 75, "subspac": 75, "coincid": 75, "negat": 75, "proxi": 75, "lambda_i": 75, "ov_circuit_all_head": 75, "ov_circuit_all_heads_eigenvalu": 75, "complex64": 75, "ov_copying_scor": 75, "zmax": 75, "zmin": 75, "l11h11": 75, "imag": 75, "imaginari": 75, "full_ov_circuit": 75, "full_ov_circuit_eigenvalu": 75, "full_ov_copying_scor": 75, "interestingli": 75, "correl": 75, "outlier": 75, "53": 75, "ansh": 75, "radhakrishnan": 75, "establish": 75, "presid": 75, "barack": 75, "obama": 75, "caught": 75, "embarrass": 75, "scandal": 75, "namerican": 75, "voter": 75, "hillari": 75, "clinton": 75, "republican": 75, "mitt": 75, "romnei": 75, "orc": 75, "poll": 75, "lowest": 75, "2006": 75, "nrepublican": 75, "lightweight": 75, "squarethenadd": 75, "hook_squar": 75, "twolayermodel": 75, "layer1": 75, "layer2": 75, "hook_in": 75, "hook_mid": 75, "hook_out": 75, "x_in": 75, "x_mid": 75, "x_out": 75, "model_out": 75, "cache_object": 75, "56": [75, 76], "780": 75, "784": 75, "set_to_zero_hook": 75, "num_checkpoint": 75, "piecewis": 75, "schedul": 75, "crash": 75, "11b": [75, 76], "centr": 75, "hoc": 75, "count": 75, "58": 75, "checkpoint_label": 75, "log_i": 75, "marker": 75, "brief": 75, "suddenli": 75, "500": 75, "visibl": 75, "curv": 75, "briefli": 75, "deliber": 75, "justic": 75, "chosen": 75, "60": [75, 76], "500m": 75, "arbitrarili": 75, "fast": 75, "checkpoint_indic": 75, "checkpointed_model": 75, "tokens_trained_on": 75, "model_for_this_checkpoint": 75, "tokens_seen_for_this_checkpoint": 75, "induction_loss_for_this_checkpoint": 75, "contextualis": 75, "95": 75, "log_x": 75, "302m": 76, "4096": 76, "708m": 76, "1280": 76, "5120": 76, "1600": 76, "6400": 76, "42m": 76, "2048": 76, "50272": 76, "2560": 76, "10240": 76, "128": 76, "16384": 76, "20480": 76, "7168": 76, "28672": 76, "9216": 76, "36864": 76, "50400": 76, "6144": 76, "50432": 76, "96": 76, "24576": 76, "2m": 76, "50304": 76, "7m": 76, "805m": 76, "50688": 76, "50278": 76, "736": 76, "2944": 76, "101m": 76, "197m": 76, "1536": 76, "48262": 76, "4m": 76, "0m": 76, "50277": 76, "524k": 76, "50259": 76, "32000": 76, "11008": 76, "13824": 76, "6656": 76, "17920": 76, "22016": 76, "78b": 76, "32016": 76, "128256": 76, "14336": 76, "25m": 76, "28996": 76, "30522": 76, "393k": 76, "6m": 76, "23b": 76, "131072": 76, "32768": 76, "47b": 76, "250880": 76, "679m": 76, "0b": 76, "49280": 76, "151936": 76, "5504": 76, "152064": 76, "13696": 76, "308m": 76, "2816": 76, "6912": 76, "391m": 76, "896": 76, "4864": 76, "8960": 76, "3584": 76, "18944": 76, "27648": 76, "80b": 76, "29568": 76, "499m": 76, "9728": 76, "12288": 76, "17408": 76, "51200": 76, "32064": 76, "100352": 76, "256000": 76, "2304": 76, "4608": 76, "64000": 76, "39b": 76, "32128": 76, "100000": 76, "formerli": 77, "transfer": 77, "courtesi": 77, "austin": 77, "kozlowski": 77}, "objects": {"transformer_lens": [[10, 0, 0, "-", "ActivationCache"], [11, 0, 0, "-", "BertNextSentencePrediction"], [12, 0, 0, "-", "FactoredMatrix"], [13, 0, 0, "-", "HookedEncoder"], [14, 0, 0, "-", "HookedEncoderDecoder"], [15, 0, 0, "-", "HookedTransformer"], [16, 0, 0, "-", "HookedTransformerConfig"], [17, 0, 0, "-", "SVDInterpreter"], [38, 0, 0, "-", "evals"], [39, 0, 0, "-", "head_detector"], [40, 0, 0, "-", "hook_points"], [41, 0, 0, "-", "loading_from_pretrained"], [42, 0, 0, "-", "past_key_value_caching"], [43, 0, 0, "-", "patching"], [67, 0, 0, "-", "train"], [73, 0, 0, "-", "utils"]], "transformer_lens.ActivationCache": [[10, 1, 1, "", "ActivationCache"]], "transformer_lens.ActivationCache.ActivationCache": [[10, 2, 1, "", "__getitem__"], [10, 2, 1, "", "__iter__"], [10, 2, 1, "", "__len__"], [10, 2, 1, "", "accumulated_resid"], [10, 2, 1, "", "apply_ln_to_stack"], [10, 2, 1, "", "apply_slice_to_batch_dim"], [10, 2, 1, "", "compute_head_results"], [10, 2, 1, "", "decompose_resid"], [10, 2, 1, "", "get_full_resid_decomposition"], [10, 2, 1, "", "get_neuron_results"], [10, 2, 1, "", "items"], [10, 2, 1, "", "keys"], [10, 2, 1, "", "logit_attrs"], [10, 2, 1, "", "remove_batch_dim"], [10, 2, 1, "", "stack_activation"], [10, 2, 1, "", "stack_head_results"], [10, 2, 1, "", "stack_neuron_results"], [10, 2, 1, "", "to"], [10, 2, 1, "", "toggle_autodiff"], [10, 2, 1, "", "values"]], "transformer_lens.BertNextSentencePrediction": [[11, 1, 1, "", "BertNextSentencePrediction"]], "transformer_lens.BertNextSentencePrediction.BertNextSentencePrediction": [[11, 2, 1, "", "forward"], [11, 2, 1, "", "run_with_cache"], [11, 2, 1, "", "to_tokens"]], "transformer_lens.FactoredMatrix": [[12, 1, 1, "", "FactoredMatrix"]], "transformer_lens.FactoredMatrix.FactoredMatrix": [[12, 3, 1, "", "AB"], [12, 3, 1, "", "BA"], [12, 3, 1, "", "S"], [12, 3, 1, "", "T"], [12, 3, 1, "", "U"], [12, 3, 1, "", "Vh"], [12, 2, 1, "", "__getitem__"], [12, 2, 1, "", "collapse_l"], [12, 2, 1, "", "collapse_r"], [12, 3, 1, "", "eigenvalues"], [12, 2, 1, "", "get_corner"], [12, 2, 1, "", "make_even"], [12, 3, 1, "", "ndim"], [12, 2, 1, "", "norm"], [12, 3, 1, "", "pair"], [12, 2, 1, "", "svd"], [12, 2, 1, "", "unsqueeze"]], "transformer_lens.HookedEncoder": [[13, 1, 1, "", "HookedEncoder"]], "transformer_lens.HookedEncoder.HookedEncoder": [[13, 3, 1, "", "OV"], [13, 3, 1, "", "QK"], [13, 3, 1, "", "W_E"], [13, 3, 1, "", "W_E_pos"], [13, 3, 1, "", "W_K"], [13, 3, 1, "", "W_O"], [13, 3, 1, "", "W_Q"], [13, 3, 1, "", "W_U"], [13, 3, 1, "", "W_V"], [13, 3, 1, "", "W_in"], [13, 3, 1, "", "W_out"], [13, 3, 1, "", "W_pos"], [13, 2, 1, "", "all_head_labels"], [13, 3, 1, "", "b_K"], [13, 3, 1, "", "b_O"], [13, 3, 1, "", "b_Q"], [13, 3, 1, "", "b_U"], [13, 3, 1, "", "b_V"], [13, 3, 1, "", "b_in"], [13, 3, 1, "", "b_out"], [13, 2, 1, "", "cpu"], [13, 2, 1, "", "cuda"], [13, 2, 1, "", "encoder_output"], [13, 2, 1, "", "forward"], [13, 2, 1, "", "from_pretrained"], [13, 2, 1, "", "mps"], [13, 2, 1, "", "run_with_cache"], [13, 2, 1, "", "to"], [13, 2, 1, "", "to_tokens"]], "transformer_lens.HookedEncoderDecoder": [[14, 1, 1, "", "HookedEncoderDecoder"]], "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder": [[14, 3, 1, "", "OV"], [14, 3, 1, "", "QK"], [14, 3, 1, "", "W_E"], [14, 3, 1, "", "W_K"], [14, 3, 1, "", "W_O"], [14, 3, 1, "", "W_Q"], [14, 3, 1, "", "W_U"], [14, 3, 1, "", "W_V"], [14, 3, 1, "", "W_in"], [14, 3, 1, "", "W_out"], [14, 3, 1, "", "W_pos"], [14, 2, 1, "", "all_head_labels"], [14, 3, 1, "", "b_K"], [14, 3, 1, "", "b_O"], [14, 3, 1, "", "b_Q"], [14, 3, 1, "", "b_U"], [14, 3, 1, "", "b_V"], [14, 3, 1, "", "b_in"], [14, 3, 1, "", "b_out"], [14, 2, 1, "", "cpu"], [14, 2, 1, "", "cuda"], [14, 2, 1, "", "forward"], [14, 2, 1, "", "from_pretrained"], [14, 2, 1, "", "generate"], [14, 2, 1, "", "mps"], [14, 2, 1, "", "run_with_cache"], [14, 2, 1, "", "to"], [14, 2, 1, "", "to_tokens"], [14, 4, 1, "", "tokenizer"]], "transformer_lens.HookedTransformer": [[15, 1, 1, "", "HookedTransformer"], [15, 1, 1, "", "Output"]], "transformer_lens.HookedTransformer.HookedTransformer": [[15, 3, 1, "", "OV"], [15, 3, 1, "", "QK"], [15, 3, 1, "", "W_E"], [15, 3, 1, "", "W_E_pos"], [15, 3, 1, "", "W_K"], [15, 3, 1, "", "W_O"], [15, 3, 1, "", "W_Q"], [15, 3, 1, "", "W_U"], [15, 3, 1, "", "W_V"], [15, 3, 1, "", "W_gate"], [15, 3, 1, "", "W_in"], [15, 3, 1, "", "W_out"], [15, 3, 1, "", "W_pos"], [15, 2, 1, "", "__init__"], [15, 2, 1, "", "accumulated_bias"], [15, 2, 1, "", "all_composition_scores"], [15, 2, 1, "", "all_head_labels"], [15, 3, 1, "", "b_K"], [15, 3, 1, "", "b_O"], [15, 3, 1, "", "b_Q"], [15, 3, 1, "", "b_U"], [15, 3, 1, "", "b_V"], [15, 3, 1, "", "b_in"], [15, 3, 1, "", "b_out"], [15, 2, 1, "", "center_unembed"], [15, 2, 1, "", "center_writing_weights"], [15, 2, 1, "", "check_hooks_to_add"], [15, 2, 1, "", "cpu"], [15, 2, 1, "", "cuda"], [15, 2, 1, "", "fold_layer_norm"], [15, 2, 1, "", "fold_value_biases"], [15, 2, 1, "", "forward"], [15, 2, 1, "", "from_pretrained"], [15, 2, 1, "", "from_pretrained_no_processing"], [15, 2, 1, "", "generate"], [15, 2, 1, "", "get_pos_offset"], [15, 2, 1, "", "get_residual"], [15, 2, 1, "", "get_token_position"], [15, 2, 1, "", "init_weights"], [15, 2, 1, "", "input_to_embed"], [15, 4, 1, "", "ln_final"], [15, 2, 1, "", "load_and_process_state_dict"], [15, 2, 1, "", "load_sample_training_dataset"], [15, 2, 1, "", "loss_fn"], [15, 2, 1, "", "move_model_modules_to_device"], [15, 2, 1, "", "mps"], [15, 2, 1, "", "process_weights_"], [15, 2, 1, "", "refactor_factored_attn_matrices"], [15, 2, 1, "", "run_with_cache"], [15, 2, 1, "", "sample_datapoint"], [15, 2, 1, "", "set_tokenizer"], [15, 2, 1, "", "set_ungroup_grouped_query_attention"], [15, 2, 1, "", "set_use_attn_in"], [15, 2, 1, "", "set_use_attn_result"], [15, 2, 1, "", "set_use_hook_mlp_in"], [15, 2, 1, "", "set_use_split_qkv_input"], [15, 2, 1, "", "to"], [15, 2, 1, "", "to_single_str_token"], [15, 2, 1, "", "to_single_token"], [15, 2, 1, "", "to_str_tokens"], [15, 2, 1, "", "to_string"], [15, 2, 1, "", "to_tokens"], [15, 4, 1, "", "tokenizer"], [15, 2, 1, "", "tokens_to_residual_directions"]], "transformer_lens.HookedTransformer.Output": [[15, 4, 1, "", "logits"], [15, 4, 1, "", "loss"]], "transformer_lens.HookedTransformerConfig": [[16, 1, 1, "", "HookedTransformerConfig"]], "transformer_lens.HookedTransformerConfig.HookedTransformerConfig": [[16, 4, 1, "", "NTK_by_parts_factor"], [16, 4, 1, "", "NTK_by_parts_high_freq_factor"], [16, 4, 1, "", "NTK_by_parts_low_freq_factor"], [16, 4, 1, "", "NTK_original_ctx_len"], [16, 4, 1, "", "act_fn"], [16, 4, 1, "", "attention_dir"], [16, 4, 1, "", "attn_only"], [16, 4, 1, "", "attn_scale"], [16, 4, 1, "", "attn_scores_soft_cap"], [16, 4, 1, "", "attn_types"], [16, 4, 1, "", "checkpoint_index"], [16, 4, 1, "", "checkpoint_label_type"], [16, 4, 1, "", "checkpoint_value"], [16, 4, 1, "", "d_head"], [16, 4, 1, "", "d_mlp"], [16, 4, 1, "", "d_model"], [16, 4, 1, "", "d_vocab"], [16, 4, 1, "", "d_vocab_out"], [16, 4, 1, "", "decoder_start_token_id"], [16, 4, 1, "", "default_prepend_bos"], [16, 4, 1, "", "device"], [16, 4, 1, "", "dtype"], [16, 4, 1, "", "eps"], [16, 4, 1, "", "experts_per_token"], [16, 4, 1, "", "final_rms"], [16, 4, 1, "", "from_checkpoint"], [16, 2, 1, "", "from_dict"], [16, 4, 1, "", "gated_mlp"], [16, 4, 1, "", "init_mode"], [16, 4, 1, "", "init_weights"], [16, 4, 1, "", "initializer_range"], [16, 2, 1, "", "is_layer_norm_activation"], [16, 4, 1, "", "load_in_4bit"], [16, 4, 1, "", "model_name"], [16, 4, 1, "", "n_ctx"], [16, 4, 1, "", "n_devices"], [16, 4, 1, "", "n_heads"], [16, 4, 1, "", "n_key_value_heads"], [16, 4, 1, "", "n_layers"], [16, 4, 1, "", "n_params"], [16, 4, 1, "", "normalization_type"], [16, 4, 1, "", "num_experts"], [16, 4, 1, "", "original_architecture"], [16, 4, 1, "", "output_logits_soft_cap"], [16, 4, 1, "", "parallel_attn_mlp"], [16, 4, 1, "", "positional_embedding_type"], [16, 4, 1, "", "post_embedding_ln"], [16, 4, 1, "", "relative_attention_max_distance"], [16, 4, 1, "", "relative_attention_num_buckets"], [16, 4, 1, "", "rotary_adjacent_pairs"], [16, 4, 1, "", "rotary_base"], [16, 4, 1, "", "rotary_dim"], [16, 4, 1, "", "scale_attn_by_inverse_layer_idx"], [16, 4, 1, "", "seed"], [16, 2, 1, "", "set_seed_everywhere"], [16, 4, 1, "", "tie_word_embeddings"], [16, 2, 1, "", "to_dict"], [16, 4, 1, "", "tokenizer_name"], [16, 4, 1, "", "tokenizer_prepends_bos"], [16, 4, 1, "", "trust_remote_code"], [16, 4, 1, "", "ungroup_grouped_query_attention"], [16, 2, 1, "", "unwrap"], [16, 4, 1, "", "use_NTK_by_parts_rope"], [16, 4, 1, "", "use_attn_in"], [16, 4, 1, "", "use_attn_result"], [16, 4, 1, "", "use_attn_scale"], [16, 4, 1, "", "use_hook_mlp_in"], [16, 4, 1, "", "use_hook_tokens"], [16, 4, 1, "", "use_local_attn"], [16, 4, 1, "", "use_normalization_before_and_after"], [16, 4, 1, "", "use_qk_norm"], [16, 4, 1, "", "use_split_qkv_input"], [16, 4, 1, "", "window_size"]], "transformer_lens.SVDInterpreter": [[17, 1, 1, "", "SVDInterpreter"]], "transformer_lens.SVDInterpreter.SVDInterpreter": [[17, 2, 1, "", "get_singular_vectors"]], "transformer_lens.components": [[19, 0, 0, "-", "abstract_attention"], [20, 0, 0, "-", "attention"], [21, 0, 0, "-", "bert_block"], [22, 0, 0, "-", "bert_embed"], [23, 0, 0, "-", "bert_mlm_head"], [24, 0, 0, "-", "bert_nsp_head"], [25, 0, 0, "-", "bert_pooler"], [26, 0, 0, "-", "embed"], [27, 0, 0, "-", "grouped_query_attention"], [28, 0, 0, "-", "layer_norm"], [29, 0, 0, "-", "layer_norm_pre"], [30, 0, 0, "-", "pos_embed"], [31, 0, 0, "-", "rms_norm"], [32, 0, 0, "-", "rms_norm_pre"], [33, 0, 0, "-", "t5_attention"], [34, 0, 0, "-", "t5_block"], [35, 0, 0, "-", "token_typed_embed"], [36, 0, 0, "-", "transformer_block"], [37, 0, 0, "-", "unembed"]], "transformer_lens.components.abstract_attention": [[19, 1, 1, "", "AbstractAttention"]], "transformer_lens.components.abstract_attention.AbstractAttention": [[19, 4, 1, "", "IGNORE"], [19, 3, 1, "", "OV"], [19, 3, 1, "", "QK"], [19, 2, 1, "", "__init__"], [19, 4, 1, "", "alibi"], [19, 2, 1, "", "apply_causal_mask"], [19, 2, 1, "", "apply_rotary"], [19, 2, 1, "", "calculate_attention_scores"], [19, 2, 1, "", "calculate_qkv_matrices"], [19, 2, 1, "", "calculate_sin_cos_rotary"], [19, 2, 1, "", "calculate_z_scores"], [19, 2, 1, "", "create_alibi_bias"], [19, 2, 1, "", "create_alibi_multipliers"], [19, 2, 1, "", "create_alibi_slope"], [19, 2, 1, "", "forward"], [19, 4, 1, "", "k_norm"], [19, 4, 1, "", "mask"], [19, 4, 1, "", "q_norm"], [19, 4, 1, "", "rotary_cos"], [19, 4, 1, "", "rotary_sin"], [19, 2, 1, "", "rotate_every_two"]], "transformer_lens.components.attention": [[20, 1, 1, "", "Attention"]], "transformer_lens.components.attention.Attention": [[20, 2, 1, "", "__init__"]], "transformer_lens.components.bert_block": [[21, 1, 1, "", "BertBlock"]], "transformer_lens.components.bert_block.BertBlock": [[21, 2, 1, "", "forward"]], "transformer_lens.components.bert_embed": [[22, 1, 1, "", "BertEmbed"]], "transformer_lens.components.bert_embed.BertEmbed": [[22, 2, 1, "", "forward"]], "transformer_lens.components.bert_mlm_head": [[23, 1, 1, "", "BertMLMHead"]], "transformer_lens.components.bert_mlm_head.BertMLMHead": [[23, 2, 1, "", "forward"]], "transformer_lens.components.bert_nsp_head": [[24, 1, 1, "", "BertNSPHead"]], "transformer_lens.components.bert_nsp_head.BertNSPHead": [[24, 2, 1, "", "forward"]], "transformer_lens.components.bert_pooler": [[25, 1, 1, "", "BertPooler"]], "transformer_lens.components.bert_pooler.BertPooler": [[25, 2, 1, "", "forward"]], "transformer_lens.components.embed": [[26, 1, 1, "", "Embed"]], "transformer_lens.components.embed.Embed": [[26, 2, 1, "", "forward"]], "transformer_lens.components.grouped_query_attention": [[27, 1, 1, "", "GroupedQueryAttention"]], "transformer_lens.components.grouped_query_attention.GroupedQueryAttention": [[27, 3, 1, "", "W_K"], [27, 3, 1, "", "W_V"], [27, 2, 1, "", "__init__"], [27, 3, 1, "", "b_K"], [27, 3, 1, "", "b_V"], [27, 2, 1, "", "calculate_attention_scores"], [27, 2, 1, "", "calculate_qkv_matrices"], [27, 2, 1, "", "calculate_z_scores"]], "transformer_lens.components.layer_norm": [[28, 1, 1, "", "LayerNorm"]], "transformer_lens.components.layer_norm.LayerNorm": [[28, 2, 1, "", "__init__"], [28, 2, 1, "", "forward"]], "transformer_lens.components.layer_norm_pre": [[29, 1, 1, "", "LayerNormPre"]], "transformer_lens.components.layer_norm_pre.LayerNormPre": [[29, 2, 1, "", "__init__"], [29, 2, 1, "", "forward"]], "transformer_lens.components.pos_embed": [[30, 1, 1, "", "PosEmbed"]], "transformer_lens.components.pos_embed.PosEmbed": [[30, 2, 1, "", "forward"]], "transformer_lens.components.rms_norm": [[31, 1, 1, "", "RMSNorm"]], "transformer_lens.components.rms_norm.RMSNorm": [[31, 2, 1, "", "__init__"], [31, 2, 1, "", "forward"]], "transformer_lens.components.rms_norm_pre": [[32, 1, 1, "", "RMSNormPre"]], "transformer_lens.components.rms_norm_pre.RMSNormPre": [[32, 2, 1, "", "__init__"], [32, 2, 1, "", "forward"]], "transformer_lens.components.t5_attention": [[33, 1, 1, "", "T5Attention"]], "transformer_lens.components.t5_attention.T5Attention": [[33, 2, 1, "", "compute_relative_attention_bias"]], "transformer_lens.components.t5_block": [[34, 1, 1, "", "T5Block"]], "transformer_lens.components.t5_block.T5Block": [[34, 2, 1, "", "forward"]], "transformer_lens.components.token_typed_embed": [[35, 1, 1, "", "TokenTypeEmbed"]], "transformer_lens.components.token_typed_embed.TokenTypeEmbed": [[35, 2, 1, "", "forward"]], "transformer_lens.components.transformer_block": [[36, 1, 1, "", "TransformerBlock"]], "transformer_lens.components.transformer_block.TransformerBlock": [[36, 2, 1, "", "apply_mlp"], [36, 2, 1, "", "forward"], [36, 4, 1, "", "ln1"], [36, 4, 1, "", "ln2"], [36, 4, 1, "", "mlp"]], "transformer_lens.components.unembed": [[37, 1, 1, "", "Unembed"]], "transformer_lens.components.unembed.Unembed": [[37, 2, 1, "", "forward"]], "transformer_lens.evals": [[38, 1, 1, "", "IOIDataset"], [38, 5, 1, "", "evaluate"], [38, 5, 1, "", "evaluate_on_dataset"], [38, 5, 1, "", "induction_loss"], [38, 5, 1, "", "ioi_eval"], [38, 5, 1, "", "make_code_data_loader"], [38, 5, 1, "", "make_owt_data_loader"], [38, 5, 1, "", "make_pile_data_loader"], [38, 5, 1, "", "make_wiki_data_loader"], [38, 5, 1, "", "sanity_check"]], "transformer_lens.evals.IOIDataset": [[38, 2, 1, "", "__getitem__"], [38, 2, 1, "", "__len__"], [38, 2, 1, "", "get_default_names"], [38, 2, 1, "", "get_default_nouns"], [38, 2, 1, "", "get_default_templates"], [38, 2, 1, "", "get_sample"]], "transformer_lens.head_detector": [[39, 5, 1, "", "compute_head_attention_similarity_score"], [39, 5, 1, "", "detect_head"], [39, 5, 1, "", "get_duplicate_token_head_detection_pattern"], [39, 5, 1, "", "get_induction_head_detection_pattern"], [39, 5, 1, "", "get_previous_token_head_detection_pattern"], [39, 5, 1, "", "get_supported_heads"]], "transformer_lens.hook_points": [[40, 4, 1, "", "HookFunction"], [40, 1, 1, "", "HookPoint"], [40, 1, 1, "", "HookedRootModule"], [40, 1, 1, "", "LensHandle"]], "transformer_lens.hook_points.HookPoint": [[40, 2, 1, "", "add_hook"], [40, 2, 1, "", "add_perma_hook"], [40, 2, 1, "", "clear_context"], [40, 2, 1, "", "forward"], [40, 2, 1, "", "layer"], [40, 2, 1, "", "remove_hooks"]], "transformer_lens.hook_points.HookedRootModule": [[40, 2, 1, "", "add_caching_hooks"], [40, 2, 1, "", "add_hook"], [40, 2, 1, "", "add_perma_hook"], [40, 2, 1, "", "cache_all"], [40, 2, 1, "", "cache_some"], [40, 2, 1, "", "check_and_add_hook"], [40, 2, 1, "", "check_hooks_to_add"], [40, 2, 1, "", "clear_contexts"], [40, 2, 1, "", "get_caching_hooks"], [40, 4, 1, "", "hook_dict"], [40, 2, 1, "", "hook_points"], [40, 2, 1, "", "hooks"], [40, 4, 1, "", "mod_dict"], [40, 4, 1, "", "name"], [40, 2, 1, "", "remove_all_hook_fns"], [40, 2, 1, "", "reset_hooks"], [40, 2, 1, "", "run_with_cache"], [40, 2, 1, "", "run_with_hooks"], [40, 2, 1, "", "setup"]], "transformer_lens.hook_points.LensHandle": [[40, 4, 1, "", "context_level"], [40, 4, 1, "", "hook"], [40, 4, 1, "", "is_permanent"]], "transformer_lens.loading_from_pretrained": [[41, 1, 1, "", "Config"], [41, 6, 1, "", "MODEL_ALIASES"], [41, 6, 1, "", "NON_HF_HOSTED_MODEL_NAMES"], [41, 6, 1, "", "OFFICIAL_MODEL_NAMES"], [41, 5, 1, "", "get_checkpoint_labels"], [41, 5, 1, "", "get_num_params_of_pretrained"], [41, 5, 1, "", "get_pretrained_model_config"]], "transformer_lens.loading_from_pretrained.Config": [[41, 4, 1, "", "d_head"], [41, 4, 1, "", "d_mlp"], [41, 4, 1, "", "d_model"], [41, 4, 1, "", "d_vocab"], [41, 4, 1, "", "debug"], [41, 4, 1, "", "init_range"], [41, 4, 1, "", "layer_norm_eps"], [41, 4, 1, "", "n_ctx"], [41, 4, 1, "", "n_heads"], [41, 4, 1, "", "n_layers"]], "transformer_lens.past_key_value_caching": [[42, 1, 1, "", "HookedTransformerKeyValueCache"], [42, 1, 1, "", "HookedTransformerKeyValueCacheEntry"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache": [[42, 2, 1, "", "__getitem__"], [42, 2, 1, "", "append_attention_mask"], [42, 4, 1, "", "entries"], [42, 2, 1, "", "freeze"], [42, 4, 1, "", "frozen"], [42, 2, 1, "", "init_cache"], [42, 4, 1, "", "previous_attention_mask"], [42, 2, 1, "", "unfreeze"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry": [[42, 2, 1, "", "append"], [42, 4, 1, "", "frozen"], [42, 2, 1, "", "init_cache_entry"], [42, 4, 1, "", "past_keys"], [42, 4, 1, "", "past_values"]], "transformer_lens.patching": [[43, 5, 1, "", "generic_activation_patch"], [43, 5, 1, "", "get_act_patch_attn_head_all_pos_every"], [43, 5, 1, "", "get_act_patch_attn_head_by_pos_every"], [43, 5, 1, "", "get_act_patch_attn_head_k_all_pos"], [43, 5, 1, "", "get_act_patch_attn_head_k_by_pos"], [43, 5, 1, "", "get_act_patch_attn_head_out_all_pos"], [43, 5, 1, "", "get_act_patch_attn_head_out_by_pos"], [43, 5, 1, "", "get_act_patch_attn_head_pattern_all_pos"], [43, 5, 1, "", "get_act_patch_attn_head_pattern_by_pos"], [43, 5, 1, "", "get_act_patch_attn_head_pattern_dest_src_pos"], [43, 5, 1, "", "get_act_patch_attn_head_q_all_pos"], [43, 5, 1, "", "get_act_patch_attn_head_q_by_pos"], [43, 5, 1, "", "get_act_patch_attn_head_v_all_pos"], [43, 5, 1, "", "get_act_patch_attn_head_v_by_pos"], [43, 5, 1, "", "get_act_patch_attn_out"], [43, 5, 1, "", "get_act_patch_block_every"], [43, 5, 1, "", "get_act_patch_mlp_out"], [43, 5, 1, "", "get_act_patch_resid_mid"], [43, 5, 1, "", "get_act_patch_resid_pre"], [43, 5, 1, "", "layer_head_dest_src_pos_pattern_patch_setter"], [43, 5, 1, "", "layer_head_pattern_patch_setter"], [43, 5, 1, "", "layer_head_pos_pattern_patch_setter"], [43, 5, 1, "", "layer_head_vector_patch_setter"], [43, 5, 1, "", "layer_pos_head_vector_patch_setter"], [43, 5, 1, "", "layer_pos_patch_setter"]], "transformer_lens.pretrained.weight_conversions": [[46, 0, 0, "-", "bert"], [47, 0, 0, "-", "bloom"], [48, 0, 0, "-", "coder"], [49, 0, 0, "-", "gemma"], [50, 0, 0, "-", "gpt2"], [51, 0, 0, "-", "gptj"], [52, 0, 0, "-", "llama"], [53, 0, 0, "-", "mingpt"], [54, 0, 0, "-", "mistral"], [55, 0, 0, "-", "mixtral"], [56, 0, 0, "-", "nanogpt"], [57, 0, 0, "-", "neel_solu_old"], [58, 0, 0, "-", "neo"], [59, 0, 0, "-", "neox"], [60, 0, 0, "-", "opt"], [61, 0, 0, "-", "phi"], [62, 0, 0, "-", "phi3"], [63, 0, 0, "-", "qwen"], [64, 0, 0, "-", "qwen2"], [65, 0, 0, "-", "qwen3"], [66, 0, 0, "-", "t5"]], "transformer_lens.pretrained.weight_conversions.bloom": [[47, 5, 1, "", "convert_bloom_weights"]], "transformer_lens.pretrained.weight_conversions.coder": [[48, 5, 1, "", "convert_coder_weights"]], "transformer_lens.pretrained.weight_conversions.mistral": [[54, 5, 1, "", "convert_mistral_weights"]], "transformer_lens.pretrained.weight_conversions.mixtral": [[55, 5, 1, "", "convert_mixtral_weights"]], "transformer_lens.pretrained.weight_conversions.phi": [[61, 5, 1, "", "convert_phi_weights"]], "transformer_lens.pretrained.weight_conversions.phi3": [[62, 5, 1, "", "convert_phi3_weights"]], "transformer_lens.pretrained.weight_conversions.qwen": [[63, 5, 1, "", "convert_qwen_weights"]], "transformer_lens.pretrained.weight_conversions.qwen2": [[64, 5, 1, "", "convert_qwen2_weights"]], "transformer_lens.pretrained.weight_conversions.qwen3": [[65, 5, 1, "", "convert_qwen3_weights"]], "transformer_lens.pretrained.weight_conversions.t5": [[66, 5, 1, "", "convert_t5_weights"]], "transformer_lens.train": [[67, 1, 1, "", "HookedTransformerTrainConfig"], [67, 5, 1, "", "train"]], "transformer_lens.train.HookedTransformerTrainConfig": [[67, 4, 1, "", "batch_size"], [67, 4, 1, "", "device"], [67, 4, 1, "", "lr"], [67, 4, 1, "", "max_grad_norm"], [67, 4, 1, "", "max_steps"], [67, 4, 1, "", "momentum"], [67, 4, 1, "", "num_epochs"], [67, 4, 1, "", "optimizer_name"], [67, 4, 1, "", "print_every"], [67, 4, 1, "", "save_dir"], [67, 4, 1, "", "save_every"], [67, 4, 1, "", "seed"], [67, 4, 1, "", "wandb"], [67, 4, 1, "", "wandb_project_name"], [67, 4, 1, "", "warmup_steps"], [67, 4, 1, "", "weight_decay"]], "transformer_lens.utilities": [[69, 0, 0, "-", "activation_functions"], [70, 0, 0, "-", "addmm"], [71, 0, 0, "-", "attention"], [72, 0, 0, "-", "devices"]], "transformer_lens.utilities.addmm": [[70, 5, 1, "", "batch_addmm"], [70, 5, 1, "", "vanilla_addmm"]], "transformer_lens.utilities.attention": [[71, 5, 1, "", "complex_attn_linear"], [71, 5, 1, "", "simple_attn_linear"]], "transformer_lens.utilities.devices": [[72, 6, 1, "", "AvailableDeviceMemory"], [72, 5, 1, "", "calculate_available_device_cuda_memory"], [72, 5, 1, "", "determine_available_memory_for_available_devices"], [72, 5, 1, "", "get_best_available_cuda_device"], [72, 5, 1, "", "get_best_available_device"], [72, 5, 1, "", "get_device_for_block_index"], [72, 5, 1, "", "move_to_and_update_config"], [72, 5, 1, "", "sort_devices_based_on_available_memory"]], "transformer_lens.utils": [[73, 1, 1, "", "LocallyOverridenDefaults"], [73, 1, 1, "", "Slice"], [73, 6, 1, "", "SliceInput"], [73, 5, 1, "", "calc_fan_in_and_fan_out"], [73, 5, 1, "", "composition_scores"], [73, 5, 1, "", "download_file_from_hf"], [73, 5, 1, "", "gelu_fast"], [73, 5, 1, "", "gelu_new"], [73, 5, 1, "", "gelu_pytorch_tanh"], [73, 5, 1, "", "get_act_name"], [73, 5, 1, "", "get_attention_mask"], [73, 5, 1, "", "get_corner"], [73, 5, 1, "", "get_cumsum_along_dim"], [73, 5, 1, "", "get_dataset"], [73, 5, 1, "", "get_device"], [73, 5, 1, "", "get_input_with_manually_prepended_bos"], [73, 5, 1, "", "get_nested_attr"], [73, 5, 1, "", "get_offset_position_ids"], [73, 5, 1, "", "get_tokenizer_with_bos"], [73, 5, 1, "", "get_tokens_with_bos_removed"], [73, 5, 1, "", "init_kaiming_normal_"], [73, 5, 1, "", "init_kaiming_uniform_"], [73, 5, 1, "", "init_xavier_normal_"], [73, 5, 1, "", "init_xavier_uniform_"], [73, 5, 1, "", "is_lower_triangular"], [73, 5, 1, "", "is_square"], [73, 5, 1, "", "keep_single_column"], [73, 5, 1, "", "lm_accuracy"], [73, 5, 1, "", "lm_cross_entropy_loss"], [73, 5, 1, "", "override_or_use_default_value"], [73, 5, 1, "", "print_gpu_mem"], [73, 5, 1, "", "remove_batch_dim"], [73, 5, 1, "", "repeat_along_head_dimension"], [73, 5, 1, "", "sample_logits"], [73, 5, 1, "", "set_nested_attr"], [73, 5, 1, "", "solu"], [73, 5, 1, "", "test_prompt"], [73, 5, 1, "", "to_numpy"], [73, 5, 1, "", "tokenize_and_concatenate"], [73, 5, 1, "", "transpose"]], "transformer_lens.utils.LocallyOverridenDefaults": [[73, 2, 1, "", "__init__"]], "transformer_lens.utils.Slice": [[73, 2, 1, "", "__init__"], [73, 2, 1, "", "apply"], [73, 2, 1, "", "indices"], [73, 4, 1, "", "slice"], [73, 2, 1, "", "unwrap"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:function", "6": "py:data"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"], "6": ["py", "data", "Python data"]}, "titleterms": {"citat": 0, "contribut": 1, "setup": [1, 74, 75], "devcontain": 1, "manual": 1, "test": [1, 5], "run": [1, 75], "format": 1, "document": 1, "docstr": 1, "style": 1, "guid": 1, "section": 1, "order": 1, "support": 1, "sphinx": 1, "properti": [1, 76], "refer": 1, "other": [1, 75], "function": [1, 74], "class": [1, 75], "math": 1, "markup": 1, "galleri": 2, "get": [3, 4], "start": [3, 4, 7], "advic": 3, "read": [3, 74], "code": 3, "instal": 3, "huggingfac": 3, "gate": 3, "access": [3, 75], "mechanist": [4, 77], "interpret": [4, 75, 77], "transformerlen": [5, 77], "2": 5, "0": 5, "first": 5, "an": [5, 75], "introduct": [5, 74, 75], "adopt": 5, "semant": 5, "version": 5, "deprec": 5, "roadmap": 5, "immedi": 5, "within": 5, "next": 5, "month": 5, "mid": 5, "term": 5, "3": 5, "perform": 5, "streamlin": 5, "ad": 5, "new": 5, "model": [5, 75, 76, 77], "long": 5, "year": 5, "integr": 5, "contributor": 5, "dev": 5, "branch": 5, "coverag": 5, "compon": [5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37], "refactor": 5, "conclus": 5, "appendix": 5, "special": 6, "case": 6, "mixtur": 6, "expert": 6, "error": 6, "rate": 6, "tutori": 7, "where": 7, "To": 7, "demo": [7, 74, 75], "transform": [8, 75], "len": [8, 74, 75], "api": 8, "content": 8, "transformer_len": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73], "submodul": [9, 18, 45, 68], "subpackag": [9, 44], "activationcach": 10, "bertnextsentencepredict": 11, "factoredmatrix": 12, "hookedencod": 13, "hookedencoderdecod": 14, "hookedtransform": 15, "hookedtransformerconfig": 16, "svdinterpret": 17, "abstract_attent": 19, "attent": [20, 71, 74], "bert_block": 21, "bert_emb": 22, "bert_mlm_head": 23, "bert_nsp_head": 24, "bert_pool": 25, "emb": 26, "grouped_query_attent": 27, "layer_norm": 28, "layer_norm_pr": 29, "pos_emb": 30, "rms_norm": 31, "rms_norm_pr": 32, "t5_attent": 33, "t5_block": 34, "token_typed_emb": 35, "transformer_block": 36, "unemb": 37, "eval": 38, "head_detector": 39, "hook_point": 40, "loading_from_pretrain": 41, "past_key_value_cach": 42, "patch": [43, 74, 75], "pretrain": [44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66], "weight_convers": [45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66], "bert": 46, "bloom": 47, "coder": 48, "gemma": 49, "gpt2": 50, "gptj": 51, "llama": 52, "mingpt": 53, "mistral": 54, "mixtral": 55, "nanogpt": 56, "neel_solu_old": 57, "neo": 58, "neox": 59, "opt": 60, "phi": 61, "phi3": 62, "qwen": 63, "qwen2": 64, "qwen3": 65, "t5": 66, "train": [67, 75], "util": [68, 69, 70, 71, 72, 73], "activation_funct": 69, "addmm": 70, "devic": 72, "exploratori": 74, "analysi": 74, "tip": 74, "thi": 74, "environ": 74, "ignor": 74, "import": [74, 75], "pytorch": 74, "plot": 74, "helper": 74, "indirect": [74, 75], "object": [74, 75], "identif": [74, 75], "brainstorm": 74, "what": 74, "": 74, "actual": 74, "go": 74, "On": 74, "option": 74, "direct": 74, "logit": 74, "attribut": 74, "layer": 74, "head": [74, 75], "activ": [74, 75], "residu": 74, "stream": 74, "decompos": 74, "consolid": 74, "understand": 74, "visual": 74, "pattern": 74, "compar": 74, "paper": 74, "bonu": 74, "explor": 74, "anomali": 74, "earli": 74, "ar": 74, "induct": [74, 75], "implic": 74, "backup": 74, "name": [74, 75], "mover": 74, "main": 75, "notebook": 75, "load": 75, "cach": 75, "all": 75, "hook": 75, "interven": 75, "task": 75, "avail": 75, "overview": 75, "open": 75, "sourc": 75, "librari": [75, 77], "some": 75, "friendli": 75, "i": 75, "ve": 75, "includ": 75, "resourc": 75, "architectur": 75, "paramet": 75, "fold": 75, "layernorm": 75, "For": 75, "curiou": 75, "featur": 75, "deal": 75, "token": 75, "gotcha": 75, "prepend_bo": 75, "factor": 75, "matrix": 75, "basic": 75, "exampl": 75, "medium": 75, "eigenvalu": 75, "copi": 75, "score": 75, "gener": [75, 77], "text": 75, "point": 75, "toi": 75, "pre": 75, "checkpoint": 75, "phase": 75, "transit": 75, "tabl": 76, "A": 77, "languag": 77}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"Citation": [[0, "citation"]], "Contributing": [[1, "contributing"]], "Setup": [[1, "setup"], [74, "Setup"], [75, "Setup"]], "DevContainer": [[1, "devcontainer"]], "Manual Setup": [[1, "manual-setup"]], "Testing": [[1, "testing"]], "Running the tests": [[1, "running-the-tests"]], "Formatting": [[1, "formatting"]], "Documentation": [[1, "documentation"]], "Docstring Style Guide": [[1, "docstring-style-guide"]], "Sections and Order": [[1, "sections-and-order"]], "Supported Sphinx Properties": [[1, "supported-sphinx-properties"]], "References to Other Functions/Classes": [[1, "references-to-other-functions-classes"]], "Maths": [[1, "maths"]], "Markup": [[1, "markup"]], "Gallery": [[2, "gallery"]], "Getting Started": [[3, "getting-started"]], "Advice for Reading the Code": [[3, "advice-for-reading-the-code"]], "Installation": [[3, "installation"]], "Huggingface Gated Access": [[3, "huggingface-gated-access"]], "Getting Started in Mechanistic Interpretability": [[4, "getting-started-in-mechanistic-interpretability"]], "TransformerLens 2.0": [[5, "transformerlens-2-0"]], "First, an introduction": [[5, "first-an-introduction"]], "Adopting Semantic Versioning": [[5, "adopting-semantic-versioning"]], "Deprecations": [[5, "deprecations"]], "Roadmap": [[5, "roadmap"]], "Immediate - within the next month": [[5, "immediate-within-the-next-month"]], "Mid-term - within the next 3 months": [[5, "mid-term-within-the-next-3-months"]], "Performance": [[5, "performance"]], "Streamlining Adding New Models": [[5, "streamlining-adding-new-models"]], "Long-term - within the next year": [[5, "long-term-within-the-next-year"]], "Model Testing": [[5, "model-testing"]], "Model Integration": [[5, "model-integration"]], "Contributors": [[5, "contributors"]], "New Dev Branches": [[5, "new-dev-branches"]], "Integration Tests": [[5, "integration-tests"]], "Test Coverage": [[5, "test-coverage"]], "Components Refactor": [[5, "components-refactor"]], "Conclusion": [[5, "conclusion"]], "Appendix": [[5, "appendix"]], "Semantic Versioning": [[5, "semantic-versioning"]], "Special Cases": [[6, "special-cases"]], "Mixture of Experts error rates": [[6, "mixture-of-experts-error-rates"]], "Tutorials": [[7, "tutorials"]], "Where To Start": [[7, "where-to-start"]], "Demos": [[7, "demos"]], "Transformer Lens API": [[8, "transformer-lens-api"]], "Contents": [[8, "contents"]], "transformer_lens": [[9, "transformer-lens"]], "Submodules": [[9, "submodules"], [18, "submodules"], [45, "submodules"], [68, "submodules"]], "Subpackages": [[9, "subpackages"], [44, "subpackages"]], "transformer_lens.ActivationCache": [[10, "module-transformer_lens.ActivationCache"]], "transformer_lens.BertNextSentencePrediction": [[11, "module-transformer_lens.BertNextSentencePrediction"]], "transformer_lens.FactoredMatrix": [[12, "module-transformer_lens.FactoredMatrix"]], "transformer_lens.HookedEncoder": [[13, "module-transformer_lens.HookedEncoder"]], "transformer_lens.HookedEncoderDecoder": [[14, "module-transformer_lens.HookedEncoderDecoder"]], "transformer_lens.HookedTransformer": [[15, "module-transformer_lens.HookedTransformer"]], "transformer_lens.HookedTransformerConfig": [[16, "module-transformer_lens.HookedTransformerConfig"]], "transformer_lens.SVDInterpreter": [[17, "module-transformer_lens.SVDInterpreter"]], "transformer_lens.components": [[18, "transformer-lens-components"]], "transformer_lens.components.abstract_attention": [[19, "module-transformer_lens.components.abstract_attention"]], "transformer_lens.components.attention": [[20, "module-transformer_lens.components.attention"]], "transformer_lens.components.bert_block": [[21, "module-transformer_lens.components.bert_block"]], "transformer_lens.components.bert_embed": [[22, "module-transformer_lens.components.bert_embed"]], "transformer_lens.components.bert_mlm_head": [[23, "module-transformer_lens.components.bert_mlm_head"]], "transformer_lens.components.bert_nsp_head": [[24, "module-transformer_lens.components.bert_nsp_head"]], "transformer_lens.components.bert_pooler": [[25, "module-transformer_lens.components.bert_pooler"]], "transformer_lens.components.embed": [[26, "module-transformer_lens.components.embed"]], "transformer_lens.components.grouped_query_attention": [[27, "module-transformer_lens.components.grouped_query_attention"]], "transformer_lens.components.layer_norm": [[28, "module-transformer_lens.components.layer_norm"]], "transformer_lens.components.layer_norm_pre": [[29, "module-transformer_lens.components.layer_norm_pre"]], "transformer_lens.components.pos_embed": [[30, "module-transformer_lens.components.pos_embed"]], "transformer_lens.components.rms_norm": [[31, "module-transformer_lens.components.rms_norm"]], "transformer_lens.components.rms_norm_pre": [[32, "module-transformer_lens.components.rms_norm_pre"]], "transformer_lens.components.t5_attention": [[33, "module-transformer_lens.components.t5_attention"]], "transformer_lens.components.t5_block": [[34, "module-transformer_lens.components.t5_block"]], "transformer_lens.components.token_typed_embed": [[35, "module-transformer_lens.components.token_typed_embed"]], "transformer_lens.components.transformer_block": [[36, "module-transformer_lens.components.transformer_block"]], "transformer_lens.components.unembed": [[37, "module-transformer_lens.components.unembed"]], "transformer_lens.evals": [[38, "module-transformer_lens.evals"]], "transformer_lens.head_detector": [[39, "module-transformer_lens.head_detector"]], "transformer_lens.hook_points": [[40, "module-transformer_lens.hook_points"]], "transformer_lens.loading_from_pretrained": [[41, "module-transformer_lens.loading_from_pretrained"]], "transformer_lens.past_key_value_caching": [[42, "module-transformer_lens.past_key_value_caching"]], "transformer_lens.patching": [[43, "module-transformer_lens.patching"]], "transformer_lens.pretrained": [[44, "transformer-lens-pretrained"]], "transformer_lens.pretrained.weight_conversions": [[45, "transformer-lens-pretrained-weight-conversions"]], "transformer_lens.pretrained.weight_conversions.bert": [[46, "module-transformer_lens.pretrained.weight_conversions.bert"]], "transformer_lens.pretrained.weight_conversions.bloom": [[47, "module-transformer_lens.pretrained.weight_conversions.bloom"]], "transformer_lens.pretrained.weight_conversions.coder": [[48, "module-transformer_lens.pretrained.weight_conversions.coder"]], "transformer_lens.pretrained.weight_conversions.gemma": [[49, "module-transformer_lens.pretrained.weight_conversions.gemma"]], "transformer_lens.pretrained.weight_conversions.gpt2": [[50, "module-transformer_lens.pretrained.weight_conversions.gpt2"]], "transformer_lens.pretrained.weight_conversions.gptj": [[51, "module-transformer_lens.pretrained.weight_conversions.gptj"]], "transformer_lens.pretrained.weight_conversions.llama": [[52, "module-transformer_lens.pretrained.weight_conversions.llama"]], "transformer_lens.pretrained.weight_conversions.mingpt": [[53, "module-transformer_lens.pretrained.weight_conversions.mingpt"]], "transformer_lens.pretrained.weight_conversions.mistral": [[54, "module-transformer_lens.pretrained.weight_conversions.mistral"]], "transformer_lens.pretrained.weight_conversions.mixtral": [[55, "module-transformer_lens.pretrained.weight_conversions.mixtral"]], "transformer_lens.pretrained.weight_conversions.nanogpt": [[56, "module-transformer_lens.pretrained.weight_conversions.nanogpt"]], "transformer_lens.pretrained.weight_conversions.neel_solu_old": [[57, "module-transformer_lens.pretrained.weight_conversions.neel_solu_old"]], "transformer_lens.pretrained.weight_conversions.neo": [[58, "module-transformer_lens.pretrained.weight_conversions.neo"]], "transformer_lens.pretrained.weight_conversions.neox": [[59, "module-transformer_lens.pretrained.weight_conversions.neox"]], "transformer_lens.pretrained.weight_conversions.opt": [[60, "module-transformer_lens.pretrained.weight_conversions.opt"]], "transformer_lens.pretrained.weight_conversions.phi": [[61, "module-transformer_lens.pretrained.weight_conversions.phi"]], "transformer_lens.pretrained.weight_conversions.phi3": [[62, "module-transformer_lens.pretrained.weight_conversions.phi3"]], "transformer_lens.pretrained.weight_conversions.qwen": [[63, "module-transformer_lens.pretrained.weight_conversions.qwen"]], "transformer_lens.pretrained.weight_conversions.qwen2": [[64, "module-transformer_lens.pretrained.weight_conversions.qwen2"]], "transformer_lens.pretrained.weight_conversions.qwen3": [[65, "module-transformer_lens.pretrained.weight_conversions.qwen3"]], "transformer_lens.pretrained.weight_conversions.t5": [[66, "module-transformer_lens.pretrained.weight_conversions.t5"]], "transformer_lens.train": [[67, "module-transformer_lens.train"]], "transformer_lens.utilities": [[68, "transformer-lens-utilities"]], "transformer_lens.utilities.activation_functions": [[69, "module-transformer_lens.utilities.activation_functions"]], "transformer_lens.utilities.addmm": [[70, "module-transformer_lens.utilities.addmm"]], "transformer_lens.utilities.attention": [[71, "module-transformer_lens.utilities.attention"]], "transformer_lens.utilities.devices": [[72, "module-transformer_lens.utilities.devices"]], "transformer_lens.utils": [[73, "module-transformer_lens.utils"]], "Exploratory Analysis Demo": [[74, "Exploratory-Analysis-Demo"]], "Tips for Reading This": [[74, "Tips-for-Reading-This"]], "Environment Setup (ignore)": [[74, "Environment-Setup-(ignore)"]], "Imports": [[74, "Imports"]], "PyTorch Setup": [[74, "PyTorch-Setup"]], "Plotting Helper Functions (ignore)": [[74, "Plotting-Helper-Functions-(ignore)"]], "Introduction": [[74, "Introduction"], [75, "Introduction"]], "Indirect Object Identification": [[74, "Indirect-Object-Identification"]], "Brainstorm What\u2019s Actually Going On (Optional)": [[74, "Brainstorm-What's-Actually-Going-On-(Optional)"]], "Direct Logit Attribution": [[74, "Direct-Logit-Attribution"]], "Logit Lens": [[74, "Logit-Lens"]], "Layer Attribution": [[74, "Layer-Attribution"]], "Head Attribution": [[74, "Head-Attribution"]], "Attention Analysis": [[74, "Attention-Analysis"]], "Activation Patching": [[74, "Activation-Patching"]], "Residual Stream": [[74, "Residual-Stream"]], "Layers": [[74, "Layers"]], "Heads": [[74, "Heads"]], "Decomposing Heads": [[74, "Decomposing-Heads"]], "Consolidating Understanding": [[74, "Consolidating-Understanding"]], "Visualizing Attention Patterns": [[74, "Visualizing-Attention-Patterns"]], "Comparing to the Paper": [[74, "Comparing-to-the-Paper"]], "Bonus: Exploring Anomalies": [[74, "Bonus:-Exploring-Anomalies"]], "Early Heads are Induction Heads(?!)": [[74, "Early-Heads-are-Induction-Heads(?!)"]], "Implications": [[74, "Implications"]], "Backup Name Mover Heads": [[74, "Backup-Name-Mover-Heads"]], "Transformer Lens Main Demo Notebook": [[75, "Transformer-Lens-Main-Demo-Notebook"]], "Loading and Running Models": [[75, "Loading-and-Running-Models"]], "Caching all Activations": [[75, "Caching-all-Activations"]], "Hooks: Intervening on Activations": [[75, "Hooks:-Intervening-on-Activations"]], "Activation Patching on the Indirect Object Identification Task": [[75, "Activation-Patching-on-the-Indirect-Object-Identification-Task"]], "Hooks: Accessing Activations": [[75, "Hooks:-Accessing-Activations"]], "Available Models": [[75, "Available-Models"]], "An overview of the important open source models in the library": [[75, "An-overview-of-the-important-open-source-models-in-the-library"]], "An overview of some interpretability-friendly models I\u2019ve trained and included": [[75, "An-overview-of-some-interpretability-friendly-models-I've-trained-and-included"]], "Other Resources:": [[75, "Other-Resources:"]], "Transformer architecture": [[75, "Transformer-architecture"]], "Parameter Names": [[75, "Parameter-Names"]], "Activation + Hook Names": [[75, "Activation-+-Hook-Names"]], "Folding LayerNorm (For the Curious)": [[75, "Folding-LayerNorm-(For-the-Curious)"]], "Features": [[75, "Features"]], "Dealing with tokens": [[75, "Dealing-with-tokens"]], "Gotcha: prepend_bos": [[75, "Gotcha:-prepend_bos"]], "Factored Matrix Class": [[75, "Factored-Matrix-Class"]], "Basic Examples": [[75, "Basic-Examples"]], "Medium Example: Eigenvalue Copying Scores": [[75, "Medium-Example:-Eigenvalue-Copying-Scores"]], "Generating Text": [[75, "Generating-Text"]], "Hook Points": [[75, "Hook-Points"]], "Toy Example": [[75, "Toy-Example"]], "Loading Pre-Trained Checkpoints": [[75, "Loading-Pre-Trained-Checkpoints"]], "Example: Induction Head Phase Transition": [[75, "Example:-Induction-Head-Phase-Transition"]], "Model Properties Table": [[76, "model-properties-table"]], "TransformerLens": [[77, "transformerlens"]], "A Library for Mechanistic Interpretability of Generative Language Models": [[77, "a-library-for-mechanistic-interpretability-of-generative-language-models"]]}, "indexentries": {"activationcache (class in transformer_lens.activationcache)": [[10, "transformer_lens.ActivationCache.ActivationCache"]], "__getitem__() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.__getitem__"]], "__iter__() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.__iter__"]], "__len__() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.__len__"]], "accumulated_resid() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.accumulated_resid"]], "apply_ln_to_stack() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.apply_ln_to_stack"]], "apply_slice_to_batch_dim() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.apply_slice_to_batch_dim"]], "compute_head_results() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.compute_head_results"]], "decompose_resid() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.decompose_resid"]], "get_full_resid_decomposition() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.get_full_resid_decomposition"]], "get_neuron_results() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.get_neuron_results"]], "items() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.items"]], "keys() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.keys"]], "logit_attrs() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.logit_attrs"]], "module": [[10, "module-transformer_lens.ActivationCache"], [11, "module-transformer_lens.BertNextSentencePrediction"], [12, "module-transformer_lens.FactoredMatrix"], [13, "module-transformer_lens.HookedEncoder"], [14, "module-transformer_lens.HookedEncoderDecoder"], [15, "module-transformer_lens.HookedTransformer"], [16, "module-transformer_lens.HookedTransformerConfig"], [17, "module-transformer_lens.SVDInterpreter"], [19, "module-transformer_lens.components.abstract_attention"], [20, "module-transformer_lens.components.attention"], [21, "module-transformer_lens.components.bert_block"], [22, "module-transformer_lens.components.bert_embed"], [23, "module-transformer_lens.components.bert_mlm_head"], [24, "module-transformer_lens.components.bert_nsp_head"], [25, "module-transformer_lens.components.bert_pooler"], [26, "module-transformer_lens.components.embed"], [27, "module-transformer_lens.components.grouped_query_attention"], [28, "module-transformer_lens.components.layer_norm"], [29, "module-transformer_lens.components.layer_norm_pre"], [30, "module-transformer_lens.components.pos_embed"], [31, "module-transformer_lens.components.rms_norm"], [32, "module-transformer_lens.components.rms_norm_pre"], [33, "module-transformer_lens.components.t5_attention"], [34, "module-transformer_lens.components.t5_block"], [35, "module-transformer_lens.components.token_typed_embed"], [36, "module-transformer_lens.components.transformer_block"], [37, "module-transformer_lens.components.unembed"], [38, "module-transformer_lens.evals"], [39, "module-transformer_lens.head_detector"], [40, "module-transformer_lens.hook_points"], [41, "module-transformer_lens.loading_from_pretrained"], [42, "module-transformer_lens.past_key_value_caching"], [43, "module-transformer_lens.patching"], [46, "module-transformer_lens.pretrained.weight_conversions.bert"], [47, "module-transformer_lens.pretrained.weight_conversions.bloom"], [48, "module-transformer_lens.pretrained.weight_conversions.coder"], [49, "module-transformer_lens.pretrained.weight_conversions.gemma"], [50, "module-transformer_lens.pretrained.weight_conversions.gpt2"], [51, "module-transformer_lens.pretrained.weight_conversions.gptj"], [52, "module-transformer_lens.pretrained.weight_conversions.llama"], [53, "module-transformer_lens.pretrained.weight_conversions.mingpt"], [54, "module-transformer_lens.pretrained.weight_conversions.mistral"], [55, "module-transformer_lens.pretrained.weight_conversions.mixtral"], [56, "module-transformer_lens.pretrained.weight_conversions.nanogpt"], [57, "module-transformer_lens.pretrained.weight_conversions.neel_solu_old"], [58, "module-transformer_lens.pretrained.weight_conversions.neo"], [59, "module-transformer_lens.pretrained.weight_conversions.neox"], [60, "module-transformer_lens.pretrained.weight_conversions.opt"], [61, "module-transformer_lens.pretrained.weight_conversions.phi"], [62, "module-transformer_lens.pretrained.weight_conversions.phi3"], [63, "module-transformer_lens.pretrained.weight_conversions.qwen"], [64, "module-transformer_lens.pretrained.weight_conversions.qwen2"], [65, "module-transformer_lens.pretrained.weight_conversions.qwen3"], [66, "module-transformer_lens.pretrained.weight_conversions.t5"], [67, "module-transformer_lens.train"], [69, "module-transformer_lens.utilities.activation_functions"], [70, "module-transformer_lens.utilities.addmm"], [71, "module-transformer_lens.utilities.attention"], [72, "module-transformer_lens.utilities.devices"], [73, "module-transformer_lens.utils"]], "remove_batch_dim() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.remove_batch_dim"]], "stack_activation() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.stack_activation"]], "stack_head_results() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.stack_head_results"]], "stack_neuron_results() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.stack_neuron_results"]], "to() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.to"]], "toggle_autodiff() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.toggle_autodiff"]], "transformer_lens.activationcache": [[10, "module-transformer_lens.ActivationCache"]], "values() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.values"]], "bertnextsentenceprediction (class in transformer_lens.bertnextsentenceprediction)": [[11, "transformer_lens.BertNextSentencePrediction.BertNextSentencePrediction"]], "forward() (transformer_lens.bertnextsentenceprediction.bertnextsentenceprediction method)": [[11, "transformer_lens.BertNextSentencePrediction.BertNextSentencePrediction.forward"]], "run_with_cache() (transformer_lens.bertnextsentenceprediction.bertnextsentenceprediction method)": [[11, "transformer_lens.BertNextSentencePrediction.BertNextSentencePrediction.run_with_cache"]], "to_tokens() (transformer_lens.bertnextsentenceprediction.bertnextsentenceprediction method)": [[11, "transformer_lens.BertNextSentencePrediction.BertNextSentencePrediction.to_tokens"]], "transformer_lens.bertnextsentenceprediction": [[11, "module-transformer_lens.BertNextSentencePrediction"]], "ab (transformer_lens.factoredmatrix.factoredmatrix property)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.AB"]], "ba (transformer_lens.factoredmatrix.factoredmatrix property)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.BA"]], "factoredmatrix (class in transformer_lens.factoredmatrix)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix"]], "s (transformer_lens.factoredmatrix.factoredmatrix property)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.S"]], "t (transformer_lens.factoredmatrix.factoredmatrix property)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.T"]], "u (transformer_lens.factoredmatrix.factoredmatrix property)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.U"]], "vh (transformer_lens.factoredmatrix.factoredmatrix property)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.Vh"]], "__getitem__() (transformer_lens.factoredmatrix.factoredmatrix method)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.__getitem__"]], "collapse_l() (transformer_lens.factoredmatrix.factoredmatrix method)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_l"]], "collapse_r() (transformer_lens.factoredmatrix.factoredmatrix method)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_r"]], "eigenvalues (transformer_lens.factoredmatrix.factoredmatrix property)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.eigenvalues"]], "get_corner() (transformer_lens.factoredmatrix.factoredmatrix method)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.get_corner"]], "make_even() (transformer_lens.factoredmatrix.factoredmatrix method)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.make_even"]], "ndim (transformer_lens.factoredmatrix.factoredmatrix property)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.ndim"]], "norm() (transformer_lens.factoredmatrix.factoredmatrix method)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.norm"]], "pair (transformer_lens.factoredmatrix.factoredmatrix property)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.pair"]], "svd() (transformer_lens.factoredmatrix.factoredmatrix method)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.svd"]], "transformer_lens.factoredmatrix": [[12, "module-transformer_lens.FactoredMatrix"]], "unsqueeze() (transformer_lens.factoredmatrix.factoredmatrix method)": [[12, "transformer_lens.FactoredMatrix.FactoredMatrix.unsqueeze"]], "hookedencoder (class in transformer_lens.hookedencoder)": [[13, "transformer_lens.HookedEncoder.HookedEncoder"]], "ov (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.OV"]], "qk (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.QK"]], "w_e (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.W_E"]], "w_e_pos (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.W_E_pos"]], "w_k (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.W_K"]], "w_o (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.W_O"]], "w_q (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.W_Q"]], "w_u (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.W_U"]], "w_v (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.W_V"]], "w_in (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.W_in"]], "w_out (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.W_out"]], "w_pos (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.W_pos"]], "all_head_labels() (transformer_lens.hookedencoder.hookedencoder method)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.all_head_labels"]], "b_k (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.b_K"]], "b_o (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.b_O"]], "b_q (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.b_Q"]], "b_u (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.b_U"]], "b_v (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.b_V"]], "b_in (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.b_in"]], "b_out (transformer_lens.hookedencoder.hookedencoder property)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.b_out"]], "cpu() (transformer_lens.hookedencoder.hookedencoder method)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.cpu"]], "cuda() (transformer_lens.hookedencoder.hookedencoder method)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.cuda"]], "encoder_output() (transformer_lens.hookedencoder.hookedencoder method)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.encoder_output"]], "forward() (transformer_lens.hookedencoder.hookedencoder method)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.forward"]], "from_pretrained() (transformer_lens.hookedencoder.hookedencoder class method)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.from_pretrained"]], "mps() (transformer_lens.hookedencoder.hookedencoder method)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.mps"]], "run_with_cache() (transformer_lens.hookedencoder.hookedencoder method)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.run_with_cache"]], "to() (transformer_lens.hookedencoder.hookedencoder method)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.to"]], "to_tokens() (transformer_lens.hookedencoder.hookedencoder method)": [[13, "transformer_lens.HookedEncoder.HookedEncoder.to_tokens"]], "transformer_lens.hookedencoder": [[13, "module-transformer_lens.HookedEncoder"]], "hookedencoderdecoder (class in transformer_lens.hookedencoderdecoder)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder"]], "ov (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.OV"]], "qk (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.QK"]], "w_e (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.W_E"]], "w_k (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.W_K"]], "w_o (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.W_O"]], "w_q (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.W_Q"]], "w_u (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.W_U"]], "w_v (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.W_V"]], "w_in (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.W_in"]], "w_out (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.W_out"]], "w_pos (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.W_pos"]], "all_head_labels() (transformer_lens.hookedencoderdecoder.hookedencoderdecoder method)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.all_head_labels"]], "b_k (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.b_K"]], "b_o (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.b_O"]], "b_q (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.b_Q"]], "b_u (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.b_U"]], "b_v (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.b_V"]], "b_in (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.b_in"]], "b_out (transformer_lens.hookedencoderdecoder.hookedencoderdecoder property)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.b_out"]], "cpu() (transformer_lens.hookedencoderdecoder.hookedencoderdecoder method)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.cpu"]], "cuda() (transformer_lens.hookedencoderdecoder.hookedencoderdecoder method)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.cuda"]], "forward() (transformer_lens.hookedencoderdecoder.hookedencoderdecoder method)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.forward"]], "from_pretrained() (transformer_lens.hookedencoderdecoder.hookedencoderdecoder class method)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.from_pretrained"]], "generate() (transformer_lens.hookedencoderdecoder.hookedencoderdecoder method)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.generate"]], "mps() (transformer_lens.hookedencoderdecoder.hookedencoderdecoder method)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.mps"]], "run_with_cache() (transformer_lens.hookedencoderdecoder.hookedencoderdecoder method)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.run_with_cache"]], "to() (transformer_lens.hookedencoderdecoder.hookedencoderdecoder method)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.to"]], "to_tokens() (transformer_lens.hookedencoderdecoder.hookedencoderdecoder method)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.to_tokens"]], "tokenizer (transformer_lens.hookedencoderdecoder.hookedencoderdecoder attribute)": [[14, "transformer_lens.HookedEncoderDecoder.HookedEncoderDecoder.tokenizer"]], "transformer_lens.hookedencoderdecoder": [[14, "module-transformer_lens.HookedEncoderDecoder"]], "hookedtransformer (class in transformer_lens.hookedtransformer)": [[15, "transformer_lens.HookedTransformer.HookedTransformer"]], "ov (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.OV"]], "output (class in transformer_lens.hookedtransformer)": [[15, "transformer_lens.HookedTransformer.Output"]], "qk (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.QK"]], "w_e (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_E"]], "w_e_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_E_pos"]], "w_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_K"]], "w_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_O"]], "w_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_Q"]], "w_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_U"]], "w_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_V"]], "w_gate (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_gate"]], "w_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_in"]], "w_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_out"]], "w_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.W_pos"]], "__init__() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.__init__"]], "accumulated_bias() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.accumulated_bias"]], "all_composition_scores() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.all_composition_scores"]], "all_head_labels() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.all_head_labels"]], "b_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_K"]], "b_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_O"]], "b_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_Q"]], "b_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_U"]], "b_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_V"]], "b_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_in"]], "b_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.b_out"]], "center_unembed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.center_unembed"]], "center_writing_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.center_writing_weights"]], "check_hooks_to_add() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.check_hooks_to_add"]], "cpu() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.cpu"]], "cuda() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.cuda"]], "fold_layer_norm() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.fold_layer_norm"]], "fold_value_biases() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.fold_value_biases"]], "forward() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.forward"]], "from_pretrained() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained"]], "from_pretrained_no_processing() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained_no_processing"]], "generate() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.generate"]], "get_pos_offset() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.get_pos_offset"]], "get_residual() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.get_residual"]], "get_token_position() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.get_token_position"]], "init_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.init_weights"]], "input_to_embed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.input_to_embed"]], "ln_final (transformer_lens.hookedtransformer.hookedtransformer attribute)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.ln_final"]], "load_and_process_state_dict() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.load_and_process_state_dict"]], "load_sample_training_dataset() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.load_sample_training_dataset"]], "logits (transformer_lens.hookedtransformer.output attribute)": [[15, "transformer_lens.HookedTransformer.Output.logits"]], "loss (transformer_lens.hookedtransformer.output attribute)": [[15, "transformer_lens.HookedTransformer.Output.loss"]], "loss_fn() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.loss_fn"]], "move_model_modules_to_device() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.move_model_modules_to_device"]], "mps() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.mps"]], "process_weights_() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.process_weights_"]], "refactor_factored_attn_matrices() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.refactor_factored_attn_matrices"]], "run_with_cache() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.run_with_cache"]], "sample_datapoint() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.sample_datapoint"]], "set_tokenizer() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.set_tokenizer"]], "set_ungroup_grouped_query_attention() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.set_ungroup_grouped_query_attention"]], "set_use_attn_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_in"]], "set_use_attn_result() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_result"]], "set_use_hook_mlp_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.set_use_hook_mlp_in"]], "set_use_split_qkv_input() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.set_use_split_qkv_input"]], "to() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.to"]], "to_single_str_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.to_single_str_token"]], "to_single_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.to_single_token"]], "to_str_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.to_str_tokens"]], "to_string() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.to_string"]], "to_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.to_tokens"]], "tokenizer (transformer_lens.hookedtransformer.hookedtransformer attribute)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.tokenizer"]], "tokens_to_residual_directions() (transformer_lens.hookedtransformer.hookedtransformer method)": [[15, "transformer_lens.HookedTransformer.HookedTransformer.tokens_to_residual_directions"]], "transformer_lens.hookedtransformer": [[15, "module-transformer_lens.HookedTransformer"]], "hookedtransformerconfig (class in transformer_lens.hookedtransformerconfig)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig"]], "ntk_by_parts_factor (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.NTK_by_parts_factor"]], "ntk_by_parts_high_freq_factor (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.NTK_by_parts_high_freq_factor"]], "ntk_by_parts_low_freq_factor (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.NTK_by_parts_low_freq_factor"]], "ntk_original_ctx_len (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.NTK_original_ctx_len"]], "act_fn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.act_fn"]], "attention_dir (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attention_dir"]], "attn_only (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_only"]], "attn_scale (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_scale"]], "attn_scores_soft_cap (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_scores_soft_cap"]], "attn_types (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_types"]], "checkpoint_index (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_index"]], "checkpoint_label_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_label_type"]], "checkpoint_value (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_value"]], "d_head (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_head"]], "d_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_mlp"]], "d_model (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_model"]], "d_vocab (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab"]], "d_vocab_out (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab_out"]], "decoder_start_token_id (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.decoder_start_token_id"]], "default_prepend_bos (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.default_prepend_bos"]], "device (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.device"]], "dtype (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.dtype"]], "eps (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.eps"]], "experts_per_token (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.experts_per_token"]], "final_rms (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.final_rms"]], "from_checkpoint (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_checkpoint"]], "from_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig class method)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_dict"]], "gated_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.gated_mlp"]], "init_mode (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_mode"]], "init_weights (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_weights"]], "initializer_range (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.initializer_range"]], "is_layer_norm_activation() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.is_layer_norm_activation"]], "load_in_4bit (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.load_in_4bit"]], "model_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.model_name"]], "n_ctx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_ctx"]], "n_devices (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_devices"]], "n_heads (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_heads"]], "n_key_value_heads (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_key_value_heads"]], "n_layers (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_layers"]], "n_params (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_params"]], "normalization_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.normalization_type"]], "num_experts (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.num_experts"]], "original_architecture (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.original_architecture"]], "output_logits_soft_cap (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.output_logits_soft_cap"]], "parallel_attn_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.parallel_attn_mlp"]], "positional_embedding_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.positional_embedding_type"]], "post_embedding_ln (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.post_embedding_ln"]], "relative_attention_max_distance (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.relative_attention_max_distance"]], "relative_attention_num_buckets (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.relative_attention_num_buckets"]], "rotary_adjacent_pairs (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_adjacent_pairs"]], "rotary_base (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_base"]], "rotary_dim (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_dim"]], "scale_attn_by_inverse_layer_idx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.scale_attn_by_inverse_layer_idx"]], "seed (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.seed"]], "set_seed_everywhere() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.set_seed_everywhere"]], "tie_word_embeddings (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tie_word_embeddings"]], "to_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.to_dict"]], "tokenizer_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_name"]], "tokenizer_prepends_bos (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_prepends_bos"]], "transformer_lens.hookedtransformerconfig": [[16, "module-transformer_lens.HookedTransformerConfig"]], "trust_remote_code (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.trust_remote_code"]], "ungroup_grouped_query_attention (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.ungroup_grouped_query_attention"]], "unwrap() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig class method)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.unwrap"]], "use_ntk_by_parts_rope (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_NTK_by_parts_rope"]], "use_attn_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_in"]], "use_attn_result (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_result"]], "use_attn_scale (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_scale"]], "use_hook_mlp_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_mlp_in"]], "use_hook_tokens (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_tokens"]], "use_local_attn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_local_attn"]], "use_normalization_before_and_after (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_normalization_before_and_after"]], "use_qk_norm (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_qk_norm"]], "use_split_qkv_input (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_split_qkv_input"]], "window_size (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[16, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.window_size"]], "svdinterpreter (class in transformer_lens.svdinterpreter)": [[17, "transformer_lens.SVDInterpreter.SVDInterpreter"]], "get_singular_vectors() (transformer_lens.svdinterpreter.svdinterpreter method)": [[17, "transformer_lens.SVDInterpreter.SVDInterpreter.get_singular_vectors"]], "transformer_lens.svdinterpreter": [[17, "module-transformer_lens.SVDInterpreter"]], "abstractattention (class in transformer_lens.components.abstract_attention)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention"]], "ignore (transformer_lens.components.abstract_attention.abstractattention attribute)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.IGNORE"]], "ov (transformer_lens.components.abstract_attention.abstractattention property)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.OV"]], "qk (transformer_lens.components.abstract_attention.abstractattention property)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.QK"]], "__init__() (transformer_lens.components.abstract_attention.abstractattention method)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.__init__"]], "alibi (transformer_lens.components.abstract_attention.abstractattention attribute)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.alibi"]], "apply_causal_mask() (transformer_lens.components.abstract_attention.abstractattention method)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.apply_causal_mask"]], "apply_rotary() (transformer_lens.components.abstract_attention.abstractattention method)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.apply_rotary"]], "calculate_attention_scores() (transformer_lens.components.abstract_attention.abstractattention method)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.calculate_attention_scores"]], "calculate_qkv_matrices() (transformer_lens.components.abstract_attention.abstractattention method)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.calculate_qkv_matrices"]], "calculate_sin_cos_rotary() (transformer_lens.components.abstract_attention.abstractattention method)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.calculate_sin_cos_rotary"]], "calculate_z_scores() (transformer_lens.components.abstract_attention.abstractattention method)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.calculate_z_scores"]], "create_alibi_bias() (transformer_lens.components.abstract_attention.abstractattention static method)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.create_alibi_bias"]], "create_alibi_multipliers() (transformer_lens.components.abstract_attention.abstractattention static method)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.create_alibi_multipliers"]], "create_alibi_slope() (transformer_lens.components.abstract_attention.abstractattention static method)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.create_alibi_slope"]], "forward() (transformer_lens.components.abstract_attention.abstractattention method)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.forward"]], "k_norm (transformer_lens.components.abstract_attention.abstractattention attribute)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.k_norm"]], "mask (transformer_lens.components.abstract_attention.abstractattention attribute)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.mask"]], "q_norm (transformer_lens.components.abstract_attention.abstractattention attribute)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.q_norm"]], "rotary_cos (transformer_lens.components.abstract_attention.abstractattention attribute)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.rotary_cos"]], "rotary_sin (transformer_lens.components.abstract_attention.abstractattention attribute)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.rotary_sin"]], "rotate_every_two() (transformer_lens.components.abstract_attention.abstractattention method)": [[19, "transformer_lens.components.abstract_attention.AbstractAttention.rotate_every_two"]], "transformer_lens.components.abstract_attention": [[19, "module-transformer_lens.components.abstract_attention"]], "attention (class in transformer_lens.components.attention)": [[20, "transformer_lens.components.attention.Attention"]], "__init__() (transformer_lens.components.attention.attention method)": [[20, "transformer_lens.components.attention.Attention.__init__"]], "transformer_lens.components.attention": [[20, "module-transformer_lens.components.attention"]], "bertblock (class in transformer_lens.components.bert_block)": [[21, "transformer_lens.components.bert_block.BertBlock"]], "forward() (transformer_lens.components.bert_block.bertblock method)": [[21, "transformer_lens.components.bert_block.BertBlock.forward"]], "transformer_lens.components.bert_block": [[21, "module-transformer_lens.components.bert_block"]], "bertembed (class in transformer_lens.components.bert_embed)": [[22, "transformer_lens.components.bert_embed.BertEmbed"]], "forward() (transformer_lens.components.bert_embed.bertembed method)": [[22, "transformer_lens.components.bert_embed.BertEmbed.forward"]], "transformer_lens.components.bert_embed": [[22, "module-transformer_lens.components.bert_embed"]], "bertmlmhead (class in transformer_lens.components.bert_mlm_head)": [[23, "transformer_lens.components.bert_mlm_head.BertMLMHead"]], "forward() (transformer_lens.components.bert_mlm_head.bertmlmhead method)": [[23, "transformer_lens.components.bert_mlm_head.BertMLMHead.forward"]], "transformer_lens.components.bert_mlm_head": [[23, "module-transformer_lens.components.bert_mlm_head"]], "bertnsphead (class in transformer_lens.components.bert_nsp_head)": [[24, "transformer_lens.components.bert_nsp_head.BertNSPHead"]], "forward() (transformer_lens.components.bert_nsp_head.bertnsphead method)": [[24, "transformer_lens.components.bert_nsp_head.BertNSPHead.forward"]], "transformer_lens.components.bert_nsp_head": [[24, "module-transformer_lens.components.bert_nsp_head"]], "bertpooler (class in transformer_lens.components.bert_pooler)": [[25, "transformer_lens.components.bert_pooler.BertPooler"]], "forward() (transformer_lens.components.bert_pooler.bertpooler method)": [[25, "transformer_lens.components.bert_pooler.BertPooler.forward"]], "transformer_lens.components.bert_pooler": [[25, "module-transformer_lens.components.bert_pooler"]], "embed (class in transformer_lens.components.embed)": [[26, "transformer_lens.components.embed.Embed"]], "forward() (transformer_lens.components.embed.embed method)": [[26, "transformer_lens.components.embed.Embed.forward"]], "transformer_lens.components.embed": [[26, "module-transformer_lens.components.embed"]], "groupedqueryattention (class in transformer_lens.components.grouped_query_attention)": [[27, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention"]], "w_k (transformer_lens.components.grouped_query_attention.groupedqueryattention property)": [[27, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.W_K"]], "w_v (transformer_lens.components.grouped_query_attention.groupedqueryattention property)": [[27, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.W_V"]], "__init__() (transformer_lens.components.grouped_query_attention.groupedqueryattention method)": [[27, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.__init__"]], "b_k (transformer_lens.components.grouped_query_attention.groupedqueryattention property)": [[27, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.b_K"]], "b_v (transformer_lens.components.grouped_query_attention.groupedqueryattention property)": [[27, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.b_V"]], "calculate_attention_scores() (transformer_lens.components.grouped_query_attention.groupedqueryattention method)": [[27, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.calculate_attention_scores"]], "calculate_qkv_matrices() (transformer_lens.components.grouped_query_attention.groupedqueryattention method)": [[27, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.calculate_qkv_matrices"]], "calculate_z_scores() (transformer_lens.components.grouped_query_attention.groupedqueryattention method)": [[27, "transformer_lens.components.grouped_query_attention.GroupedQueryAttention.calculate_z_scores"]], "transformer_lens.components.grouped_query_attention": [[27, "module-transformer_lens.components.grouped_query_attention"]], "layernorm (class in transformer_lens.components.layer_norm)": [[28, "transformer_lens.components.layer_norm.LayerNorm"]], "__init__() (transformer_lens.components.layer_norm.layernorm method)": [[28, "transformer_lens.components.layer_norm.LayerNorm.__init__"]], "forward() (transformer_lens.components.layer_norm.layernorm method)": [[28, "transformer_lens.components.layer_norm.LayerNorm.forward"]], "transformer_lens.components.layer_norm": [[28, "module-transformer_lens.components.layer_norm"]], "layernormpre (class in transformer_lens.components.layer_norm_pre)": [[29, "transformer_lens.components.layer_norm_pre.LayerNormPre"]], "__init__() (transformer_lens.components.layer_norm_pre.layernormpre method)": [[29, "transformer_lens.components.layer_norm_pre.LayerNormPre.__init__"]], "forward() (transformer_lens.components.layer_norm_pre.layernormpre method)": [[29, "transformer_lens.components.layer_norm_pre.LayerNormPre.forward"]], "transformer_lens.components.layer_norm_pre": [[29, "module-transformer_lens.components.layer_norm_pre"]], "posembed (class in transformer_lens.components.pos_embed)": [[30, "transformer_lens.components.pos_embed.PosEmbed"]], "forward() (transformer_lens.components.pos_embed.posembed method)": [[30, "transformer_lens.components.pos_embed.PosEmbed.forward"]], "transformer_lens.components.pos_embed": [[30, "module-transformer_lens.components.pos_embed"]], "rmsnorm (class in transformer_lens.components.rms_norm)": [[31, "transformer_lens.components.rms_norm.RMSNorm"]], "__init__() (transformer_lens.components.rms_norm.rmsnorm method)": [[31, "transformer_lens.components.rms_norm.RMSNorm.__init__"]], "forward() (transformer_lens.components.rms_norm.rmsnorm method)": [[31, "transformer_lens.components.rms_norm.RMSNorm.forward"]], "transformer_lens.components.rms_norm": [[31, "module-transformer_lens.components.rms_norm"]], "rmsnormpre (class in transformer_lens.components.rms_norm_pre)": [[32, "transformer_lens.components.rms_norm_pre.RMSNormPre"]], "__init__() (transformer_lens.components.rms_norm_pre.rmsnormpre method)": [[32, "transformer_lens.components.rms_norm_pre.RMSNormPre.__init__"]], "forward() (transformer_lens.components.rms_norm_pre.rmsnormpre method)": [[32, "transformer_lens.components.rms_norm_pre.RMSNormPre.forward"]], "transformer_lens.components.rms_norm_pre": [[32, "module-transformer_lens.components.rms_norm_pre"]], "t5attention (class in transformer_lens.components.t5_attention)": [[33, "transformer_lens.components.t5_attention.T5Attention"]], "compute_relative_attention_bias() (transformer_lens.components.t5_attention.t5attention method)": [[33, "transformer_lens.components.t5_attention.T5Attention.compute_relative_attention_bias"]], "transformer_lens.components.t5_attention": [[33, "module-transformer_lens.components.t5_attention"]], "t5block (class in transformer_lens.components.t5_block)": [[34, "transformer_lens.components.t5_block.T5Block"]], "forward() (transformer_lens.components.t5_block.t5block method)": [[34, "transformer_lens.components.t5_block.T5Block.forward"]], "transformer_lens.components.t5_block": [[34, "module-transformer_lens.components.t5_block"]], "tokentypeembed (class in transformer_lens.components.token_typed_embed)": [[35, "transformer_lens.components.token_typed_embed.TokenTypeEmbed"]], "forward() (transformer_lens.components.token_typed_embed.tokentypeembed method)": [[35, "transformer_lens.components.token_typed_embed.TokenTypeEmbed.forward"]], "transformer_lens.components.token_typed_embed": [[35, "module-transformer_lens.components.token_typed_embed"]], "transformerblock (class in transformer_lens.components.transformer_block)": [[36, "transformer_lens.components.transformer_block.TransformerBlock"]], "apply_mlp() (transformer_lens.components.transformer_block.transformerblock method)": [[36, "transformer_lens.components.transformer_block.TransformerBlock.apply_mlp"]], "forward() (transformer_lens.components.transformer_block.transformerblock method)": [[36, "transformer_lens.components.transformer_block.TransformerBlock.forward"]], "ln1 (transformer_lens.components.transformer_block.transformerblock attribute)": [[36, "transformer_lens.components.transformer_block.TransformerBlock.ln1"]], "ln2 (transformer_lens.components.transformer_block.transformerblock attribute)": [[36, "transformer_lens.components.transformer_block.TransformerBlock.ln2"]], "mlp (transformer_lens.components.transformer_block.transformerblock attribute)": [[36, "transformer_lens.components.transformer_block.TransformerBlock.mlp"]], "transformer_lens.components.transformer_block": [[36, "module-transformer_lens.components.transformer_block"]], "unembed (class in transformer_lens.components.unembed)": [[37, "transformer_lens.components.unembed.Unembed"]], "forward() (transformer_lens.components.unembed.unembed method)": [[37, "transformer_lens.components.unembed.Unembed.forward"]], "transformer_lens.components.unembed": [[37, "module-transformer_lens.components.unembed"]], "ioidataset (class in transformer_lens.evals)": [[38, "transformer_lens.evals.IOIDataset"]], "__getitem__() (transformer_lens.evals.ioidataset method)": [[38, "transformer_lens.evals.IOIDataset.__getitem__"]], "__len__() (transformer_lens.evals.ioidataset method)": [[38, "transformer_lens.evals.IOIDataset.__len__"]], "evaluate() (in module transformer_lens.evals)": [[38, "transformer_lens.evals.evaluate"]], "evaluate_on_dataset() (in module transformer_lens.evals)": [[38, "transformer_lens.evals.evaluate_on_dataset"]], "get_default_names() (transformer_lens.evals.ioidataset static method)": [[38, "transformer_lens.evals.IOIDataset.get_default_names"]], "get_default_nouns() (transformer_lens.evals.ioidataset static method)": [[38, "transformer_lens.evals.IOIDataset.get_default_nouns"]], "get_default_templates() (transformer_lens.evals.ioidataset static method)": [[38, "transformer_lens.evals.IOIDataset.get_default_templates"]], "get_sample() (transformer_lens.evals.ioidataset method)": [[38, "transformer_lens.evals.IOIDataset.get_sample"]], "induction_loss() (in module transformer_lens.evals)": [[38, "transformer_lens.evals.induction_loss"]], "ioi_eval() (in module transformer_lens.evals)": [[38, "transformer_lens.evals.ioi_eval"]], "make_code_data_loader() (in module transformer_lens.evals)": [[38, "transformer_lens.evals.make_code_data_loader"]], "make_owt_data_loader() (in module transformer_lens.evals)": [[38, "transformer_lens.evals.make_owt_data_loader"]], "make_pile_data_loader() (in module transformer_lens.evals)": [[38, "transformer_lens.evals.make_pile_data_loader"]], "make_wiki_data_loader() (in module transformer_lens.evals)": [[38, "transformer_lens.evals.make_wiki_data_loader"]], "sanity_check() (in module transformer_lens.evals)": [[38, "transformer_lens.evals.sanity_check"]], "transformer_lens.evals": [[38, "module-transformer_lens.evals"]], "compute_head_attention_similarity_score() (in module transformer_lens.head_detector)": [[39, "transformer_lens.head_detector.compute_head_attention_similarity_score"]], "detect_head() (in module transformer_lens.head_detector)": [[39, "transformer_lens.head_detector.detect_head"]], "get_duplicate_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[39, "transformer_lens.head_detector.get_duplicate_token_head_detection_pattern"]], "get_induction_head_detection_pattern() (in module transformer_lens.head_detector)": [[39, "transformer_lens.head_detector.get_induction_head_detection_pattern"]], "get_previous_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[39, "transformer_lens.head_detector.get_previous_token_head_detection_pattern"]], "get_supported_heads() (in module transformer_lens.head_detector)": [[39, "transformer_lens.head_detector.get_supported_heads"]], "transformer_lens.head_detector": [[39, "module-transformer_lens.head_detector"]], "hookfunction (in module transformer_lens.hook_points)": [[40, "transformer_lens.hook_points.HookFunction"]], "hookpoint (class in transformer_lens.hook_points)": [[40, "transformer_lens.hook_points.HookPoint"]], "hookedrootmodule (class in transformer_lens.hook_points)": [[40, "transformer_lens.hook_points.HookedRootModule"]], "lenshandle (class in transformer_lens.hook_points)": [[40, "transformer_lens.hook_points.LensHandle"]], "add_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.add_caching_hooks"]], "add_hook() (transformer_lens.hook_points.hookpoint method)": [[40, "transformer_lens.hook_points.HookPoint.add_hook"]], "add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.add_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookpoint method)": [[40, "transformer_lens.hook_points.HookPoint.add_perma_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.add_perma_hook"]], "cache_all() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.cache_all"]], "cache_some() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.cache_some"]], "check_and_add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.check_and_add_hook"]], "check_hooks_to_add() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.check_hooks_to_add"]], "clear_context() (transformer_lens.hook_points.hookpoint method)": [[40, "transformer_lens.hook_points.HookPoint.clear_context"]], "clear_contexts() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.clear_contexts"]], "context_level (transformer_lens.hook_points.lenshandle attribute)": [[40, "transformer_lens.hook_points.LensHandle.context_level"]], "forward() (transformer_lens.hook_points.hookpoint method)": [[40, "transformer_lens.hook_points.HookPoint.forward"]], "get_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.get_caching_hooks"]], "hook (transformer_lens.hook_points.lenshandle attribute)": [[40, "transformer_lens.hook_points.LensHandle.hook"]], "hook_dict (transformer_lens.hook_points.hookedrootmodule attribute)": [[40, "transformer_lens.hook_points.HookedRootModule.hook_dict"]], "hook_points() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.hook_points"]], "hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.hooks"]], "is_permanent (transformer_lens.hook_points.lenshandle attribute)": [[40, "transformer_lens.hook_points.LensHandle.is_permanent"]], "layer() (transformer_lens.hook_points.hookpoint method)": [[40, "transformer_lens.hook_points.HookPoint.layer"]], "mod_dict (transformer_lens.hook_points.hookedrootmodule attribute)": [[40, "transformer_lens.hook_points.HookedRootModule.mod_dict"]], "name (transformer_lens.hook_points.hookedrootmodule attribute)": [[40, "transformer_lens.hook_points.HookedRootModule.name"]], "remove_all_hook_fns() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.remove_all_hook_fns"]], "remove_hooks() (transformer_lens.hook_points.hookpoint method)": [[40, "transformer_lens.hook_points.HookPoint.remove_hooks"]], "reset_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.reset_hooks"]], "run_with_cache() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.run_with_cache"]], "run_with_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.run_with_hooks"]], "setup() (transformer_lens.hook_points.hookedrootmodule method)": [[40, "transformer_lens.hook_points.HookedRootModule.setup"]], "transformer_lens.hook_points": [[40, "module-transformer_lens.hook_points"]], "config (class in transformer_lens.loading_from_pretrained)": [[41, "transformer_lens.loading_from_pretrained.Config"]], "model_aliases (in module transformer_lens.loading_from_pretrained)": [[41, "transformer_lens.loading_from_pretrained.MODEL_ALIASES"]], "non_hf_hosted_model_names (in module transformer_lens.loading_from_pretrained)": [[41, "transformer_lens.loading_from_pretrained.NON_HF_HOSTED_MODEL_NAMES"]], "official_model_names (in module transformer_lens.loading_from_pretrained)": [[41, "transformer_lens.loading_from_pretrained.OFFICIAL_MODEL_NAMES"]], "d_head (transformer_lens.loading_from_pretrained.config attribute)": [[41, "transformer_lens.loading_from_pretrained.Config.d_head"]], "d_mlp (transformer_lens.loading_from_pretrained.config attribute)": [[41, "transformer_lens.loading_from_pretrained.Config.d_mlp"]], "d_model (transformer_lens.loading_from_pretrained.config attribute)": [[41, "transformer_lens.loading_from_pretrained.Config.d_model"]], "d_vocab (transformer_lens.loading_from_pretrained.config attribute)": [[41, "transformer_lens.loading_from_pretrained.Config.d_vocab"]], "debug (transformer_lens.loading_from_pretrained.config attribute)": [[41, "transformer_lens.loading_from_pretrained.Config.debug"]], "get_checkpoint_labels() (in module transformer_lens.loading_from_pretrained)": [[41, "transformer_lens.loading_from_pretrained.get_checkpoint_labels"]], "get_num_params_of_pretrained() (in module transformer_lens.loading_from_pretrained)": [[41, "transformer_lens.loading_from_pretrained.get_num_params_of_pretrained"]], "get_pretrained_model_config() (in module transformer_lens.loading_from_pretrained)": [[41, "transformer_lens.loading_from_pretrained.get_pretrained_model_config"]], "init_range (transformer_lens.loading_from_pretrained.config attribute)": [[41, "transformer_lens.loading_from_pretrained.Config.init_range"]], "layer_norm_eps (transformer_lens.loading_from_pretrained.config attribute)": [[41, "transformer_lens.loading_from_pretrained.Config.layer_norm_eps"]], "n_ctx (transformer_lens.loading_from_pretrained.config attribute)": [[41, "transformer_lens.loading_from_pretrained.Config.n_ctx"]], "n_heads (transformer_lens.loading_from_pretrained.config attribute)": [[41, "transformer_lens.loading_from_pretrained.Config.n_heads"]], "n_layers (transformer_lens.loading_from_pretrained.config attribute)": [[41, "transformer_lens.loading_from_pretrained.Config.n_layers"]], "transformer_lens.loading_from_pretrained": [[41, "module-transformer_lens.loading_from_pretrained"]], "hookedtransformerkeyvaluecache (class in transformer_lens.past_key_value_caching)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache"]], "hookedtransformerkeyvaluecacheentry (class in transformer_lens.past_key_value_caching)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry"]], "__getitem__() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.__getitem__"]], "append() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry method)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.append"]], "append_attention_mask() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.append_attention_mask"]], "entries (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.entries"]], "freeze() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.freeze"]], "frozen (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.frozen"]], "frozen (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.frozen"]], "init_cache() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache class method)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.init_cache"]], "init_cache_entry() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry class method)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.init_cache_entry"]], "past_keys (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_keys"]], "past_values (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_values"]], "previous_attention_mask (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.previous_attention_mask"]], "transformer_lens.past_key_value_caching": [[42, "module-transformer_lens.past_key_value_caching"]], "unfreeze() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[42, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.unfreeze"]], "generic_activation_patch() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.generic_activation_patch"]], "get_act_patch_attn_head_all_pos_every() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_all_pos_every"]], "get_act_patch_attn_head_by_pos_every() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_by_pos_every"]], "get_act_patch_attn_head_k_all_pos() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_k_all_pos"]], "get_act_patch_attn_head_k_by_pos() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_k_by_pos"]], "get_act_patch_attn_head_out_all_pos() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_out_all_pos"]], "get_act_patch_attn_head_out_by_pos() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_out_by_pos"]], "get_act_patch_attn_head_pattern_all_pos() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_pattern_all_pos"]], "get_act_patch_attn_head_pattern_by_pos() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_pattern_by_pos"]], "get_act_patch_attn_head_pattern_dest_src_pos() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_pattern_dest_src_pos"]], "get_act_patch_attn_head_q_all_pos() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_q_all_pos"]], "get_act_patch_attn_head_q_by_pos() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_q_by_pos"]], "get_act_patch_attn_head_v_all_pos() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_v_all_pos"]], "get_act_patch_attn_head_v_by_pos() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_head_v_by_pos"]], "get_act_patch_attn_out() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_attn_out"]], "get_act_patch_block_every() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_block_every"]], "get_act_patch_mlp_out() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_mlp_out"]], "get_act_patch_resid_mid() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_resid_mid"]], "get_act_patch_resid_pre() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.get_act_patch_resid_pre"]], "layer_head_dest_src_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.layer_head_dest_src_pos_pattern_patch_setter"]], "layer_head_pattern_patch_setter() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.layer_head_pattern_patch_setter"]], "layer_head_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.layer_head_pos_pattern_patch_setter"]], "layer_head_vector_patch_setter() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.layer_head_vector_patch_setter"]], "layer_pos_head_vector_patch_setter() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.layer_pos_head_vector_patch_setter"]], "layer_pos_patch_setter() (in module transformer_lens.patching)": [[43, "transformer_lens.patching.layer_pos_patch_setter"]], "transformer_lens.patching": [[43, "module-transformer_lens.patching"]], "transformer_lens.pretrained.weight_conversions.bert": [[46, "module-transformer_lens.pretrained.weight_conversions.bert"]], "convert_bloom_weights() (in module transformer_lens.pretrained.weight_conversions.bloom)": [[47, "transformer_lens.pretrained.weight_conversions.bloom.convert_bloom_weights"]], "transformer_lens.pretrained.weight_conversions.bloom": [[47, "module-transformer_lens.pretrained.weight_conversions.bloom"]], "convert_coder_weights() (in module transformer_lens.pretrained.weight_conversions.coder)": [[48, "transformer_lens.pretrained.weight_conversions.coder.convert_coder_weights"]], "transformer_lens.pretrained.weight_conversions.coder": [[48, "module-transformer_lens.pretrained.weight_conversions.coder"]], "transformer_lens.pretrained.weight_conversions.gemma": [[49, "module-transformer_lens.pretrained.weight_conversions.gemma"]], "transformer_lens.pretrained.weight_conversions.gpt2": [[50, "module-transformer_lens.pretrained.weight_conversions.gpt2"]], "transformer_lens.pretrained.weight_conversions.gptj": [[51, "module-transformer_lens.pretrained.weight_conversions.gptj"]], "transformer_lens.pretrained.weight_conversions.llama": [[52, "module-transformer_lens.pretrained.weight_conversions.llama"]], "transformer_lens.pretrained.weight_conversions.mingpt": [[53, "module-transformer_lens.pretrained.weight_conversions.mingpt"]], "convert_mistral_weights() (in module transformer_lens.pretrained.weight_conversions.mistral)": [[54, "transformer_lens.pretrained.weight_conversions.mistral.convert_mistral_weights"]], "transformer_lens.pretrained.weight_conversions.mistral": [[54, "module-transformer_lens.pretrained.weight_conversions.mistral"]], "convert_mixtral_weights() (in module transformer_lens.pretrained.weight_conversions.mixtral)": [[55, "transformer_lens.pretrained.weight_conversions.mixtral.convert_mixtral_weights"]], "transformer_lens.pretrained.weight_conversions.mixtral": [[55, "module-transformer_lens.pretrained.weight_conversions.mixtral"]], "transformer_lens.pretrained.weight_conversions.nanogpt": [[56, "module-transformer_lens.pretrained.weight_conversions.nanogpt"]], "transformer_lens.pretrained.weight_conversions.neel_solu_old": [[57, "module-transformer_lens.pretrained.weight_conversions.neel_solu_old"]], "transformer_lens.pretrained.weight_conversions.neo": [[58, "module-transformer_lens.pretrained.weight_conversions.neo"]], "transformer_lens.pretrained.weight_conversions.neox": [[59, "module-transformer_lens.pretrained.weight_conversions.neox"]], "transformer_lens.pretrained.weight_conversions.opt": [[60, "module-transformer_lens.pretrained.weight_conversions.opt"]], "convert_phi_weights() (in module transformer_lens.pretrained.weight_conversions.phi)": [[61, "transformer_lens.pretrained.weight_conversions.phi.convert_phi_weights"]], "transformer_lens.pretrained.weight_conversions.phi": [[61, "module-transformer_lens.pretrained.weight_conversions.phi"]], "convert_phi3_weights() (in module transformer_lens.pretrained.weight_conversions.phi3)": [[62, "transformer_lens.pretrained.weight_conversions.phi3.convert_phi3_weights"]], "transformer_lens.pretrained.weight_conversions.phi3": [[62, "module-transformer_lens.pretrained.weight_conversions.phi3"]], "convert_qwen_weights() (in module transformer_lens.pretrained.weight_conversions.qwen)": [[63, "transformer_lens.pretrained.weight_conversions.qwen.convert_qwen_weights"]], "transformer_lens.pretrained.weight_conversions.qwen": [[63, "module-transformer_lens.pretrained.weight_conversions.qwen"]], "convert_qwen2_weights() (in module transformer_lens.pretrained.weight_conversions.qwen2)": [[64, "transformer_lens.pretrained.weight_conversions.qwen2.convert_qwen2_weights"]], "transformer_lens.pretrained.weight_conversions.qwen2": [[64, "module-transformer_lens.pretrained.weight_conversions.qwen2"]], "convert_qwen3_weights() (in module transformer_lens.pretrained.weight_conversions.qwen3)": [[65, "transformer_lens.pretrained.weight_conversions.qwen3.convert_qwen3_weights"]], "transformer_lens.pretrained.weight_conversions.qwen3": [[65, "module-transformer_lens.pretrained.weight_conversions.qwen3"]], "convert_t5_weights() (in module transformer_lens.pretrained.weight_conversions.t5)": [[66, "transformer_lens.pretrained.weight_conversions.t5.convert_t5_weights"]], "transformer_lens.pretrained.weight_conversions.t5": [[66, "module-transformer_lens.pretrained.weight_conversions.t5"]], "hookedtransformertrainconfig (class in transformer_lens.train)": [[67, "transformer_lens.train.HookedTransformerTrainConfig"]], "batch_size (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.batch_size"]], "device (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.device"]], "lr (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.lr"]], "max_grad_norm (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.max_grad_norm"]], "max_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.max_steps"]], "momentum (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.momentum"]], "num_epochs (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.num_epochs"]], "optimizer_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.optimizer_name"]], "print_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.print_every"]], "save_dir (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.save_dir"]], "save_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.save_every"]], "seed (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.seed"]], "train() (in module transformer_lens.train)": [[67, "transformer_lens.train.train"]], "transformer_lens.train": [[67, "module-transformer_lens.train"]], "wandb (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.wandb"]], "wandb_project_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.wandb_project_name"]], "warmup_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.warmup_steps"]], "weight_decay (transformer_lens.train.hookedtransformertrainconfig attribute)": [[67, "transformer_lens.train.HookedTransformerTrainConfig.weight_decay"]], "transformer_lens.utilities.activation_functions": [[69, "module-transformer_lens.utilities.activation_functions"]], "batch_addmm() (in module transformer_lens.utilities.addmm)": [[70, "transformer_lens.utilities.addmm.batch_addmm"]], "transformer_lens.utilities.addmm": [[70, "module-transformer_lens.utilities.addmm"]], "vanilla_addmm() (in module transformer_lens.utilities.addmm)": [[70, "transformer_lens.utilities.addmm.vanilla_addmm"]], "complex_attn_linear() (in module transformer_lens.utilities.attention)": [[71, "transformer_lens.utilities.attention.complex_attn_linear"]], "simple_attn_linear() (in module transformer_lens.utilities.attention)": [[71, "transformer_lens.utilities.attention.simple_attn_linear"]], "transformer_lens.utilities.attention": [[71, "module-transformer_lens.utilities.attention"]], "availabledevicememory (in module transformer_lens.utilities.devices)": [[72, "transformer_lens.utilities.devices.AvailableDeviceMemory"]], "calculate_available_device_cuda_memory() (in module transformer_lens.utilities.devices)": [[72, "transformer_lens.utilities.devices.calculate_available_device_cuda_memory"]], "determine_available_memory_for_available_devices() (in module transformer_lens.utilities.devices)": [[72, "transformer_lens.utilities.devices.determine_available_memory_for_available_devices"]], "get_best_available_cuda_device() (in module transformer_lens.utilities.devices)": [[72, "transformer_lens.utilities.devices.get_best_available_cuda_device"]], "get_best_available_device() (in module transformer_lens.utilities.devices)": [[72, "transformer_lens.utilities.devices.get_best_available_device"]], "get_device_for_block_index() (in module transformer_lens.utilities.devices)": [[72, "transformer_lens.utilities.devices.get_device_for_block_index"]], "move_to_and_update_config() (in module transformer_lens.utilities.devices)": [[72, "transformer_lens.utilities.devices.move_to_and_update_config"]], "sort_devices_based_on_available_memory() (in module transformer_lens.utilities.devices)": [[72, "transformer_lens.utilities.devices.sort_devices_based_on_available_memory"]], "transformer_lens.utilities.devices": [[72, "module-transformer_lens.utilities.devices"]], "locallyoverridendefaults (class in transformer_lens.utils)": [[73, "transformer_lens.utils.LocallyOverridenDefaults"]], "slice (class in transformer_lens.utils)": [[73, "transformer_lens.utils.Slice"]], "sliceinput (in module transformer_lens.utils)": [[73, "transformer_lens.utils.SliceInput"]], "__init__() (transformer_lens.utils.locallyoverridendefaults method)": [[73, "transformer_lens.utils.LocallyOverridenDefaults.__init__"]], "__init__() (transformer_lens.utils.slice method)": [[73, "transformer_lens.utils.Slice.__init__"]], "apply() (transformer_lens.utils.slice method)": [[73, "transformer_lens.utils.Slice.apply"]], "calc_fan_in_and_fan_out() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.calc_fan_in_and_fan_out"]], "composition_scores() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.composition_scores"]], "download_file_from_hf() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.download_file_from_hf"]], "gelu_fast() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.gelu_fast"]], "gelu_new() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.gelu_new"]], "gelu_pytorch_tanh() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.gelu_pytorch_tanh"]], "get_act_name() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.get_act_name"]], "get_attention_mask() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.get_attention_mask"]], "get_corner() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.get_corner"]], "get_cumsum_along_dim() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.get_cumsum_along_dim"]], "get_dataset() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.get_dataset"]], "get_device() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.get_device"]], "get_input_with_manually_prepended_bos() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.get_input_with_manually_prepended_bos"]], "get_nested_attr() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.get_nested_attr"]], "get_offset_position_ids() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.get_offset_position_ids"]], "get_tokenizer_with_bos() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.get_tokenizer_with_bos"]], "get_tokens_with_bos_removed() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.get_tokens_with_bos_removed"]], "indices() (transformer_lens.utils.slice method)": [[73, "transformer_lens.utils.Slice.indices"]], "init_kaiming_normal_() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.init_kaiming_normal_"]], "init_kaiming_uniform_() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.init_kaiming_uniform_"]], "init_xavier_normal_() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.init_xavier_normal_"]], "init_xavier_uniform_() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.init_xavier_uniform_"]], "is_lower_triangular() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.is_lower_triangular"]], "is_square() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.is_square"]], "keep_single_column() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.keep_single_column"]], "lm_accuracy() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.lm_accuracy"]], "lm_cross_entropy_loss() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.lm_cross_entropy_loss"]], "override_or_use_default_value() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.override_or_use_default_value"]], "print_gpu_mem() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.print_gpu_mem"]], "remove_batch_dim() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.remove_batch_dim"]], "repeat_along_head_dimension() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.repeat_along_head_dimension"]], "sample_logits() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.sample_logits"]], "set_nested_attr() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.set_nested_attr"]], "slice (transformer_lens.utils.slice attribute)": [[73, "transformer_lens.utils.Slice.slice"]], "solu() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.solu"]], "test_prompt() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.test_prompt"]], "to_numpy() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.to_numpy"]], "tokenize_and_concatenate() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.tokenize_and_concatenate"]], "transformer_lens.utils": [[73, "module-transformer_lens.utils"]], "transpose() (in module transformer_lens.utils)": [[73, "transformer_lens.utils.transpose"]], "unwrap() (transformer_lens.utils.slice class method)": [[73, "transformer_lens.utils.Slice.unwrap"]]}})